{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90d3509-df4e-4110-8946-c25d93d6d4fa",
   "metadata": {},
   "source": [
    "# **Projeto de IA em Saúde: Modelo Preditivo para Risco de Diabetes na População Pima**\n",
    "\n",
    "## **1. Descrição do Cenário**\n",
    "\n",
    "A diabetes é uma doença crônica que afeta milhões de pessoas em todo o mundo e representa um desafio significativo para os sistemas de saúde. A detecção precoce e a identificação de indivíduos em alto risco são cruciais para a prevenção e o manejo eficaz da doença, permitindo intervenções no estilo de vida (dieta, exercícios) que podem retardar ou até mesmo prevenir seu aparecimento.\n",
    "\n",
    "Este projeto utilizará o dataset \"Pima Indians Diabetes Database\", que foi originalmente coletado pelo Instituto Nacional de Diabetes e Doenças Digestivas e Renais dos EUA. O dataset contém dados de saúde de mulheres com pelo menos 21 anos de idade, descendentes da tribo Pima, uma população com alta prevalência de diabetes. O objetivo é construir um modelo que possa prever a probabilidade de uma paciente ter diabetes com base em 8 medições diagnósticas.\n",
    "\n",
    "## **2. Qual é o objetivo do projeto?**\n",
    "\n",
    "O objetivo principal do projeto é **desenvolver e avaliar um modelo de Machine Learning de alta performance para prever a presença de diabetes com base em dados clínicos e demográficos.**\n",
    "\n",
    "Os objetivos específicos são:\n",
    "\n",
    "1.  **Análise Exploratória de Dados (EDA):** Realizar uma análise detalhada do dataset para entender a distribuição de cada variável e a correlação entre elas e o desfecho (presença de diabetes).\n",
    "2.  **Pré-processamento e Limpeza:** Identificar e tratar os valores implausíveis (zeros inadequados), substituindo-os por estimativas apropriadas (como a média ou mediana), e padronizar os dados para o treinamento.\n",
    "3.  **Visualização de Dados:** Criar visualizações claras e informativas (histogramas, boxplots, heatmaps) para comunicar os insights encontrados na fase de análise.\n",
    "4.  **Treinamento e Comparação de Modelos:** Treinar e comparar o desempenho de diferentes algoritmos de classificação (ex: Regressão Logística, K-Nearest Neighbors, Random Forest, Gradient Boosting).\n",
    "5.  **Avaliação de Performance:** Avaliar os modelos usando um conjunto de métricas robustas, incluindo Acurácia, Precisão, Recall, F1-Score e a Curva ROC/AUC, para selecionar o modelo mais equilibrado e eficaz.\n",
    "6.  **Interpretabilidade do Modelo:** Utilizar técnicas como *Feature Importance* para identificar quais dos 8 fatores de risco são os mais determinantes para o diagnóstico de diabetes, segundo o melhor modelo.\n",
    "\n",
    "## **3. Qual é o contexto da organização para o qual o projeto está sendo desenvolvido?**\n",
    "\n",
    "O projeto está sendo desenvolvido no contexto de uma **Clínica de Atenção Primária à Saúde (fictícia)**, focada em medicina preventiva e manejo de doenças crônicas.\n",
    "\n",
    "**Contexto da Organização:**\n",
    "\n",
    "*   **Missão:** A clínica tem como missão oferecer cuidados de saúde proativos e personalizados à sua comunidade, com um forte foco na prevenção de doenças crônicas como diabetes, hipertensão e doenças cardíacas.\n",
    "*   **Desafio Atual:** Os médicos da clínica identificam pacientes de risco com base em consultas e exames de rotina, mas o processo é reativo e depende da iniciativa do paciente em agendar uma consulta. A clínica deseja implementar um sistema mais proativo para triar sua base de pacientes e identificar aqueles que, mesmo sem sintomas aparentes, possam ter um alto risco de desenvolver diabetes.\n",
    "*   **Objetivo Estratégico:** A clínica quer adotar ferramentas de análise de dados para criar \"scores de risco\" para seus pacientes. Este projeto serve como uma prova de conceito para demonstrar como um modelo de Machine Learning, treinado com dados clínicos padrão, pode automatizar e escalar a identificação de pacientes de alto risco.\n",
    "*   **Aplicação Prática do Projeto:** Se o modelo for bem-sucedido, ele poderia ser integrado ao sistema de prontuário eletrônico da clínica. Periodicamente, o sistema rodaria o modelo nos dados dos pacientes e geraria uma lista priorizada para a equipe de enfermagem. Os pacientes identificados com alto risco seriam então contatados para uma consulta de acompanhamento, exames adicionais e aconselhamento sobre mudanças no estilo de vida, transformando o cuidado de reativo para proativo.\n",
    "*   \n",
    "## 4. **Quais técnicas de PLN e ML serão utilizadas?**\n",
    "\n",
    "Os modelos mais indicados podem ser agrupados em três categorias:\n",
    "\n",
    "1.  **Modelos Simples e Interpretáveis (Ótimos para Começar)**\n",
    "2.  **Modelos de Ensemble (Geralmente a Melhor Performance)**\n",
    "3.  **Outros Modelos Poderosos**\n",
    "\n",
    "### 1. Modelos Simples e Interpretáveis\n",
    "\n",
    "Esses modelos são ideais para obter um *baseline* rápido e entender quais features são mais importantes.\n",
    "\n",
    "#### a) Regressão Logística (Logistic Regression)\n",
    "\n",
    "*   **Por que é indicado?** É o ponto de partida padrão para qualquer problema de classificação. É rápido, eficiente e, o mais importante, **altamente interpretável**. Pode ver facilmente o peso (coeficiente) que o modelo atribui a cada feature (ex: \"um aumento de 10 pontos na Glicose aumenta a chance de diabetes em X%\").\n",
    "*   **Quando usar?** Sempre. É o primeiro modelo para estabelecer uma base de comparação.\n",
    "*   **Ponto fraco:** Assume uma relação linear entre as features e a probabilidade do resultado, o que nem sempre é verdade.\n",
    "\n",
    "#### b) K-Nearest Neighbors (KNN)\n",
    "\n",
    "*   **Por que é indicado?** É um modelo intuitivo baseado em \"proximidade\". Ele classifica um novo paciente com base na classe da maioria dos seus \"vizinhos\" mais próximos no conjunto de dados.\n",
    "*   **Quando usar?** Quando você suspeita que pacientes com características semelhantes têm o mesmo resultado, sem necessariamente haver uma relação linear.\n",
    "*   **Ponto fraco:** Pode ser lento com muitos dados e é muito sensível à escala das features (exige **padronização**).\n",
    "\n",
    "### 2. Modelos de Ensemble (Melhor Performance Geral)\n",
    "\n",
    "Esses modelos combinam as previsões de vários modelos mais simples (geralmente árvores de decisão) para obter um resultado mais robusto e preciso. Eles quase sempre superam os modelos simples em performance.\n",
    "\n",
    "#### a) Random Forest (Floresta Aleatória)\n",
    "\n",
    "*   **Por que é indicado?** É um dos modelos mais populares e eficazes que existem. Ele constrói centenas de árvores de decisão em subconjuntos aleatórios dos dados e das features, e a previsão final é a \"votação\" da maioria das árvores. É robusto a outliers e não exige padronização das features.\n",
    "*   **Quando usar?** Quando seu objetivo principal é **maximizar a precisão da previsão**.\n",
    "*   **Ponto fraco:** É menos interpretável que a Regressão Logística (é uma \"caixa-preta\"). Você pode ver a importância geral das features, mas não a direção do efeito.\n",
    "\n",
    "#### b) Gradient Boosting (e suas variantes: XGBoost, LightGBM, CatBoost)\n",
    "\n",
    "*   **Por que é indicado?** **Estes são os reis da performance** em dados tabulares como o seu. Eles constroem árvores de forma sequencial, onde cada nova árvore tenta corrigir os erros da anterior.\n",
    "*   **Quando usar?** Quando você precisa da **máxima performance preditiva possível**. LightGBM é extremamente rápido, e XGBoost é incrivelmente robusto.\n",
    "*   **Ponto fraco:** Ainda mais \"caixa-preta\" que o Random Forest e possui mais hiperparâmetros para ajustar, o que pode tornar o treinamento mais complexo.\n",
    "\n",
    "### 3. Outros Modelos Poderosos\n",
    "\n",
    "#### a) Support Vector Machines (SVM)\n",
    "\n",
    "*   **Por que é indicado?** É um modelo muito poderoso que funciona encontrando o \"hiperplano\" que melhor separa as duas classes (diabéticos e não diabéticos) no espaço das features. É muito eficaz em espaços de alta dimensão.\n",
    "*   **Quando usar?** Funciona bem quando há uma separação clara entre as classes, mesmo que essa separação não seja linear (usando o \"truque do kernel\").\n",
    "*   **Ponto fraco:** Exige padronização das features e pode ser computacionalmente caro com muitos dados. A interpretação também não é direta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fcb443-accb-4af2-a595-094319264022",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados (EDA)\n",
    "Para começar a explorar o dataset, que foi baixado diretamente do site **Kaggle**, vamos primeiro carregar o dataset em dataframe pandas e fazer uma pré visualização para verificar se o dataframe foi criado corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d894ed-4d5a-4c2a-9117-a0a58bd541a8",
   "metadata": {},
   "source": [
    "## Bibliotecas usadas para o projeto\n",
    "A seguir estão as bibliotecas usadas para o projeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348196c3-7081-4346-8c08-e1f97b13be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # importando o pandas para manipularmos o \n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport # importando o pandas-profiling para fazer o profile do dataset\n",
    "from sklearn.preprocessing import StandardScaler # importando somente o StandardScaler do scikit-learn\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')  # Use the 'Agg' backend which doesn't require GUI\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # utilizado para o split entre treinamento e teste\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import seaborn as sns\n",
    "#sns.set_style(\"whitegrid\")  # Options include: darkgrid, whitegrid, dark, white, ticks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e432b3b-a296-43c3-a535-3c10621ee933",
   "metadata": {},
   "source": [
    "## Carregando o dataset \n",
    "Vamos criar um dataframe a partir do dataset e vizualiar os dados para garantir que esta etapa foi realizada com sucesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e44fc-2ad6-44a1-90e4-020660b1d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'diabetes.csv'\n",
    "\n",
    "#  Carregar o arquivo CSV em um DataFrame pandas\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Passo 4: Verificar se os dados foram carregados corretamente\n",
    "    print(f\"Dataset '{file_path}' carregado com sucesso!\")\n",
    "    print(f\"O dataset possui {df.shape[0]} linhas e {df.shape[1]} colunas.\")\n",
    "    \n",
    "    print(\"\\n--- 5 Primeiras Linhas do Dataset ---\")\n",
    "    # A função display() do Jupyter formata a tabela de forma mais elegante\n",
    "    display(df.head())\n",
    "\n",
    "    print(\"\\n--- Informações Gerais do Dataset ---\")\n",
    "    df.info()\n",
    "\n",
    "    print(\"\\n--- Estatísticas Descritivas ---\")\n",
    "    display(df.describe())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: O arquivo '{file_path}' não foi encontrado.\")\n",
    "    print(\"Por favor, verifique se o nome do arquivo está correto e se ele está na mesma pasta do seu notebook.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro inesperado: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802a746-58f0-4016-bba8-1ef93c7aee07",
   "metadata": {},
   "source": [
    "### Contexto\n",
    "Este conjunto de dados é originalmente do Instituto Nacional de Diabetes e Doenças Digestivas e Renais. O objetivo do conjunto de dados é prever, por meio de diagnóstico, se um paciente tem ou não diabetes, com base em certas medidas diagnósticas incluídas no conjunto de dados. Diversas restrições foram impostas à seleção desses casos a partir de um banco de dados maior. Em particular, todos os pacientes aqui são mulheres com pelo menos 21 anos de idade e de ascendência indígena Pima.\n",
    "\n",
    "### Features (variáveis)\n",
    "O conjunto de dados consiste em diversas variáveis preditoras médicas e uma variável alvo (**Outcome**). As variáveis preditoras incluem o número de gestações que a paciente teve, seu IMC, nível de insulina, idade, entre outras.\n",
    "\n",
    "\n",
    "#### Variáveis Preditivas \n",
    "\n",
    "Estas são as 8 variáveis que usaremos para tentar prever o resultado.\n",
    "\n",
    "1.  **`Pregnancies` (Número de Gestações)**\n",
    "    *   **Significado:** O número de vezes que a paciente esteve grávida.\n",
    "    *   **Contexto Clínico:** A gravidez pode induzir um estado de resistência à insulina, e múltiplas gestações são por vezes associadas a um risco aumentado de desenvolver diabetes tipo 2 mais tarde na vida. É um fator demográfico e de histórico de saúde importante.\n",
    "    *   **Tipo:** Numérica, discreta.\n",
    "\n",
    "2.  **`Glucose` (Glicose)**\n",
    "    *   **Significado:** A concentração de glicose no plasma sanguíneo, medida 2 horas após a ingestão de uma quantidade padrão de açúcar (75g) durante um Teste Oral de Tolerância à Glicose (TOTG).\n",
    "    *   **Contexto Clínico:** Esta é **uma das variáveis mais importantes**. Níveis elevados de glicose após o teste são um indicador chave de pré-diabetes ou diabetes. Um valor normal geralmente fica abaixo de 140 mg/dL, enquanto valores acima de 200 mg/dL indicam diabetes.\n",
    "    *   **Tipo:** Numérica, contínua.\n",
    "\n",
    "3.  **`BloodPressure` (Pressão Arterial)**\n",
    "    *   **Significado:** Pressão arterial diastólica, medida em milímetros de mercúrio (mm Hg). A diastólica é a pressão nas artérias quando o coração está em repouso, entre os batimentos.\n",
    "    *   **Contexto Clínico:** A hipertensão (pressão alta) é frequentemente associada à diabetes e faz parte da chamada \"síndrome metabólica\". Pacientes com diabetes têm um risco maior de desenvolver pressão alta, e vice-versa.\n",
    "    *   **Tipo:** Numérica, contínua.\n",
    "\n",
    "4.  **`SkinThickness` (Espessura da Dobra Cutânea)**\n",
    "    *   **Significado:** A espessura da dobra da pele do tríceps, medida em milímetros (mm).\n",
    "    *   **Contexto Clínico:** É uma medida usada para estimar a gordura corporal. Níveis mais altos de gordura corporal estão fortemente correlacionados com a resistência à insulina e o risco de diabetes tipo 2.\n",
    "    *   **Tipo:** Numérica, contínua.\n",
    "\n",
    "5.  **`Insulin` (Insulina)**\n",
    "    *   **Significado:** O nível de insulina no soro sanguíneo, medido 2 horas após o início do teste de tolerância à glicose, em micro unidades por mililitro (mu U/ml).\n",
    "    *   **Contexto Clínico:** Esta é outra **variável crucial**. No início da resistência à insulina (pré-diabetes), o pâncreas tenta compensar produzindo *mais* insulina. Portanto, níveis elevados de insulina podem indicar que o corpo está lutando para controlar o açúcar no sangue. Em estágios avançados da diabetes tipo 2, a produção de insulina pode diminuir.\n",
    "    *   **Tipo:** Numérica, contínua.\n",
    "\n",
    "6.  **`BMI` (Body Mass Index / Índice de Massa Corporal)**\n",
    "    *   **Significado:** Um índice calculado a partir do peso e da altura de uma pessoa (peso em kg / (altura em m)²).\n",
    "    *   **Contexto Clínico:** O IMC é uma medida amplamente utilizada para classificar o peso de uma pessoa (abaixo do peso, normal, sobrepeso, obesidade). A obesidade (IMC > 30) é um dos maiores fatores de risco para o desenvolvimento de diabetes tipo 2.\n",
    "    *   **Tipo:** Numérica, contínua.\n",
    "\n",
    "7.  **`DiabetesPedigreeFunction` (Função de Predisposição Genética para Diabetes)**\n",
    "    *   **Significado:** Uma função que calcula uma pontuação de risco de diabetes com base no histórico familiar da paciente (idade e diagnóstico de diabetes em parentes).\n",
    "    *   **Contexto Clínico:** Esta variável sintetiza a predisposição genética. Um valor mais alto indica uma maior probabilidade de ter a doença com base na genética familiar, que é um fator de risco bem conhecido.\n",
    "    *   **Tipo:** Numérica, contínua.\n",
    "\n",
    "8.  **`Age` (Idade)**\n",
    "    *   **Significado:** A idade da paciente em anos.\n",
    "    *   **Contexto Clínico:** O risco de desenvolver diabetes tipo 2 aumenta significativamente com a idade, especialmente após os 45 anos.\n",
    "    *   **Tipo:** Numérica, discreta.\n",
    "\n",
    "#### Variável Alvo (Target)\n",
    "\n",
    "Esta é a variável que queremos que o nosso modelo aprenda a prever.\n",
    "\n",
    "9.  **`Outcome` (Desfecho / Resultado)**\n",
    "    *   **Significado:** Uma variável binária que indica se a paciente foi diagnosticada com diabetes ou não.\n",
    "    *   **Valores:**\n",
    "        *   **1**: A paciente tem diabetes.\n",
    "        *   **0**: A paciente não tem diabetes.\n",
    "    *   **Tipo:** Categórica, binária."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254e0e2-0f1d-410e-954c-670fbdebfc98",
   "metadata": {},
   "source": [
    "## Pré-processamento e Limpeza\n",
    "Um desafio interessante neste dataset é que alguns valores \"zero\" em certas colunas (como `Glucose`, `BloodPressure` ou `BMI`) são, na verdade, dados ausentes ou implausíveis (uma pessoa não pode ter pressão arterial de 0). Tratar esses valores de forma adequada será uma parte importante do pré-processamento.\n",
    "\n",
    "### Tratando valores zeros\n",
    "Vamos substituir os valores zeros por NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a5244-e36d-45cb-a8e2-3bb1d7531063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar e contar os zeros nas colunas onde zero é um valor inválido.\n",
    "# Não incluímos 'Pregnancies' e 'Outcome', pois 0 é um valor válido para elas.\n",
    "colunas_com_zeros_invalidos = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "\n",
    "print(\"--- Contagem de Zeros Inválidos Antes da Substituição ---\")\n",
    "# Itera sobre a lista de colunas e conta quantos zeros existem em cada uma.\n",
    "for coluna in colunas_com_zeros_invalidos:\n",
    "    num_zeros = (df[coluna] == 0).sum()\n",
    "    print(f\"Coluna '{coluna}': {num_zeros} zeros\")\n",
    "\n",
    "#  Substituir os zeros por NaN (Not a Number) diretamente no DataFrame 'df'.\n",
    "df[colunas_com_zeros_invalidos] = df[colunas_com_zeros_invalidos].replace(0, np.nan)\n",
    "print(\"\\nValores '0' substituídos por NaN no DataFrame 'df'.\")\n",
    "\n",
    "#  Confirmar a contagem de valores nulos de forma explícita.\n",
    "print(\"\\n--- Contagem de Valores Nulos (NaN) por Coluna ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"Porcentagem de valores ausanetes por coluna:\")\n",
    "((df.isnull().sum() / df.shape[0])*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48023252-1549-499a-b22a-67bfc0d8bcac",
   "metadata": {},
   "source": [
    "### Análise das Porcentagens de Valores Ausentes\n",
    "\n",
    "*   **`Insulin`: 48.7%**\n",
    "    *   **Problema:** Quase metade dos dados de insulina está faltando. Esta é uma quantidade muito significativa.\n",
    "    *   **Impacto:** Simplesmente remover quase metade das linhas do nosso dataset seria desastroso, pois perderíamos muita informação valiosa das outras colunas. Preencher quase 50% dos valores com uma única estatística (média/mediana) também é arriscado, pois pode distorcer a distribuição natural da variável e diminuir seu poder preditivo.\n",
    "\n",
    "*   **`SkinThickness`: 29.6%**\n",
    "    *   **Problema:** Similar à insulina, mas um pouco menos severo. Quase um terço dos dados de espessura da pele está ausente.\n",
    "    *   **Impacto:** As mesmas preocupações se aplicam. A imputação precisa ser feita com cuidado.\n",
    "\n",
    "*   **`BloodPressure`: 4.6%**, **`BMI`: 1.4%**, **`Glucose`: 0.7%**\n",
    "    *   **Problema:** Estas colunas têm uma quantidade pequena e muito mais gerenciável de dados ausentes.\n",
    "    *   **Impacto:** Para estas variáveis, a imputação com a média ou mediana é uma estratégia segura e padrão. O risco de distorcer a distribuição é mínimo.\n",
    "\n",
    "### Estratégia de Pré-processamento (Plano de Ação)\n",
    "\n",
    "Com base nessa análise, podemos definir uma estratégia clara.\n",
    "\n",
    "**1. Para `Glucose`, `BloodPressure` e `BMI` (Poucos Dados Ausentes):**\n",
    "\n",
    "A melhor abordagem é a **imputação pela mediana**. Usamos a mediana em vez da média porque ela é menos sensível a valores extremos (outliers), que são comuns em dados médicos.\n",
    "\n",
    "**2. Para `Insulin` e `SkinThickness` (Muitos Dados Ausentes):**\n",
    "\n",
    "Aqui temos algumas opções, da mais simples à mais complexa:\n",
    "\n",
    "*   **Opção A (Mais Simples): Imputação pela Mediana.**\n",
    "    *   **Prós:** Rápido e fácil de implementar. Mantém o tamanho do dataset.\n",
    "    *   **Contras:** Pode introduzir um viés significativo no modelo, já que estamos \"inventando\" uma grande quantidade de dados. O modelo pode aprender que o valor da mediana está associado a um determinado resultado, o que não é verdade.\n",
    "\n",
    "*   **Opção B (Mais Segura): Remover as Colunas.**\n",
    "    *   **Prós:** Evita completamente o risco de introduzir informações falsas. O modelo será treinado apenas com os dados que temos certeza que são reais.\n",
    "    *   **Contras:** Perdemos potencialmente informações preditivas importantes. A insulina, por exemplo, é fundamental no diagnóstico da diabetes.\n",
    "\n",
    "*   **Opção C (Avançada): Imputação Preditiva.**\n",
    "    *   **Prós:** A abordagem mais sofisticada. Treinamos um modelo de regressão (ex: k-NN ou Regressão Linear) para *prever* os valores ausentes de `Insulin` com base nas outras colunas.\n",
    "    *   **Contras:** Muito mais complexo de implementar e pode vazar informação do conjunto de teste se não for feito corretamente dentro de um pipeline.\n",
    "\n",
    "**Escolha para o Projeto:**\n",
    "\n",
    "Para este projeto, seguirmos um caminho mais simples:\n",
    "\n",
    "1.  **Excluir `Glucose`, `BloodPressure` e `BMI` com valores ausetes.**\n",
    "2.  **Excluir as colunas `Insulin` e `SkinThickness`** e testar os modelos preditivos sem estas colunas.\n",
    "3.  **Mantar as colunas  `Insulin` e `SkinThickness`** mas apagar as linhas com valores ausentes e testar os modelos preditivos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d4947-5f38-4a4a-9882-df2e86a9766f",
   "metadata": {},
   "source": [
    "#### Passos 1 e 2\n",
    "Criaremos um novo dataframe  após realizar os passos 1 e 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3621b051-ff58-4664-9d8c-5a059df7c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Criar uma cópia do DataFrame para não alterar o original ---\n",
    "# Todas as operações de limpeza serão feitas no 'df_limpo'.\n",
    "df_limpo = df.copy()\n",
    "\n",
    "print(\"--- Estado Inicial dos DataFrames ---\")\n",
    "print(f\"df_limpo (cópia) possui {df_limpo.shape[0]} linhas e {df_limpo.shape[1]} colunas.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- Excluir as LINHAS com valores ausentes em colunas específicas do df_limpo ---\n",
    "# Definimos as colunas onde não aceitaremos valores ausentes.\n",
    "colunas_para_limpar_linhas = ['Glucose', 'BloodPressure', 'BMI']\n",
    "\n",
    "# Usamos .dropna() no df_limpo. O resultado é atribuído de volta a ele mesmo.\n",
    "# O argumento 'subset' especifica que devemos olhar apenas para estas colunas.\n",
    "df_limpo = df_limpo.dropna(subset=colunas_para_limpar_linhas)\n",
    "\n",
    "print(\"\\n--- Após exclusão de LINHAS no 'df_limpo' ---\")\n",
    "print(f\"df_limpo agora possui {df_limpo.shape[0]} linhas.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# ---  Excluir as COLUNAS 'Insulin' e 'SkinThickness' do df_limpo ---\n",
    "# Usamos .drop() para remover as colunas.\n",
    "# 'axis=1' especifica que queremos remover COLUNAS.\n",
    "colunas_para_excluir = ['Insulin', 'SkinThickness']\n",
    "df_limpo = df_limpo.drop(columns=colunas_para_excluir)\n",
    "\n",
    "print(\"\\n--- Após exclusão de COLUNAS no 'df_limpo' ---\")\n",
    "print(f\"df_limpo agora possui {df_limpo.shape[1]} colunas.\")\n",
    "print(f\"Colunas restantes: {df_limpo.columns.tolist()}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "df_limpo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab13f70-7be9-4d60-82bd-41990aa26848",
   "metadata": {},
   "source": [
    "#### Passos 1 e 3\n",
    "Criaremos um novo dataframe após realizar os passos 1 e 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14056034-dc22-49c5-8ab4-ff738fce9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Criar uma cópia do DataFrame original ---\n",
    "# O novo DataFrame 'df_short' receberá as modificações.\n",
    "df_short = df.copy()\n",
    "\n",
    "print(\"--- Estado Inicial dos DataFrames ---\")\n",
    "print(f\"df_short (cópia) possui {df_short.shape[0]} linhas e {df_short.shape[1]} colunas.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- Excluir TODAS as linhas que contenham QUALQUER valor ausente (NaN) ---\n",
    "# O método .dropna() sem argumentos remove qualquer linha que tenha pelo menos um NaN.\n",
    "# O resultado da operação (um DataFrame menor) é atribuído de volta a 'df_short'.\n",
    "df_short = df_short.dropna()\n",
    "\n",
    "print(\"\\n--- Após remover TODAS as linhas com valores NaN do 'df_short' ---\")\n",
    "print(f\"O 'df_short' agora possui {df_short.shape[0]} linhas.\")\n",
    "print(f\"Foram removidas {df.shape[0] - df_short.shape[0]} linhas.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\n--- Após exclusão de COLUNAS no 'df_short' ---\")\n",
    "print(f\"df_limpo agora possui {df_short.shape[1]} colunas.\")\n",
    "print(f\"Colunas restantes: {df_short.columns.tolist()}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "df_short.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053f928-0808-4304-aac6-7f2006a9e681",
   "metadata": {},
   "source": [
    "### ProfileReport\n",
    "\n",
    "Uma ferramenta poderosa para a análiseexploratória é o **ProfileReport** da biblioteca ydata_profiling. Esta ferramenta gera  um relatório detalhado e interativo sobre um DataFrame do pandas, automatizando o processo de Análise Exploratória de Dados (AED). Dentre as principais ferramentas estão;\n",
    "1. Visão Geral (Overview): Mostra estatísticas gerais do conjunto de dados, como o número de variáveis, número de observações, valores em falta (missing values), percentagem de valores em falta, linhas duplicadas e o tamanho total na memória. Também informa os tipos de variáveis detetadas (numéricas, categóricas, etc.).\n",
    "2. Alertas (Alerts): Esta é uma das funcionalidades mais úteis. O relatório identifica automaticamente potenciais problemas nos dados, como colunas com alta correlação, alta cardinalidade (muitos valores únicos), assimetria (skewness) nos dados, ou colunas com um valor constante.\n",
    "3. Análise de Variáveis (Variables): Para cada coluna do DataFrame, o relatório fornece estatísticas detalhadas.\n",
    "    * Para variáveis numéricas: Estatísticas descritivas (média, mediana, desvio padrão, etc.), um histograma da distribuição, e valores mais comuns.\n",
    "    * Para variáveis categóricas: Contagem de valores únicos, um gráfico de barras com a frequência de cada categoria.\n",
    "4. Correlações (Correlations): Apresenta matrizes de correlação (como Pearson, Spearman, etc.) para visualizar a relação entre as variáveis numéricas.\n",
    "5. Valores em Falta (Missing Values): Mostra visualizações como matrizes ou gráficos de barras para ajudar a entender onde os valores em falta estão localizados e em que quantidade.\n",
    "6. Amostra (Sample): Exibe as primeiras e as últimas linhas do conjunto de dados, semelhante aos métodos .head() e .tail() do pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dda2db-1bef-448b-8cba-30877754957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile_limpo = ProfileReport(df_limpo)\n",
    "#profile_limpo.to_file(\"relatorio_df_limpo.html\")\n",
    "\n",
    "#profile_short = ProfileReport(df_short)\n",
    "#profile_short.to_file(\"relatorio_df_short.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f30e1ae-e3de-42ad-99c6-9f3a54d5e88e",
   "metadata": {},
   "source": [
    "#### Analisando o df_limpo com o ProfileReport\n",
    "\n",
    "Aqui está uma análise das correlações mais significativas:\n",
    "\n",
    "| Variável 1 | Variável 2 | Coeficiente de Correlação | Força da Correlação | Interpretação |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Age** | **Pregnancies** | 0.617 | Moderada | Há uma correlação positiva moderada entre idade e número de gestações. Isso sugere que, em geral, mulheres mais velhas neste conjunto de dados tendem a ter tido mais gestações. |\n",
    "| **Glucose** | **Outcome** | 0.475 | Moderada | Existe uma correlação positiva moderada entre o nível de glicose e o resultado (provavelmente a presença de diabetes). Isso indica que níveis mais altos de glicose estão associados a uma maior probabilidade do resultado positivo para diabetes. |\n",
    "| **Age** | **BloodPressure** | 0.367 | Fraca | A correlação entre idade e pressão arterial é positiva, mas fraca. |\n",
    "\n",
    "**Principais Conclusões:**\n",
    "\n",
    "*   A **Glicose** é o preditor individual mais forte do `Outcome` (desfecho), com uma correlação de **0.475**.\n",
    "*   A **Idade (`Age`)** e o **Número de Gestações (`Pregnancies`)** estão moderadamente correlacionados (**0.617**), não vamos remover nehuma das duas, não é uma correlação tão forte.\n",
    "*   Variáveis como `DiabetesPedigreeFunction` e `BloodPressure` têm correlações mais fracas com o `Outcome` em comparação com a Glicose.\n",
    "\n",
    "#### Analisando o df_short com o ProfileReport\n",
    "\n",
    "Aqui está a análise das correlações mais importantes, com foco nas relações mais fortes:\n",
    "\n",
    "| Variável 1 | Variável 2 | Coeficiente de Correlação | Força da Correlação | Interpretação |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **BMI** | **SkinThickness** | 0.674 | Forte | Há uma forte correlação positiva entre o IMC (Índice de Massa Corporal) e a espessura da dobra cutânea. Isso é esperado, pois um IMC mais alto geralmente corresponde a mais gordura corporal. |\n",
    "| **Glucose** | **Insulin** | 0.659 | Forte | Existe uma forte correlação positiva entre os níveis de glicose e de insulina. Isso faz sentido fisiologicamente, pois o corpo libera insulina em resposta a níveis elevados de glicose no sangue. |\n",
    "| **Age** | **Pregnancies** | 0.634 | Moderada | Semelhante à tabela anterior, há uma correlação positiva moderada entre idade e número de gestações. |\n",
    "| **Glucose** | **Outcome** | 0.524 | Moderada | A correlação entre Glicose e o Desfecho (`Outcome`) é de 0.524, sendo a mais forte com a variável alvo. Isso reforça a glicose como um indicador chave para o diagnóstico de diabetes. |\n",
    "\n",
    "**Principais Conclusões e Comparação:**\n",
    "\n",
    "*   **Novas Correlações Fortes:** A inclusão das variáveis `Insulin` e `SkinThickness` revelou duas novas correlações fortes que não estavam visíveis antes:\n",
    "    *   **IMC e Espessura da Pele (0.674):** A mais forte de todas na tabela.\n",
    "    *   **Glicose e Insulina (0.659):** Também muito forte e clinicamente relevante.\n",
    "*   **Melhor Preditor do `Outcome`:** A **Glicose** continua sendo a variável com a maior correlação com o `Outcome` (**0.524**), e essa correlação é ainda mais forte neste conjunto de dados (`df_shrot`) em comparação com o anterior (`df_limpo`, que era 0.475).\n",
    "*   **Multicolinearidade:** As fortes correlações entre `BMI` e `SkinThickness`, e entre `Glucose` e `Insulin`, indicam **multicolinearidade**. Isso significa que essas variáveis carregam informações semelhantes. Ao construir um modelo de machine learning, pode ser útil usar apenas uma de cada par para evitar redundância e instabilidade no modelo.\n",
    "\n",
    "Em resumo, o dataframe `df_shrot` parece ser mais rico em informações, e as novas variáveis confirmam relações fisiológicas importantes e fornecem insights valiosos para a modelagem.\n",
    "\n",
    "Vamos excluir as colunas **BMI** e **Insulin** por ter menor correlação com a **outcome**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1fb91-0ca2-4b42-ba19-dc22b3bf8b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removendos as colunas desnecessárias\n",
    "df_short = df_short.drop(['BMI', 'Insulin'], axis=1)\n",
    "\n",
    "df_short.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693001ef-5d4e-4b67-999c-16c67f5a099d",
   "metadata": {},
   "source": [
    "# 3. Divisão do dataset\n",
    "Agora vamos dividir o dataset em duas base de dados;\n",
    "* Treinamento: 80% dos dados seram usados para treinar os modelos.\n",
    "* Teste: 20% dos dados seram usados para testar os modelos.\n",
    "\n",
    "## df_limpo\n",
    "Vamos dividir o df_limpo em terino e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5297af88-cebb-40ea-a754-bdf27d30cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, dividimos em treino (80%) e teste (20%)\n",
    "X_train_limpo, X_test_limpo, y_train_limpo, y_test_limpo = train_test_split(\n",
    "    df_limpo.drop(['Outcome'], axis=1),   # remove as colunas label \n",
    "    df_limpo['Outcome'],   # Coluna que será usada como label de classificação\n",
    "    test_size=0.2,  # informamos a porcentagem de divisão para a base de testes.\n",
    "    random_state=35  # aqui informamos um \"seed\".\n",
    ")\n",
    "\n",
    "print(\"Dimensões dos conjuntos:\")\n",
    "print(\"dataset original\", df_limpo.shape)\n",
    "print(\"X_train_limpo:\", X_train_limpo.shape, \"| y_train_limpo:\", y_train_limpo.shape)\n",
    "print(\"X_test_limpo:\", X_test_limpo.shape, \"  | y_test_limpo:\", y_test_limpo.shape)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff0f7d-c9df-4e18-9b8b-fa38312b40ae",
   "metadata": {},
   "source": [
    "## df_short\n",
    "Vamos dividir o df_short em terino e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c845361-5ca5-42d3-96f5-2fd913bfbe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, dividimos em treino (80%) e teste (20%)\n",
    "X_train_short, X_test_short, y_train_short, y_test_short = train_test_split(\n",
    "    df_short.drop(['Outcome'], axis=1),   # remove as colunas label \n",
    "    df_short['Outcome'],   # Coluna que será usada como label de classificação\n",
    "    test_size=0.2,  # informamos a porcentagem de divisão para a base de testes.\n",
    "    random_state=35  # aqui informamos um \"seed\".\n",
    ")\n",
    "\n",
    "print(\"Dimensões dos conjuntos:\")\n",
    "print(\"dataset original\", df_limpo.shape)\n",
    "print(\"X_train_short:\", X_train_short.shape, \"| y_train_short:\", y_train_short.shape)\n",
    "print(\"X_test_short:\", X_test_short.shape, \"  | y_test_short:\", y_test_short.shape)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eae4e9-a8f0-484f-9f3e-b6b4d7ac2890",
   "metadata": {},
   "source": [
    "# 4. Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fae048-f12b-46ae-8f53-eee1b393f6c9",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "\n",
    "Vamos usar Box Plot para verificar os **outliers**, **dispersão dos dados** e **simetria dos dados**:\n",
    "\n",
    "### X_train_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b808841f-fea2-49cd-a0c5-0658edd8504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar as colunas numéricas para os box plots\n",
    "numeric_cols = ['Pregnancies', 'Glucose', 'BloodPressure', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "# Configurações de estilo para os gráficos\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Título geral para a figura\n",
    "plt.suptitle(\"Box Plots das Variáveis Numéricas para Detecção de Outliers\", fontsize=20, y=0.97)\n",
    "\n",
    "# Loop para criar um box plot para cada coluna numérica\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    plt.subplot(3, 3, i + 1)  # para criar uma grade de subplots de 3x3 (9 espaços)\n",
    "    \n",
    "    sns.boxplot(y=X_train_limpo[col], color='skyblue', width=0.5)\n",
    "    plt.title(f'Distribuição de {col}', fontsize=14)\n",
    "    plt.ylabel('')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95]) # Ajusta o layout para não sobrepor títulos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94299f5b-9d61-4469-9da2-fed33897eadd",
   "metadata": {},
   "source": [
    "#### Removendo Outliers do Conjunto df_limpo\n",
    "Este código irá calcular os limites com base em **X_train_limpo** e depois removerá as linhas com outliers de X_train_limpo, y_train_limpo, X_test_limpo e y_test_limpo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88308f47-0ec9-4557-9667-24b12b669929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IDENTIFICAR AS COLUNAS PARA VERIFICAR OUTLIERS ---\n",
    "# Vamos focar nas colunas numéricas contínuas onde outliers são mais prováveis e problemáticos.\n",
    "colunas_para_verificar = ['Pregnancies', 'Glucose', 'BloodPressure', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "\n",
    "# ---  APRENDER OS LIMITES DOS OUTLIERS APENAS COM O CONJUNTO DE TREINO ---\n",
    "print(\"--- Aprendendo os limites dos outliers com o conjunto de treino ---\")\n",
    "limites = {}\n",
    "\n",
    "for coluna in colunas_para_verificar:\n",
    "    Q1 = X_train_limpo[coluna].quantile(0.25)\n",
    "    Q3 = X_train_limpo[coluna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    limites[coluna] = (limite_inferior, limite_superior)\n",
    "    print(f\"Coluna '{coluna}': Limites calculados = [{limite_inferior:.2f}, {limite_superior:.2f}]\")\n",
    "\n",
    "    \n",
    "# --- APLICAR OS FILTROS A TODOS OS CONJUNTOS DE DADOS ---\n",
    "\n",
    "# Criar uma cópia para não modificar os dataframes originais\n",
    "X_train_limpo_outlier = X_train_limpo.copy()\n",
    "y_train_limpo_outlier = y_train_limpo.copy()\n",
    "X_test_limpo_outlier = X_test_limpo.copy()\n",
    "y_test_limpo_outlier = y_test_limpo.copy()\n",
    "\n",
    "print(\"\\n--- Removendo outliers ---\")\n",
    "for coluna in colunas_para_verificar:\n",
    "    limite_inf, limite_sup = limites[coluna]\n",
    "    \n",
    "    # Criar máscaras booleanas para cada conjunto de dados\n",
    "    mascara_train = (X_train_limpo_outlier[coluna] >= limite_inf) & (X_train_limpo_outlier[coluna] <= limite_sup)\n",
    "    mascara_test = (X_test_limpo_outlier[coluna] >= limite_inf) & (X_test_limpo_outlier[coluna] <= limite_sup)\n",
    "    \n",
    "    # Aplicar as máscaras para filtrar os dataframes\n",
    "    X_train_limpo_outlier = X_train_limpo_outlier[mascara_train]\n",
    "    y_train_limpo_outlier = y_train_limpo_outlier[mascara_train]\n",
    "    \n",
    "    X_test_limpo_outlier = X_test_limpo_outlier[mascara_test]\n",
    "    y_test_limpo_outlier = y_test_limpo_outlier[mascara_test]\n",
    "\n",
    "\n",
    "# ---  VERIFICAR O RESULTADO ---\n",
    "print(\"\\n--- Comparação de Tamanhos (Antes vs. Depois) ---\")\n",
    "print(f\"Tamanho de X_train_limpo_outlier: {len(X_train_limpo)} -> {len(X_train_limpo_outlier)} (removidos {len(X_train_limpo) - len(X_train_limpo_outlier)} outliers)\")\n",
    "print(f\"Tamanho de X_test_limpo_outlier:  {len(X_test_limpo)} -> {len(X_test_limpo_outlier)} (removidos {len(X_test_limpo) - len(X_test_limpo_outlier)} outliers)\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Amostra do DataFrame de Treino Limpo ---\")\n",
    "display(X_train_limpo_outlier.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b0008f-08f3-46ad-8ad3-965bc62cc650",
   "metadata": {},
   "source": [
    "### X_train_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3285ba2-445f-4136-adb2-765119d93e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar as colunas numéricas para os box plots\n",
    "numeric_cols = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "# Configurações de estilo para os gráficos\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Título geral para a figura\n",
    "plt.suptitle(\"Box Plots das Variáveis Numéricas para Detecção de Outliers\", fontsize=20, y=0.97)\n",
    "\n",
    "# Loop para criar um box plot para cada coluna numérica\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    plt.subplot(3, 3, i + 1)  # para criar uma grade de subplots de 3x3 (9 espaços)\n",
    "    \n",
    "    sns.boxplot(y=X_train_short[col], color='skyblue', width=0.5)\n",
    "    plt.title(f'Distribuição de {col}', fontsize=14)\n",
    "    plt.ylabel('')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95]) # Ajusta o layout para não sobrepor títulos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b61be-c01a-4112-b8c6-27145290e3ec",
   "metadata": {},
   "source": [
    "#### Removendo Outliers do Conjunto df_short\n",
    "Este código irá calcular os limites com base em **X_train_short** e depois removerá as linhas com outliers de X_train_short, y_train_short, X_test_short e y_test_short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7462a9e5-df66-44bc-95a5-277b5972563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IDENTIFICAR AS COLUNAS PARA VERIFICAR OUTLIERS ---\n",
    "# Vamos focar nas colunas numéricas contínuas onde outliers são mais prováveis e problemáticos.\n",
    "colunas_para_verificar = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "\n",
    "# ---  APRENDER OS LIMITES DOS OUTLIERS APENAS COM O CONJUNTO DE TREINO ---\n",
    "print(\"--- Aprendendo os limites dos outliers com o conjunto de treino ---\")\n",
    "limites = {}\n",
    "\n",
    "for coluna in colunas_para_verificar:\n",
    "    Q1 = X_train_short[coluna].quantile(0.25)\n",
    "    Q3 = X_train_short[coluna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    limites[coluna] = (limite_inferior, limite_superior)\n",
    "    print(f\"Coluna '{coluna}': Limites calculados = [{limite_inferior:.2f}, {limite_superior:.2f}]\")\n",
    "\n",
    "    \n",
    "# --- APLICAR OS FILTROS A TODOS OS CONJUNTOS DE DADOS ---\n",
    "\n",
    "# Criar uma cópia para não modificar os dataframes originais\n",
    "X_train_short_outlier = X_train_short.copy()\n",
    "y_train_short_outlier = y_train_short.copy()\n",
    "X_test_short_outlier = X_test_short.copy()\n",
    "y_test_short_outlier = y_test_short.copy()\n",
    "\n",
    "print(\"\\n--- Removendo outliers ---\")\n",
    "for coluna in colunas_para_verificar:\n",
    "    limite_inf, limite_sup = limites[coluna]\n",
    "    \n",
    "    # Criar máscaras booleanas para cada conjunto de dados\n",
    "    mascara_train = (X_train_short_outlier[coluna] >= limite_inf) & (X_train_short_outlier[coluna] <= limite_sup)\n",
    "    mascara_test = (X_test_short_outlier[coluna] >= limite_inf) & (X_test_short_outlier[coluna] <= limite_sup)\n",
    "    \n",
    "    # Aplicar as máscaras para filtrar os dataframes\n",
    "    X_train_short_outlier = X_train_short_outlier[mascara_train]\n",
    "    y_train_short_outlier = y_train_short_outlier[mascara_train]\n",
    "    \n",
    "    X_test_short_outlier = X_test_short_outlier[mascara_test]\n",
    "    y_test_short_outlier = y_test_short_outlier[mascara_test]\n",
    "\n",
    "\n",
    "# ---  VERIFICAR O RESULTADO ---\n",
    "print(\"\\n--- Comparação de Tamanhos (Antes vs. Depois) ---\")\n",
    "print(f\"Tamanho de X_train_short_outlier: {len(X_train_short)} -> {len(X_train_short_outlier)} (removidos {len(X_train_short) - len(X_train_short_outlier)} outliers)\")\n",
    "print(f\"Tamanho de X_test_short_outlier:  {len(X_test_short)} -> {len(X_test_short_outlier)} (removidos {len(X_test_short) - len(X_test_short_outlier)} outliers)\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Amostra do DataFrame de Treino Limpo ---\")\n",
    "display(X_train_short_outlier.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88250203-9545-4d00-bf62-f6ad336de321",
   "metadata": {},
   "source": [
    "## Normalização ou padronização\n",
    "\n",
    "### 1. Normalização (Min-Max Scaling)\n",
    "\n",
    "*   **O que faz?** Transforma os dados para que eles fiquem em um intervalo fixo, geralmente entre **0 e 1**.\n",
    "*   **Fórmula:** `X_norm = (X - X_min) / (X_max - X_min)`\n",
    "*   **Prós:** Garante que todos os dados fiquem na mesma escala exata. Útil para alguns algoritmos de redes neurais e para visualização.\n",
    "*   **Contras (O Ponto Crítico):** É **extremamente sensível a outliers**. Se você tiver um outlier (um valor muito alto ou muito baixo), ele vai \"espremer\" todos os outros dados em um intervalo muito pequeno, distorcendo a distribuição relativa entre eles. Como você acabou de fazer um trabalho cuidadoso para *remover* outliers, a normalização até poderia ser usada, mas a padronização ainda é mais robusta.\n",
    "\n",
    "### 2. Padronização (Standardization / Z-score Normalization)\n",
    "\n",
    "*   **O que faz?** Transforma os dados para que eles tenham uma média (`μ`) de **0** e um desvio padrão (`σ`) de **1**. Não limita os valores a um intervalo específico.\n",
    "*   **Fórmula:** `X_std = (X - μ) / σ`\n",
    "*   **Prós:**\n",
    "    *   **É muito menos sensível a outliers** do que a normalização. Um outlier não influenciará a escala dos outros pontos de forma tão drástica.\n",
    "    *   Mantém a forma da distribuição original dos dados.\n",
    "    *   É o pré-requisito para muitos algoritmos de machine learning que assumem que os dados estão centrados em zero.\n",
    "*   **Contras:** Não coloca os dados em um intervalo fixo, o que pode ser um problema para algoritmos muito específicos que exigem isso (raro em classificação clássica).\n",
    "\n",
    "### Por que a Padronização é mais aconselhável para nosso caso?\n",
    "\n",
    "1.  **Compatibilidade com os Modelos:**\n",
    "    *   **Regressão Logística e SVM:** Esses modelos se beneficiam enormemente da padronização. Esses algoritmos de otimização convergem muito mais rápido quando os dados estão centrados em zero e têm a mesma variância.\n",
    "    *   **KNN:** A performance do KNN depende da distância entre os pontos. A padronização garante que features com escalas maiores (como `Glucose`) não dominem o cálculo da distância em relação a features com escalas menores (como `DiabetesPedigreeFunction`).\n",
    "    *   **Modelos de Árvore (Random Forest, XGBoost):** Estes modelos **não exigem** nem padronização nem normalização, pois suas decisões são baseadas em dividir uma feature de cada vez (`ex: Glicose > 140?`), independentemente da escala das outras. No entanto, aplicar a padronização não prejudica o desempenho deles e permite que você use o mesmo pipeline de pré-processamento para todos os modelos, simplificando seu fluxo de trabalho.\n",
    "\n",
    "### Regra de Ouro (Data Leakage)\n",
    "\n",
    "Assim como na remoção de outliers, lembre-se da regra mais importante:\n",
    "\n",
    "1.  **Ajuste (Fit) o Scaler APENAS no conjunto de treino:** Você deve calcular a média (`μ`) e o desvio padrão (`σ`) **exclusivamente** a partir dos dados de `X_train`.\n",
    "2.  **Transforme (Transform) ambos os conjuntos:** Use o scaler já \"treinado\" para transformar tanto o `X_train` quanto o `X_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d87847d-b7b5-468b-9fe8-4dd5e1f685a6",
   "metadata": {},
   "source": [
    "# 5. Treinando alguns modelos pedritivos\n",
    "## df_limpo após remoção de outlier\n",
    "Vamos testar alguns modelos com o dataframe df_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7673c-69f6-4bf1-a805-cfdafa1c42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  DEFINIÇÃO DOS PIPELINES ---\n",
    "pipe_lr_limpo = Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression(random_state=35))])\n",
    "pipe_knn_limpo = Pipeline([('scaler', StandardScaler()), ('model', KNeighborsClassifier())])\n",
    "pipe_rf_limpo = Pipeline([('scaler', StandardScaler()), ('model', RandomForestClassifier(random_state=35))])\n",
    "pipe_xgb_limpo = Pipeline([('scaler', StandardScaler()), ('model', XGBClassifier(random_state=35, eval_metric='logloss'))])\n",
    "pipe_svm_limpo = Pipeline([('scaler', StandardScaler()), ('model', SVC(random_state=35))])\n",
    "\n",
    "pipelines_limpo = [pipe_lr_limpo, pipe_knn_limpo, pipe_rf_limpo, pipe_xgb_limpo, pipe_svm_limpo]\n",
    "model_names = ['Regressão Logística', 'KNN (k-NN)', 'Random Forest', 'XGBoost', 'SVM']\n",
    "\n",
    "# --- TREINAMENTO E AVALIAÇÃO ---\n",
    "print(\"\\n---Treinando e avaliando cada pipeline ---\")\n",
    "results = []\n",
    "for i, pipe in enumerate(pipelines_limpo):\n",
    "    pipe.fit(X_train_limpo_outlier, y_train_limpo_outlier)\n",
    "    y_pred = pipe.predict(X_test_limpo_outlier)\n",
    "    accuracy = accuracy_score(y_test_limpo_outlier, y_pred)\n",
    "    precision = precision_score(y_test_limpo_outlier, y_pred)\n",
    "    recall = recall_score(y_test_limpo_outlier, y_pred)\n",
    "    f1 = f1_score(y_test_limpo_outlier, y_pred)\n",
    "    results.append([model_names[i], accuracy, precision, recall, f1])\n",
    "    print(f\"Modelo: {model_names[i]}... treinado e avaliado.\")\n",
    "\n",
    "# --- APRESENTAÇÃO DOS RESULTADOS ---\n",
    "print(\"\\n--- Tabela Comparativa de Resultados do df_limpo após remoção de outliers---\")\n",
    "results_df_limpo = pd.DataFrame(results, columns=['Modelo', 'Acurácia', 'Precisão', 'Recall', 'F1-Score'])\n",
    "results_df_limpo = results_df_limpo.round(3)\n",
    "\n",
    "print(results_df_limpo.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5c700-1c1d-4ea1-a5ad-81d2099a02dc",
   "metadata": {},
   "source": [
    "## df_short após remoção de outlier\n",
    "Vamos testar alguns modelos com o dataframe df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e6d96-2fe5-4ae5-b6ad-18e9b9d1f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  DEFINIÇÃO DOS PIPELINES ---\n",
    "pipe_lr_short = Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression(random_state=35))])\n",
    "pipe_knn_short = Pipeline([('scaler', StandardScaler()), ('model', KNeighborsClassifier())])\n",
    "pipe_rf_short = Pipeline([('scaler', StandardScaler()), ('model', RandomForestClassifier(random_state=35))])\n",
    "pipe_xgb_short = Pipeline([('scaler', StandardScaler()), ('model', XGBClassifier(random_state=35, eval_metric='logloss'))])\n",
    "pipe_svm_short = Pipeline([('scaler', StandardScaler()), ('model', SVC(random_state=35))])\n",
    "\n",
    "pipelines_short = [pipe_lr_short, pipe_knn_short, pipe_rf_short, pipe_xgb_short, pipe_svm_short]\n",
    "model_names = ['Regressão Logística', 'KNN (k-NN)', 'Random Forest', 'XGBoost', 'SVM']\n",
    "\n",
    "# --- TREINAMENTO E AVALIAÇÃO ---\n",
    "print(\"\\n---Treinando e avaliando cada pipeline ---\")\n",
    "results = []\n",
    "for i, pipe in enumerate(pipelines_short):\n",
    "    pipe.fit(X_train_short_outlier, y_train_short_outlier)\n",
    "    y_pred = pipe.predict(X_test_short_outlier)\n",
    "    accuracy = accuracy_score(y_test_short_outlier, y_pred)\n",
    "    precision = precision_score(y_test_short_outlier, y_pred)\n",
    "    recall = recall_score(y_test_short_outlier, y_pred)\n",
    "    f1 = f1_score(y_test_short_outlier, y_pred)\n",
    "    results.append([model_names[i], accuracy, precision, recall, f1])\n",
    "    print(f\"Modelo: {model_names[i]}... treinado e avaliado.\")\n",
    "\n",
    "# --- APRESENTAÇÃO DOS RESULTADOS ---\n",
    "print(\"\\n--- Tabela Comparativa de Resultados do df_short após remoção de outliers---\")\n",
    "results_df_short = pd.DataFrame(results, columns=['Modelo', 'Acurácia', 'Precisão', 'Recall', 'F1-Score'])\n",
    "results_df_short = results_df_short.round(3)\n",
    "\n",
    "print(results_df_short.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31ff16-39b1-46ce-9b50-e18f741611dc",
   "metadata": {},
   "source": [
    "# 6. Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f602c-77e7-487f-b7bb-5c6bf446d4b0",
   "metadata": {},
   "source": [
    "## Análise Comparativa: `df_limpo` vs. `df_short`\n",
    "\n",
    "**Resultados do `df_limpo` (sem `Insulin` e `SkinThickness`)**\n",
    "\n",
    "| Modelo | Acurácia | Precisão | Recall | F1-Score |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| SVM | **0.795**  |  **0.864** |  0.452  |   0.594 |\n",
    "| Regressão Logística | 0.787   |  0.759 |  **0.524**   |  **0.620** |\n",
    "| Random Forest | 0.780  |   0.733  | 0.524   |  0.611 |\n",
    "| XGBoost | 0.748 |    0.679 |  0.452 |    0.543 |\n",
    "| KNN (k-NN) | 0.740  |   0.667  | 0.429  |   0.522 |\n",
    "\n",
    "**Resultados do `df_short` (com `Insulin` e `SkinThickness`)**\n",
    "\n",
    "| Modelo | Acurácia | Precisão | Recall | F1-Score |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| Regressão Logística | **0.794** | 0.667 | **0.700** | **0.683** |\n",
    "| Random Forest | 0.746 | 0.591 | 0.650 | 0.619 |\n",
    "| SVM | 0.746 | 0.600 | 0.600 | 0.600 |\n",
    "| XGBoost | 0.714 | 0.542 | 0.650 | 0.591 |\n",
    "| KNN (k-NN) | 0.698 | 0.524 | 0.550 | 0.537 |\n",
    "\n",
    "\n",
    "### Principais Conclusões e Insights\n",
    "\n",
    "1.  **Melhora Drástica no Recall:**\n",
    "    *   Este é o ganho mais significativo. O **Recall** da Regressão Logística saltou de **0.524 para 0.700**.\n",
    "    *   **Interpretação:** Isso significa que, com as novas features, o modelo agora consegue identificar **70%** dos pacientes que realmente têm diabetes, em comparação com apenas 52% antes. A capacidade do modelo de \"encontrar\" os casos positivos melhorou enormemente. As informações de `Insulin` e `SkinThickness` são claramente cruciais para não deixar diagnósticos passarem despercebidos.\n",
    "\n",
    "2.  **Regressão Logística se Torna o Campeão Indiscutível:**\n",
    "    *   No `df_limpo`, havia uma competição entre SVM (melhor precisão) e Regressão Logística (melhor F1-Score).\n",
    "    *   No `df_short`, a **Regressão Logística** é claramente o melhor modelo em quase todas as métricas importantes: tem a maior Acurácia (empatada), o maior Recall e o maior F1-Score. Seu F1-Score de **0.683** é substancialmente maior que o melhor F1-Score do cenário anterior (0.620).\n",
    "\n",
    "3.  **O Trade-off Precisão-Recall Mudou:**\n",
    "    *   Com o `df_short`, a Precisão da Regressão Logística caiu um pouco (de 0.759 para 0.667). Isso significa que, para conseguir encontrar mais diabéticos (maior Recall), o modelo passou a gerar um pouco mais de falsos positivos.\n",
    "    *   No entanto, o ganho massivo no Recall compensou essa perda, resultando em um F1-Score (o equilíbrio) muito superior. Para um problema de diagnóstico médico, geralmente é preferível ter um Recall mais alto, tornando este um excelente trade-off.\n",
    "\n",
    "4.  **As Novas Features São Valiosas:**\n",
    "    *   A conclusão final é inequívoca: **Sim, as features `Insulin` e `SkinThickness` são extremamente valiosas.** Mesmo que o `df_short` tenha menos amostras no total, a qualidade da informação contida nessas duas colunas adicionais permitiu que o modelo aprendesse padrões muito mais robustos, especialmente para identificar corretamente os casos positivos.\n",
    "\n",
    "## Resumo Estratégico Final\n",
    "\n",
    "O modelo de **Regressão Logística treinado no `df_short`** (com todas as features e após a limpeza de outliers) é, de longe, a melhor solução encontrada. Ele oferece a melhor capacidade de diagnóstico (maior Recall) e o melhor equilíbrio geral de performance (maior F1-Score).\n",
    "\n",
    "Este é um resultado clássico em ciência de dados: a qualidade e a relevância das features (`feature engineering`) muitas vezes superam a complexidade do algoritmo ou até mesmo a quantidade de dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7586bd6-eb45-4aac-9df1-c32fe15a31be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
