{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pontif√≠cia Universidade Cat√≥lica do Paran√°\n",
    "## Disciplina: T√©cnicas de Machine Learning\n",
    "#### Conte√∫do complementar da Semana 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, carregarei todas as bibliotecas necess√°rias para trabalharmos neste notebook. Geralmente n√£o h√° problema algum em voc√™ acabar fazendo alguns imports ao longo do notebook, mas confesso que fica melhor se voc√™ organizar todos os seus imports dentro de uma √∫nica c√©lula.\n",
    "\n",
    "Estarei fazendo alguns coment√°rios (iniciados com `#`) ao lado de cada `import` para lhe explicar para que serve cada biblioteca. Note que voc√™ n√£o √© obrigado a fazer isto para cada biblioteca, mas fa√ßo isto com a inten√ß√£o de lhe explicar. Note que o texto _ap√≥s_ o coment√°rio fica com uma formata√ß√£o diferente: isto serve para que voc√™, ao observar o c√≥digo, j√° consiga visualmente diferenciar o que √© c√≥digo do que n√£o seria um c√≥digo em si."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # biblioteca para o carregamento de datasets a partir de arquivos em Excel, CSV e outros formatos\n",
    "import numpy as np # biblioteca para manipula√ß√£o de vetores e matrizes grandes al√©m de outras manipula√ß√µes de dados de larga escala\n",
    "import matplotlib.cm as mcm # biblioteca para mostrar gr√°ficos (espeficamente uma parte para cores)\n",
    "import matplotlib.pyplot as plt # biblioteca para mostrar gr√°ficos (espeficamente uma parte para criar gr√°ficos)\n",
    "import seaborn as sns # outra biblioteca para mostrar gr√°ficos (ela √© especificamente boa para alguns tipos de gr√°ficos, como mapas de calor)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # importando somente o StandardScaler do scikit-learn\n",
    "from sklearn.datasets import load_wine # importando somente a fun√ß√£o para obtermos o dataset wine (que j√° vem incluso no scikit-learn)\n",
    "from sklearn.feature_selection import * # importando todas as fun√ß√µes espec√≠ficas de sele√ß√£o de atributos do scikit-learn\n",
    "from sklearn.decomposition import * # importando todas as fun√ß√µes espec√≠ficas para a extra√ß√£o de atributos do scikit-learn\n",
    "from sklearn.cluster import * # importando todas as fun√ß√µes espec√≠ficas para o agrupamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset do Campeonato Brasileiro (S√©rie A) de 2020\n",
    "\n",
    "Este dataset serviu para mostrar a import√¢ncia do escalonamento dos dados (isto √©, deix√°-los com uma escala num√©rica similar e compar√°vel) dentro do conte√∫do apresentado. Primeiramente, lemos os dados da tabela do Brasileir√£o os quais est√£o em um arquivo de texto. Voc√™ pode abrir o arquivo dentro do Bloco de Notas ou aplica√ß√£o similar. O separador (isto √©, o que divide os valores) √© o <kbd>Tab</kbd> (tabula√ß√£o).\n",
    "\n",
    "Viu l√° em cima que usamos o `import pandas as pd` ao inv√©s de `import pandas`? O `as pd` serve para que fa√ßamos chamadas de c√≥digo mais enxutas. Logo, √© mais f√°cil digitar `pd.read_csv` do que `pandas.read_csv`.\n",
    "\n",
    "Como o separador √© o <kbd>Tab</kbd>, informamos que o separador (`sep`) √© o <kbd>Tab</kbd>. O operador `\\t` √© outra forma de nos referirmos √† tecla <kbd>Tab</kbd>. Como sabemos disso? <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\">Consultando sempre a documenta√ß√£o do Pandas</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('brasileirao.tsv', sep='\\t') # lendo o arquivo. O resultado ficar√° no dataframe chamado \"df\"\n",
    "df.tail() # o \"tail\" mostra o final do dataset. Se n√£o colocarmos nada entre os par√™nteses teremos por padr√£o as √∫ltimas 5 linhas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compara√ß√£o para a normaliza√ß√£o\n",
    "\n",
    "Aqui, mostrarei dois gr√°ficos: um deles utiliza as colunas `Derrotas` e `Saldo de Gols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5)) #criando uma figura com o mesmo tamanho nos dois eixos (isto √©, uma imagem quadrada)\n",
    "plt.scatter(df['Derrotas'], df['Saldo de Gols'], color=mcm.rainbow(np.linspace(0, 1, 20))) # mostrando um gr√°fico de dispers√£o (scatterplot) onde o eixo x representa os valores da coluna derrotas, o eixo y representa o saldo de gols e, finalmente, colocamos uma escala de cores para as bolinhas. As bolinhas s√£o geradas de acordo com a ordem das linhas no dataframe\n",
    "plt.xlim((-35,25)) # colocamos uma escala num√©rica para o eixo x (opcional, mas aqui √© importante para vermos as diferentes ordens de grandeza)\n",
    "plt.ylim((-35,25)) # colocamos uma escala num√©rica para o eixo y (opcional, mas aqui √© importante para vermos as diferentes ordens de grandeza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, aplicarei o `StandardScaler` para padronizar as duas colunas. No final, mostro o dataset completo. Note que a escala num√©rica dessas duas colunas mudou. Depois, somente rodamos novamente o gr√°fico (agora com os valores j√° padronizados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Derrotas', 'Saldo de Gols']] = StandardScaler().fit_transform(df[['Derrotas', 'Saldo de Gols']])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(df['Derrotas'], df['Saldo de Gols'], color=mcm.rainbow(np.linspace(0, 1, 20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset de vinhos\n",
    "\n",
    "Este dataset serviu para testarmos algumas t√©cnicas de aprendizagem n√£o-supervisionada. <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\">Ele √© um toy dataset que j√° vem incluso no scikit-learn</a>. Note que possui dois atributos adicionais: `as_frame` (o qual estamos usando para que j√° esteja no formato compat√≠vel com o Pandas, o que ajuda muito na visualiza√ß√£o) e `return_X_y` (o qual retorna dois dados somente: o dataframe com os dados de entrada - ou seja, todas as caracter√≠sticas dos vinhos; e os dados de sa√≠da - ou seja, a classe/label que estamos analisando. Aqui, seriam os tr√™s produtores de vinho. O `display` √© uma fun√ß√£o bem parecida com o `print` do Python, mas que permite uma melhor visualiza√ß√£o dentro do Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine, target_wine = load_wine(as_frame=True, return_X_y=True)\n",
    "display(df_wine.tail())\n",
    "display(target_wine.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sele√ß√£o de Atributos\n",
    "### VarianceThreshold\n",
    "Aqui testamos diferentes t√©cnicas na mesma base de dados (o `df_wine`). Primeiro, testamos o <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold\">VarianceThreshold</a>. Como ele somente retorna uma matriz (lembra na disciplina de Racioc√≠nio Computacional?), perdemos os nomes das colunas. Por outro lado, compare os resultados conforme vamos alterando o `threshold` (limite aceit√°vel).\n",
    "\n",
    "Ah, e antes que me esque√ßa: o pd.DataFrame cria um novo dataframe (j√° que o VarianceThreshold retorna uma matriz, como comentei) e contendo somente as colunas que importam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for limite in [0.0, 0.1, 0.5, 0.8, 1.0]:\n",
    "    display(f'Testando com um threshold de {limite}. Resultado:')\n",
    "    sel = VarianceThreshold(threshold=limite)\n",
    "    display(pd.DataFrame(sel.fit_transform(df_wine), columns=df_wine.columns[sel.get_support()]).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembra do `StandardScaler` que vimos h√° pouco? Vamos ver como ficaria com exatamente a mesma tabela, mas ap√≥s us√°-lo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine_scaled = StandardScaler().fit_transform(df_wine)\n",
    "\n",
    "for limite in [0.0, 0.1, 0.5, 0.8, 1.0]:\n",
    "    display(f'Testando com um threshold de {limite} (com StandardScaler). Resultado:')\n",
    "    sel = VarianceThreshold(threshold=limite)\n",
    "    display(pd.DataFrame(sel.fit_transform(df_wine_scaled), columns=df_wine.columns[sel.get_support()]).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest\n",
    "\n",
    "Como j√° criamos o `df_wine_scaled` anteriormente, n√£o precisaremos recri√°-lo aqui. Vamos comparar os resultados do `SelectKBest` para o `df_wine` antes e ap√≥s a sua normaliza√ß√£o. O `.shape` retorna a quantidade de **linhas e colunas** de um dataframe. J√° o `.shape[0]` retorna s√≥ a quantidade de linhas (igual ao `len`, visto em Racioc√≠nio Computacional) e o `shape[1]` retorna s√≥ a quantidade de colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for limite in range(df_wine.shape[1]):\n",
    "    display(f'Testando com um k={limite}. Resultado:')\n",
    "    sel = SelectKBest(k=limite)\n",
    "    display(pd.DataFrame(sel.fit_transform(df_wine, target_wine), columns=df_wine.columns[sel.get_support()]).tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for limite in range(df_wine.shape[1]):\n",
    "    display(f'Testando com um k={limite} (com StandardScaler). Resultado:')\n",
    "    sel = SelectKBest(k=limite)\n",
    "    display(pd.DataFrame(sel.fit_transform(df_wine_scaled, target_wine), columns=df_wine.columns[sel.get_support()]).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for limite in [5, 10, 50, 80, 100]:\n",
    "    display(f'Testando com um percentile={limite}. Resultado:')\n",
    "    sel = SelectPercentile(percentile=limite)\n",
    "    display(pd.DataFrame(sel.fit_transform(df_wine, target_wine), columns=df_wine.columns[sel.get_support()]).tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for limite in [5, 10, 50, 80, 100]:\n",
    "    display(f'Testando com um percentile={limite}. Resultado:')\n",
    "    sel = SelectPercentile(percentile=limite)\n",
    "    display(pd.DataFrame(sel.fit_transform(df_wine_scaled, target_wine), columns=df_wine.columns[sel.get_support()]).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra√ß√£o de atributos\n",
    "### PCA\n",
    "A documenta√ß√£o do scikit-learn possui uma <a href=\"https://scikit-learn.org/stable/modules/decomposition.html\">explica√ß√£o bem interessante sobre PCA</a>, caso tenha interesse. Aqui, o PCA √© basicamente sobre extrair _novos_ atributos a partir dos atributos j√° existentes. Sendo assim, vamos aplicar o PCA no exemplo do wine. Consulte a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA\">documenta√ß√£o espec√≠fica do PCA</a> para entender que tipo de opera√ß√µes seriam poss√≠veis com ele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=df_wine.shape[1]) # colocando que queremos que o n√∫mero de componentes seja igual ao que j√° temos hoje para fins de visualiza√ß√£o e estudo\n",
    "pca.fit(df_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5)) # criando um gr√°fico retangular para facilitar a visualiza√ß√£o\n",
    "plt.plot(pca.explained_variance_ratio_, color='r') # colocando a porcentagem de vari√¢ncia que cada componente nos trouxe\n",
    "plt.xticks(np.arange(df_wine.shape[1])) # mostrando todos os n√∫meros no eixo x\n",
    "plt.show() # mostrando o gr√°fico final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, como interpretamos isso? Existe um m√©todo chamado **elbow method** (ou _m√©todo do cotovelo_) que pode ajudar. Basicamente olhamos da esquerda para direita e paramos quando identificamos um \"cotovelo\" no gr√°fico: isto √©, indo para a direita ver√≠amos que n√£o ter√≠amos mais grandes altera√ß√µes na curva indicando, assim, que haver√≠amos chegado √† quantidade ideal de componentes e n√£o valeria o esfor√ßo selecionarmos mais componentes. Olhando para o gr√°fico acima fica f√°cil: √† direita do **1** no eixo x n√£o vemos uma mudan√ßa no comportamento: logo, os componentes 0 e 1 seriam os mais adequados (em outras palavras, somente 2 componentes).\n",
    "\n",
    "Por outro lado, o componente 0 parece ser estranhamente relevante em rela√ß√£o aos demais, n√£o √©? Olhando a documenta√ß√£o do scikit-learn sobre o PCA encontramos um item interessante chamado `components_`. Com ele, conseguimos ver a contribui√ß√£o de cada um dos atributos (abaixo representados pelas linhas) sobre os componentes (representados abaixo pelas colunas). Note que no componente **0** temos um valor bem destoante do `flavanoids` em rela√ß√£o aos demais. Isto indicaria que somente esta coluna impactaria muito para detectar o produtor de um vinho. Ser√° que √© _s√≥ isso mesmo_ que influencia? Pensemos em um caso real: ser√° que para tomarmos decis√µes n√£o acabamos olhando para um conjunto de atributos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "sns.heatmap(pd.DataFrame(pca.components_, index=df_wine.columns), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√° que n√£o faltaria normalizarmos os dados? Vejamos o mesmo PCA, mas agora com o `df_wine_scaled`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=df_wine_scaled.shape[1])\n",
    "pca.fit(df_wine_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5)) # criando um gr√°fico retangular para facilitar a visualiza√ß√£o\n",
    "plt.plot(pca.explained_variance_ratio_, color='r') # colocando a porcentagem de vari√¢ncia que cada componente nos trouxe\n",
    "plt.xticks(np.arange(df_wine.shape[1])) # mostrando todos os n√∫meros no eixo x\n",
    "plt.show() # mostrando o gr√°fico final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece mais justo, n√£o √©? Podemos ter um elbow j√° no **3** (ou seja, 4 componentes) ou, ainda, l√° no **7** (ou seja, 8 componentes j√° que a contagem come√ßou no 0 e n√£o no 1). Em casos reais geralmente queremos menos componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "sns.heatmap(pd.DataFrame(pca.components_, index=df_wine.columns), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhor! Veja que no primeiro componente temos uma contribui√ß√£o de fatores liderados pelo `proanthocyanins` e `malic_acid`. J√° no segundo componente, `total_phenols`, `flavanoids`, `alcalinity_of_ash` e, em menor escala, `color_intensity`. J√° no terceiro componente, `ash` e `hue` (de forma antag√¥nica - veja que um √© positivo e outro com sinal negativo). No quarto, `ash`, `hue` e `nonflanavoid_phenols` (agora com `ash` e `hue` com o mesmo sinal). Veja que todas as colunas influenciam em maior ou menor grau nos componentes.\n",
    "\n",
    "De forma geral, √© poss√≠vel darmos um nome para os componentes de acordo com as colunas que mais trazem impacto e a rela√ß√£o entre elas: olhemos o componente **7**: os `flavanoids`, `magnesium` e `alcohol` trazem os maiores impactos. Os `flavanoids` s√£o respons√°veis (pelo que pesquisei rapidamente no Google) pela cor v√≠vida nos alimentos e bebidas; `magnesium` √© um metal importante para o nosso corpo e √© presente no vinho; e o `alcohol` √© a porcentagem de √°lcool na bebida. Aqui, vemos que um vinho com um alto n√∫mero neste componente seria provavelmente um vinho de cor v√≠vida (pela alta influ√™ncia dos `flavanoids` e por ter sinal positivo), com baixo teor alco√≥lico e n√≠veis de magn√©sio (visto pelo sinal negativo, mas alta representatividade destes valores). Logo, quem sabe n√£o poder√≠amos renomear este componente **7** para **cor_vivida_baixo_alcool_e_manganes**? Sim, n√£o √© um nome nada inspirado - mas creio que conseguiu captar a ideia.\n",
    "\n",
    "Finalmente, caso tenha interesse em ver o resultado final do PCA: observe como ficaria abaixo a tabela gerada com **4** componentes escolhidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "pd.DataFrame(pca.fit_transform(df_wine_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al√©m disso, vamos mostrar de forma gr√°fica como o PCA pode ajudar (e outras t√©cnicas de sele√ß√£o de atributos tamb√©m). O `pairplot` √© uma visualiza√ß√£o a qual compara todos os atributos contra todos os atributos. Como nosso c√©rebro visualiza at√© 3 dimens√µes, para vermos mais do que isso precisamos recorrer para t√©cnicas como esta. Veja que cada bolinha representa um produtor diferente. Note, ainda, que para algumas colunas conseguimos ver que h√° uma *certa* divis√£o entre os diferentes produtores, mas em outras fica dif√≠cil de fazermos esta separa√ß√£o.\n",
    "\n",
    "Ora, se at√© para n√≥s humanos √© dif√≠cil de nos acharmos aqui com a _consci√™ncia_ de que estamos analisando vinhos, imagine ent√£o como seria para um algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine_plot = df_wine.copy() # criando uma c√≥pia do df_wine para fins de visualiza√ß√£o\n",
    "df_wine_plot['class'] = target_wine # colocando os produtores dentro desta c√≥pia para podermos separ√°-los no gr√°fico\n",
    "sns.pairplot(df_wine_plot, hue='class') # criando o pairplot e dividindo por cor de produtor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora olhe para o mesmo `pairplot`, agora com o PCA aplicado. Tire as suas pr√≥prias conclus√µes. ü§ê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_resultado = pd.DataFrame(pca.fit_transform(df_wine_scaled))\n",
    "df_pca_resultado['class'] = target_wine\n",
    "sns.pairplot(df_pca_resultado, hue='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupamento\n",
    "### KMeans e MiniBatchKMeans\n",
    "\n",
    "O KMeans √© a t√©cnica mais conhecida de agrupamento (lembrando que agora estamos falando de agrupar **inst√¢ncias**, e n√£o **atributos**). Neste caso e de forma similar ao que j√° fizemos anteriormente, aplicaremos o KMeans para o `df_wine`. Note que ele agrupa todos os dados dispon√≠veis para a sua an√°lise: logo, n√£o √© legal colocarmos uma classe/label no meio desta an√°lise.\n",
    "\n",
    "Al√©m disso, o `MiniBatchKMeans` √© efetivamente o `KMeans` para grandes bases de dados. Logo, nos concentraremos somente no `KMeans`. Note que ele possui um par√¢metro chamado `random_state`: ele √© o que chamamos tamb√©m de _seed_: um c√≥digo aleat√≥rio que define um ponto de partida aleat√≥rio. Aqui, deixamos um valor fixo para que toda execu√ß√£o tenha o mesmo resultado, n√£o importando de qual computador fa√ßamos os testes.\n",
    "\n",
    "Finalmente, para fins de visualiza√ß√£o (lembra que o `sns.pairplot` com todas as colunas ficou gigante, certo?) estaremos j√° aplicando o `SelectKBest` para reduzir a quantidade de colunas sendo analisadas e colocadas em gr√°fico. Note tamb√©m que estamos usando o `df_wine_scaled` como base da an√°lise ao inv√©s do `df_wine`: isto se d√° porque precisamos que eles tenham uma mesma escala num√©rica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectKBest(k=5)\n",
    "df_wine_kbest = pd.DataFrame(sel.fit_transform(df_wine_scaled, target_wine), columns=df_wine.columns[sel.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    display(f'Resultados do KMeans com k={i}')\n",
    "    df_wine_kmeans = df_wine_kbest.copy()\n",
    "    kmeans = KMeans(n_clusters=i, random_state=0).fit(df_wine_kmeans)\n",
    "    df_wine_kmeans['cluster'] = kmeans.predict(df_wine_kmeans)\n",
    "\n",
    "    sns.pairplot(df_wine_kmeans, hue='cluster')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN\n",
    "\n",
    "O DBSCAN busca primeiramente encontrar exemplos que est√£o bem juntos/unidos/colados e, a partir da√≠, come√ßa a encontrar os seus _vizinhos_. Ao contr√°rio do KMeans, n√£o requer um n√∫mero de grupos/clusters. Todos os elementos que segundo ele n√£o seriam membros de um cluster em espec√≠fico ficariam dentro do cluster **-1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine_dbscan = df_wine_kbest.copy()\n",
    "df_wine_dbscan['cluster'] = DBSCAN().fit_predict(df_wine_dbscan)\n",
    "\n",
    "sns.pairplot(df_wine_dbscan, hue='cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTICS\n",
    "\n",
    "O OPTICS √© similar ao DBSCAN, mas pode levar a um agrupamento diferente uma vez que gera um c√°lculo que pode acabar por penalizar alguns elementos que n√£o possuem tantos exemplos similares. Todos os elementos que segundo ele n√£o seriam membros de um cluster em espec√≠fico ficariam dentro do cluster **-1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine_optics = df_wine_kbest.copy()\n",
    "df_wine_optics['cluster'] = OPTICS().fit_predict(df_wine_optics)\n",
    "\n",
    "sns.pairplot(df_wine_optics, hue='cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
