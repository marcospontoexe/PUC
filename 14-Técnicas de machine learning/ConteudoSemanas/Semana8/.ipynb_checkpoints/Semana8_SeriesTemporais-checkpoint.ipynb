{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pontifícia Universidade Católica do Paraná\n",
    "## Disciplina: Técnicas de Machine Learning\n",
    "#### Conteúdo complementar da Semana 5 - Séries Temporais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia deste notebook é a de realizarmos o processo de treinamento e previsão de séries temporais.\n",
    "\n",
    "Como comentamos nos últimos notebooks, sempre que tiver uma dúvida sobre alguma função em específico encorajamos que busque nas documentações. O exercício de sempre consultar a documentação é parte do dia-a-dia de um profissional de TI e, portanto, vale a pena colocarmos em prática quando possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose # utilizado para realizar a decomposição de séries temporais\n",
    "\n",
    "from prophet import Prophet # utilizado para séries temporais\n",
    "from sklearn.model_selection import train_test_split # utilizado para o split entre treinamento e teste\n",
    "from sklearn.ensemble import RandomForestRegressor # random forest para regressão\n",
    "from pmdarima.arima import auto_arima # utilizado para treinar o AutoARIMA\n",
    "\n",
    "import pandas as pd # importando o pandas para manipularmos os datasets\n",
    "import numpy as np # importando o numpy para realizar manipulações de vetores\n",
    "import matplotlib.pyplot as plt # utilizado para a geração de gráficos\n",
    "import seaborn as sns # utilizado para a geração de gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o seasonal_decompose usa o tamanho padrão (quadrado) de imagem do Matplotlib, o que acaba sendo pequeno demais para o nosso caso\n",
    "# logo, estamos alterando o tamanho padrão dos gráficos\n",
    "plt.rc('figure', figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura da base de dados\n",
    "O dataset ```df_dolar``` contém todas as cotações do dólar entre 2021-05-12 e 2021-06-11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tipo do dataset: Data        object\n",
      "Cotacao    float64\n",
      "dtype: object\n",
      "\n",
      "tipo do dataset após conversão: Data       datetime64[ns]\n",
      "Cotacao           float64\n",
      "dtype: object\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Cotacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>5.8856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>5.8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>5.8115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>5.8554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>5.7190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>5.0451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>5.0325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>5.0621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>5.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>5.1171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data  Cotacao\n",
       "279 2020-05-12   5.8856\n",
       "278 2020-05-13   5.8852\n",
       "277 2020-05-14   5.8115\n",
       "276 2020-05-15   5.8554\n",
       "275 2020-05-18   5.7190\n",
       "..         ...      ...\n",
       "4   2021-06-07   5.0451\n",
       "3   2021-06-08   5.0325\n",
       "2   2021-06-09   5.0621\n",
       "1   2021-06-10   5.0552\n",
       "0   2021-06-11   5.1171\n",
       "\n",
       "[280 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dolar = pd.read_csv('dolar.tsv', sep='\\t').sort_values(by='Data') # ordenando primeiro pela data mais antiga\n",
    "\n",
    "# a coluna Data é do tipo objeto, isso é interpretado como texto\n",
    "print(f\"\\ntipo do dataset: {df_dolar.dtypes}\") \n",
    "\n",
    "# Convertemos a coluna Data para o tipo datetime\n",
    "df_dolar['Data'] = pd.to_datetime(df_dolar['Data'])\n",
    "print(f\"\\ntipo do dataset após conversão: {df_dolar.dtypes}\\n\")\n",
    "df_dolar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposição de séries temporais\n",
    "Para que a decomposição dê certo, o ```seasonal_decompose``` espera que o índice seja a data e que o dataset esteja ordenado da data mais antiga para a data mais recente. Logo, faremos as devidas alterações para que isto aconteça utilizando o ```set_index``` (para que o índice passe a ser a coluna Data) e ```sort_index``` (para ordenar da maneira correta).\n",
    "\n",
    "Depois, vamos mostrar dois exemplos de decomposição: um utilizando somente abril de 2021 e parte de maio de 2021 (que utilizamos na unidade) e outro contendo todo o histórico. Para todo o histórico, estamos informando uma periodicidade de 7 dias. Compare os resultados entre ambos. Se possível, teste diferentes valores no ```period```. O que acontecerá se você mudar para 5? 14? 30? 90?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dolar_decompose = df_dolar.copy()\n",
    "# Configura a coluna Data para ser a coluna de índice, e ordena em ordem cronologica\n",
    "df_dolar_decompose = df_dolar_decompose.set_index('Data').sort_index()\n",
    "df_dolar_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = seasonal_decompose(df_dolar_decompose[(df_dolar_decompose.index>='2021-04-01') & (df_dolar_decompose.index<='2021-05-14')]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = seasonal_decompose(df_dolar_decompose, period=7).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão\n",
    "\n",
    "Vamos criar um modelo de regressão para esta base. Como vimos que há uma sazonalidade a cada sete dias (aproximadamente), usaremos um ***sliding window*** de ```7``` dias. Faremos isto com a ajuda da função <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shift.html\">shift</a>, do Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dolar_ml = df_dolar\n",
    "\n",
    "for lag in range(1, 8):\n",
    "    col = f'Cotacao_-{lag}'\n",
    "    df_dolar_ml[col] = df_dolar_ml['Cotacao'].shift(lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fins de demonstração, também incluiremos duas novas colunas: uma, utilizando a ***média móvel*** dos últimos ```7``` dias com a função <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html\">rolling</a>, do Pandas, combinado com a função <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html\">mean</a>. A combinação dos dois basicamente captura os últimos ```7``` valores e calcula a média deles. O ```shift(1)``` desloca em um dia para que a cotação do dia atual não seja calculada em conjunto.\n",
    "\n",
    "Finalmente, o <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.dayofweek.html\">dayofweek</a> obtém o dia da semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Gerando a média móvel.')\n",
    "df_dolar_ml['MediaMovel7Dias'] = df_dolar_ml['Cotacao'].shift(1).rolling(7).mean()\n",
    "df_dolar_ml['DiaSemana'] = df_dolar_ml['Data'].dt.dayofweek\n",
    "df_dolar_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos remover agora as colunas com dados nulos (no caso, estes primeiros dias com esta <em>\"escadinha\"</em> de ```NaN```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dolar_ml = df_dolar_ml.dropna()\n",
    "df_dolar_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento e teste\n",
    "\n",
    "Agora, para o treinamento consideramos todos os dias com a exceção dos últimos 30 dias. Como a base de dados já está ordenada por data, separaremos as últimas 30 linhas para o teste com a função <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.iloc.html\">iloc</a>. Vamos usar o ```RandomForestRegressor``` para o treinamento. A coluna da ```Data``` será removida já que o algoritmo poderia não ser treinado adequadamente com esta coluna. Compare as previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dolar_ml.drop(['Cotacao', 'Data'], axis=1)\n",
    "y = df_dolar_ml['Cotacao']\n",
    "\n",
    "X_train = X.iloc[:-30]\n",
    "y_train = y.iloc[:-30]\n",
    "\n",
    "X_test = X.iloc[-30:]\n",
    "y_test = y.iloc[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestRegressor(random_state=0).fit(X_train, y_train)\n",
    "df_previsoes_rf = pd.DataFrame(np.array([y_test.values, model_rf.predict(X_test)]).T, columns=['Real', 'Previsão (Random Forest)'])\n",
    "df_previsoes_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet\n",
    "\n",
    "Vamos fazer a mesma previsão, mas agora via Prophet. Da mesma forma que fizemos na regressão separaremos os últimos ```30``` dias para o backtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dolar_ml = df_dolar.sort_values(by='Data').rename(columns={'Data': 'ds', 'Cotacao': 'y'}) # ordenando primeiro pela data mais antiga e renomeando as colunas\n",
    "\n",
    "df_train = df_dolar_ml.iloc[:-30]\n",
    "df_test = df_dolar_ml.iloc[-30:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fins de teste, criaremos dois modelos do Prophet: um contendo todo o histórico e outro contendo somente os últimos ```60``` dias da base de treinamento.\n",
    "\n",
    "Observe também os resultados que o algoritmo forneceu - as previsões estão na coluna ```yhat```. O intervalo de confiança é representado pelas colunas ```yhat_lower``` e ```yhat_upper```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prophet_todo_historico = Prophet().fit(df_train) # treinando o Prophet\n",
    "previsoes_prophet_todo_historico = model_prophet_todo_historico.predict(df_test) # gerando as predições\n",
    "previsoes_prophet_todo_historico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prophet_ultimos_dois_meses = Prophet().fit(df_train.iloc[-60:]) # treinando o Prophet\n",
    "previsoes_prophet_ultimos_dois_meses = model_prophet_ultimos_dois_meses.predict(df_test) # gerando as predições\n",
    "previsoes_prophet_ultimos_dois_meses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe os resultados. O que observa os últimos 60 dias aparenta começar mais próximo da realidade, mas também se perde no futuro. Já o que considera todo o histórico aparenta ser bem pessimista. Na documentação do Prophet existem algumas configurações (as quais chamamos de **hiperparâmetros**) que ajudam a melhor calibrar o modelo.\n",
    "\n",
    "Existem casos nos quais o Prophet é melhor do que um modelo de regressão ou um ARIMA, e vice-versa. Na prática, é um trabalho de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previsoes_prophet = pd.DataFrame(np.array([df_test['y'].values,\n",
    "                                              previsoes_prophet_todo_historico['yhat'],\n",
    "                                              previsoes_prophet_ultimos_dois_meses['yhat']]).T,\n",
    "                                    columns=['Real', 'Previsão (Prophet, Todo Histórico)', 'Previsão (Prophet, Últimos 60 Dias)'])\n",
    "df_previsoes_prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA\n",
    "\n",
    "Finalmente, demonstraremos um exemplo de uso do ARIMA. Para nos aproximarmos do mundo de ML ao invés de irmos para a Estatística teremos como foco o <a href=\"https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html#pmdarima-arima-auto-arima\">AutoARIMA</a>, ok? Por outro lado, lembre-se: o uso do ARIMA aqui serve tão somente para um propósito informacional na disciplina. Caso tenha interesse sugerimos ler a documentação do AutoARIMA com calma.\n",
    "\n",
    "Note que o resultado do AutoARIMA para este caso foi um ```order=(1, 0, 0)```, o que também é chamado de ```AR(1)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_dolar['Cotacao'].iloc[:-30]\n",
    "y_test = df_dolar['Cotacao'].iloc[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arima = auto_arima(y_train)\n",
    "model_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previsoes_autoarima = pd.DataFrame(np.array([y_test.values,\n",
    "                                                model_arima.predict(n_periods=30)]).T,\n",
    "                                      columns=['Real', 'Previsão (AutoARIMA)'])\n",
    "df_previsoes_autoarima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostrando os resultados\n",
    "\n",
    "Agora, vamos mostrar os resultados de cada uma das técnicas. Analise os seguintes pontos:\n",
    " - Os modelos dão previsões mais corretas para os primeiros dias (curto prazo) ou bem no futuro (longo prazo)?\n",
    " - Existem pontos fortes e pontos fracos nas previsões dos modelos?\n",
    " - Provavelmente o modelo que ficou mais próximo da realidade foi o RandomForest, mas ele sempre possui o que aconteceu no dia anterior. Já os outros modelos possuem menos informações para gerar os próximos 30 dias. Sendo assim, como alteraríamos o nosso dataset para que o RandomForest pudesse prever dois dias à frente? Ou três dias à frente? Ou mais dias à frente?\n",
    " - Será que o ARIMA teria resultados diferentes se mudássemos os seus parâmetros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dolar.iloc[-30:]['Data'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para criar o gráfico usaremos a função <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html\">melt</a>. Ela pegará todas as colunas de previsões e agrupará dentro de uma coluna única contendo todos os valores e outra coluna contendo os tipos dos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unindo as tabelas\n",
    "df_previsoes = df_previsoes_rf.merge(df_previsoes_prophet, on='Real').merge(df_previsoes_autoarima, on='Real')\n",
    "df_previsoes['Data'] = df_dolar.iloc[-30:]['Data'].values\n",
    "df_previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previsoes = df_previsoes.melt(id_vars='Data')\n",
    "df_previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.lineplot(data=df_dolar.iloc[:-30], x='Data', y='Cotacao')\n",
    "sns.lineplot(data=df_previsoes, x='Data', y='value', hue='variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
