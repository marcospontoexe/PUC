{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8d9f14f-5242-4707-889a-14b80cf55478",
   "metadata": {},
   "source": [
    "# Atividade Somativa 2\n",
    "\n",
    "O objetivo dessa atividade é usar um mode preditivo. Como o dataser escolhido foi o **seoul_bike_data**, que contém dados horários sobre o aluguel de bicicletas públicas em Seul, capital da Coreia do Sul, cobrindo um período de um ano (de 1º de dezembro de 2017 a 30 de novembro de 2018), usaremos um modelo preditivo de regressão para prever a demanda de bicicletas alugadas.\n",
    "\n",
    "## Visão Geral do Dataset\n",
    "O objetivo principal ao usar este dataset é prever a demanda por bicicletas alugadas (Rented Bike Count) com base em variáveis como; temperatura, quantidade de chuva, de neve, de radiação solar, de humidade, entre outras variáveis disponíveis no dataset.\n",
    "\n",
    "Começaremos montando uma sequencia básica;\n",
    "1. Carregar o dataset.\n",
    "2. Limpeza de dataset.\n",
    "   * Remoção de atributos correlacionados.\n",
    "   * Remoção de instâncias vazias ou duplicadas.\n",
    "3. Divisão do dataset para dados de treino, validação de early stopping e de teste.\n",
    "4. Preparação dos dados (X_train -> X_train_early_stp -> X_train_limpo -> X_train_vt/X_train_kbest/X_train_kbest_mutual -> X_train_kbest_limpo).\n",
    "   * Remoção de outliers.\n",
    "   * seleção de atributos.\n",
    "   * Padronização.\n",
    "5. Treinamento do modelo XGBoost.\n",
    "6. Analise de resultado do xgboost.\n",
    "7. Uso de Pipeline para analise de outros modelos.\n",
    "8. Analise de resultado dos pipelines.\n",
    "9. Otimizando hiperparametros.\n",
    "10. Conclusões finais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92e58c4-1875-4f61-a90c-fb8f7623196e",
   "metadata": {},
   "source": [
    "# 1. Carregando o Dataset\n",
    "\n",
    "Vamos carregar o dataset em um dataframe e analisar seus features.\n",
    "\n",
    "O dataset é composto por 8.760 linhas (24 horas por dia × 365 dias) e 14 colunas. As colunas são:\n",
    "\n",
    "| Nome da Coluna | Descrição | Tipo de Dado | Exemplo |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **DateTime** | A data e hora do registro. | Objeto/Texto | 01/12/20172017-01-12 00:00:00 |\n",
    "| **Day** | Dia do registro. | Numérico (Inteiro) | 01|\n",
    "| **Weekday** | Dia da semana. | Numérico (Inteiro) | 7 |\n",
    "| **Hour** | A hora do dia (0 a 23). | Numérico (Inteiro) | 0, 1, 2, ... |\n",
    "| **Rented Bike Count** | **(Variável Alvo)** O número de bicicletas alugadas em uma determinada hora. | Numérico (Inteiro) | 254 |\n",
    "| **Temperature(°C)** | A temperatura em graus Celsius. | Numérico (Float) | -5.2 |\n",
    "| **Humidity(%)** | A umidade relativa do ar em porcentagem. | Numérico (Inteiro) | 37 |\n",
    "| **Wind speed (m/s)** | A velocidade do vento em metros por segundo. | Numérico (Float) | 2.2 |\n",
    "| **Visibility (10m)** | A visibilidade em uma escala de 10 metros (ex: 2000 significa 20km). | Numérico (Inteiro) | 2000 |\n",
    "| **Dew point temp(°C)** | A temperatura do ponto de orvalho em graus Celsius. | Numérico (Float) | -17.6 |\n",
    "| **Solar Radiation (MJ/m2)**| A radiação solar. Geralmente é zero durante a noite. | Numérico (Float) | 0.0 |\n",
    "| **Rainfall(mm)** | A quantidade de chuva em milímetros. | Numérico (Float) | 0.0 |\n",
    "| **Snowfall (cm)** | A quantidade de neve em centímetros. | Numérico (Float) | 0.0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f3514-bb7c-45f1-af5e-ab8023670bd6",
   "metadata": {},
   "source": [
    "## Bibliotecas \n",
    "Vamos começar importando as blibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30cfd46a-043d-4ad4-abac-25c986dee44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd # importando o pandas para manipularmos o dataset\n",
    "from ydata_profiling import ProfileReport # importando o pandas-profiling para fazer o profile do dataset\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # utilizado para o split entre treinamento e teste e para a otimização de hiperparâmetros\n",
    "import xgboost as xgb  # XGBoost para regressão\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler # importando somente o StandardScaler do scikit-learn\n",
    "from sklearn.pipeline import Pipeline # utilizado para criar pipelines\n",
    "from sklearn.metrics import * # importando todas as funções de métricas do scikit-learn\n",
    "from sklearn.feature_selection import * # importando todas as funções específicas de seleção de atributos do scikit-learn\n",
    "\n",
    "from sklearn import set_config # utilizado para mostrar os passos do pipeline de forma visual\n",
    "set_config(display='diagram') # forçando para que os passos do pipeline sejam mostrados em visual\n",
    "\n",
    "# forçando a saída do pandas para que somente 3 dígitos sejam mostrados no lugar da notação científica\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db3665a-9f1d-42df-8cb3-654c37083404",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97d3cc-bfe3-4bd8-baff-65f8453d8e5e",
   "metadata": {},
   "source": [
    "Agora vamos importar o dataset para um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0512aa8e-55d7-4d4f-9a29-e074701696d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostra dos dados (primeiras 5 linhas):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-12 00:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>-5.200</td>\n",
       "      <td>37</td>\n",
       "      <td>2.200</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-12 01:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>-5.500</td>\n",
       "      <td>38</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-12 02:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>39</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-12 03:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>-6.200</td>\n",
       "      <td>40</td>\n",
       "      <td>0.900</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-12 04:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>78</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>36</td>\n",
       "      <td>2.300</td>\n",
       "      <td>2000</td>\n",
       "      <td>-18.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DateTime  Day  Weekday  Hour  Rented Bike Count  \\\n",
       "0  2017-01-12 00:00:00   12        5     0                254   \n",
       "1  2017-01-12 01:00:00   12        5     1                204   \n",
       "2  2017-01-12 02:00:00   12        5     2                173   \n",
       "3  2017-01-12 03:00:00   12        5     3                107   \n",
       "4  2017-01-12 04:00:00   12        5     4                 78   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Wind speed (m/s)  Visibility (10m)  \\\n",
       "0           -5.200           37             2.200              2000   \n",
       "1           -5.500           38             0.800              2000   \n",
       "2           -6.000           39             1.000              2000   \n",
       "3           -6.200           40             0.900              2000   \n",
       "4           -6.000           36             2.300              2000   \n",
       "\n",
       "   Dew point temperature(°C)  Solar Radiation (MJ/m2)  Rainfall(mm)  \\\n",
       "0                    -17.600                    0.000         0.000   \n",
       "1                    -17.600                    0.000         0.000   \n",
       "2                    -17.700                    0.000         0.000   \n",
       "3                    -17.600                    0.000         0.000   \n",
       "4                    -18.600                    0.000         0.000   \n",
       "\n",
       "   Snowfall (cm)  \n",
       "0          0.000  \n",
       "1          0.000  \n",
       "2          0.000  \n",
       "3          0.000  \n",
       "4          0.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informações gerais sobre o DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8760 entries, 0 to 8759\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   DateTime                   8760 non-null   object \n",
      " 1   Day                        8760 non-null   int64  \n",
      " 2   Weekday                    8760 non-null   int64  \n",
      " 3   Hour                       8760 non-null   int64  \n",
      " 4   Rented Bike Count          8760 non-null   int64  \n",
      " 5   Temperature(°C)            8760 non-null   float64\n",
      " 6   Humidity(%)                8760 non-null   int64  \n",
      " 7   Wind speed (m/s)           8760 non-null   float64\n",
      " 8   Visibility (10m)           8760 non-null   int64  \n",
      " 9   Dew point temperature(°C)  8760 non-null   float64\n",
      " 10  Solar Radiation (MJ/m2)    8760 non-null   float64\n",
      " 11  Rainfall(mm)               8760 non-null   float64\n",
      " 12  Snowfall (cm)              8760 non-null   float64\n",
      "dtypes: float64(6), int64(6), object(1)\n",
      "memory usage: 889.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bike = pd.read_excel('seoul_bike_data.xlsx')\n",
    "    \n",
    "print(\"Amostra dos dados (primeiras 5 linhas):\")\n",
    "display(df_bike.head())\n",
    "\n",
    "print(\"\\nInformações gerais sobre o DataFrame:\")\n",
    "df_bike.info()\n",
    "\n",
    "#profile = ProfileReport(df_bike)\n",
    "#profile.to_file(\"relatorio.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59720e6-05b1-484c-91d6-71e76f33bd85",
   "metadata": {},
   "source": [
    "# 2. Limpeza do dataset\n",
    "Ao analisando a tabela de correlação estre as variáveis com a ferramenta **ydata_profiling**, foi possível notar o seguinte:\n",
    "\n",
    "## Análise de Redundância (Multicolinearidade)\n",
    "\n",
    "Este é o primeiro passo: encontrar atributos que medem quase a mesma coisa.\n",
    "\n",
    "*   **`Temperature(°C)` vs. `Dew point temperature(°C)`: Correlação de 0.912**\n",
    "    *   **Análise:** Este é um valor de correlação **extremamente alto**. Como esperado, a temperatura e a temperatura do ponto de orvalho estão fortemente ligadas. Manter ambas no modelo é redundante e pode confundir alguns algoritmos.\n",
    "    *   **Ação Recomendada:** **remover uma dessas duas colunas**. Mas qual? Para decidir, olhamos a correlação de cada uma com a nossa variável alvo, `Rented Bike Count`.\n",
    "        *   Correlação de `Temperature` com `Rented Bike Count` = **0.565**\n",
    "        *   Correlação de `Dew point temperature` com `Rented Bike Count` = **0.374**\n",
    "    *   **Decisão:** A `Temperature(°C)` tem uma correlação muito mais forte com o número de bicicletas alugadas. Portanto, **mantenha `Temperature(°C)` e removemos `Dew point temperature(°C)`**.\n",
    "\n",
    "## Análise do Poder Preditivo (Relação com `Rented Bike Count`)\n",
    "\n",
    "Agora, vamos focar na linha/coluna `Rented Bike Count` para ver quais atributos são os melhores preditores.\n",
    "\n",
    "**Correlações Positivas (Quando estes aumentam, a demanda tende a aumentar):**\n",
    "\n",
    "*   **`Temperature(°C)` (0.565):** Esta é a **correlação mais forte** com a variável alvo. Confirma a intuição de que a demanda por bicicletas aumenta significativamente com a temperatura. Este é o seu preditor mais importante.\n",
    "*   **`Hour` (0.389):** Uma correlação positiva forte. Isso indica que, ao longo do dia (das 0h às 23h), há uma tendência geral de aumento na demanda, provavelmente devido aos picos da tarde/noite. A hora do dia é um preditor crucial.\n",
    "*   **`Solar Radiation (MJ/m2)` (0.382):** Também uma correlação forte. Mais radiação solar significa um dia ensolarado e agradável, o que incentiva o uso de bicicletas.\n",
    "*   **`Visibility (10m)` (0.176):** Correlação positiva, mas mais fraca. Melhor visibilidade (menos neblina) está associada a um leve aumento no número de aluguéis.\n",
    "*   **`Wind speed (m/s)` (0.148):** Correlação positiva fraca. Isso é um pouco contraintuitivo, pois esperaríamos que ventos fortes desincentivassem o ciclismo. Essa correlação fraca pode indicar uma relação não-linear (ex: um pouco de vento é agradável, mas muito vento é ruim).\n",
    "\n",
    "**Correlações Negativas (Quando estes aumentam, a demanda tende a diminuir):**\n",
    "\n",
    "*   **`Rainfall(mm)` (-0.282):** Uma correlação negativa moderada. Como esperado, quando chove, as pessoas alugam menos bicicletas.\n",
    "*   **`Snowfall (cm)` (-0.221):** Correlação negativa moderada. Similar à chuva, a neve também desincentiva o uso de bicicletas.\n",
    "*   **`Humidity(%)` (-0.221):** Correlação negativa moderada. Alta umidade (clima abafado ou úmido) está associada a uma menor demanda.\n",
    "\n",
    "**Correlações Próximas de Zero (Pouco Poder Preditivo Linear):**\n",
    "\n",
    "*   **`Day` (0.067)** e **`Weekday` (0.062):** Essas colunas têm uma correlação linear muito fraca com a demanda. Isso **não significa que elas são inúteis!** Significa apenas que a relação não é uma linha reta simples (ex: a demanda não aumenta linearmente de segunda para domingo). O dia da semana (`Weekday`) é quase certamente um preditor muito importante devido à diferença de padrão entre dias úteis (picos de deslocamento) e fins de semana (uso para lazer). Modelos baseados em árvores (como RandomForest) conseguirão capturar essa relação complexa.\n",
    "\n",
    "## Resumo e Próximos Passos\n",
    "\n",
    "1. **Ação Imediata:** Remover a coluna `Dew point temperature(°C)` do dataset para eliminar a redundância.\n",
    "2. **Preditores Mais Fortes:** Os atributos mais importantes são `Temperature(°C)`, `Hour` e `Solar Radiation (MJ/m2)`.\n",
    "3. **Preditores Relevantes:** `Rainfall(mm)`, `Snowfall (cm)` e `Humidity(%)` também são importantes e devem ser mantidos.\n",
    "4. **Não se Engane com Correlação Baixa:** Mantemos `Weekday` e `Hour`. Apesar da correlação linear baixa, eles contêm padrões cíclicos (diários e semanais) que são fundamentais para o problema e serão capturados por modelos mais sofisticados.\n",
    "5. **Valores não numéricos:**: O algoritmo aprende com números, não podemos passar os atributos da coluna **DateTime**, então devemos excluir essa coluna da nossa base de dados.\n",
    "6. **Limpeza de instancias (linhas):** Não é necessário fazer nenhuma limpeza de instancias no dataframe, pois analizando como ydata_profiling foi verificado que não existe nenuma linha duplicada, NaN ou em branco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69857350-6235-4ba5-aa7c-7cc170c32def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe após a remoção das colunas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>-5.200</td>\n",
       "      <td>37</td>\n",
       "      <td>2.200</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>-5.500</td>\n",
       "      <td>38</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>39</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>-6.200</td>\n",
       "      <td>40</td>\n",
       "      <td>0.900</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>78</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>36</td>\n",
       "      <td>2.300</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>163</td>\n",
       "      <td>0.000</td>\n",
       "      <td>31</td>\n",
       "      <td>2.200</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>161</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>32</td>\n",
       "      <td>0.900</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>179</td>\n",
       "      <td>-1.600</td>\n",
       "      <td>35</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>155</td>\n",
       "      <td>-2.100</td>\n",
       "      <td>36</td>\n",
       "      <td>1.700</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>227</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>40</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Day  Weekday  Hour  Rented Bike Count  Temperature(°C)  Humidity(%)  \\\n",
       "0      12        5     0                254           -5.200           37   \n",
       "1      12        5     1                204           -5.500           38   \n",
       "2      12        5     2                173           -6.000           39   \n",
       "3      12        5     3                107           -6.200           40   \n",
       "4      12        5     4                 78           -6.000           36   \n",
       "...   ...      ...   ...                ...              ...          ...   \n",
       "8755   31        2    19                163            0.000           31   \n",
       "8756   31        2    20                161           -1.000           32   \n",
       "8757   31        2    21                179           -1.600           35   \n",
       "8758   31        2    22                155           -2.100           36   \n",
       "8759   31        2    23                227           -2.600           40   \n",
       "\n",
       "      Wind speed (m/s)  Visibility (10m)  Solar Radiation (MJ/m2)  \\\n",
       "0                2.200              2000                    0.000   \n",
       "1                0.800              2000                    0.000   \n",
       "2                1.000              2000                    0.000   \n",
       "3                0.900              2000                    0.000   \n",
       "4                2.300              2000                    0.000   \n",
       "...                ...               ...                      ...   \n",
       "8755             2.200              2000                    0.000   \n",
       "8756             0.900              2000                    0.000   \n",
       "8757             1.000              2000                    0.000   \n",
       "8758             1.700              2000                    0.000   \n",
       "8759             0.600              2000                    0.000   \n",
       "\n",
       "      Rainfall(mm)  Snowfall (cm)  \n",
       "0            0.000          0.000  \n",
       "1            0.000          0.000  \n",
       "2            0.000          0.000  \n",
       "3            0.000          0.000  \n",
       "4            0.000          0.000  \n",
       "...            ...            ...  \n",
       "8755         0.000          0.000  \n",
       "8756         0.000          0.000  \n",
       "8757         0.000          0.000  \n",
       "8758         0.000          0.000  \n",
       "8759         0.000          0.000  \n",
       "\n",
       "[8760 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removendos as colunas desnecessárias\n",
    "df_bike = df_bike.drop(['DateTime', 'Dew point temperature(°C)'], axis=1)\n",
    "#df_bike = df_bike.drop(['DateTime', 'Day', 'Dew point temperature(°C)', 'Weekday', 'Wind speed (m/s)'], axis=1)\n",
    "\n",
    "print(\"Dataframe após a remoção das colunas:\")\n",
    "df_bike"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd3653-7a21-4648-8f6c-5b959fab181b",
   "metadata": {},
   "source": [
    "# 3. Divisão do dataset\n",
    "Agora vamos dividir o dataset em três base de dados;\n",
    "* Treinamento: Para treinar as árvores\n",
    "* Validação (ou eval_set) para o Early Stopping: Para monitorar a performance e decidir quando parar. \n",
    "* Teste: Para a avaliação final.\n",
    "\n",
    "## Early Stopping\n",
    "O Early Stopping (Parada Antecipada) é uma técnica de regularização extremamente poderosa e prática, usada para encontrar o número ideal de **n_estimators** e, ao mesmo tempo, prevenir o overfitting. Permite que você defina um n_estimators bem alto e, então, monitora a performance do modelo em um conjunto de dados de validação, parando o treinamento automaticamente quando a performance para de melhorar.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f06cfd8a-ae53-4952-9bba-c961dc3f8270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões dos conjuntos:\n",
      "dataset original (8760, 11)\n",
      "X_train_early_stp: (5256, 10) | y_train_early_stp: (5256,)\n",
      "X_val: (1752, 10)   | y_val: (1752,)\n",
      "X_test: (1752, 10)  | y_test: (1752,)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Primeiro, dividimos em treino+validação (80%) e teste (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_bike.drop(['Rented Bike Count'], axis=1),   # remove as colunas label \n",
    "    df_bike['Rented Bike Count'],   # Coluna que será usada como label de classificação\n",
    "    test_size=0.2,  # informamos a porcentagem de divisão para a base de testes.\n",
    "    random_state=35  # aqui informamos um \"seed\".\n",
    ")\n",
    "\n",
    "# Agora, dividimos o conjunto temporário em treino (75% de 80% = 60% do total) \n",
    "# e validação (25% de 80% = 20% do total)\n",
    "X_train_early_stp, X_val, y_train_early_stp, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=35\n",
    ")\n",
    "\n",
    "print(\"Dimensões dos conjuntos:\")\n",
    "print(\"dataset original\", df_bike.shape)\n",
    "print(\"X_train_early_stp:\", X_train_early_stp.shape, \"| y_train_early_stp:\", y_train_early_stp.shape)\n",
    "print(\"X_val:\", X_val.shape, \"  | y_val:\", y_val.shape)\n",
    "print(\"X_test:\", X_test.shape, \" | y_test:\", y_test.shape)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a27b5-b3de-4670-93e3-54c3e833e423",
   "metadata": {},
   "source": [
    "# 4. Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447579ad-2b31-48eb-9d31-d1b2c3a0f068",
   "metadata": {},
   "source": [
    "## Remoção de Outliers\n",
    "Os outliers são prejudiciais para o processo de normalização ou padronização do dataset, então vamos verificar os outliers e remove-los.\n",
    "\n",
    "1. Identifique os outliers no dataset de treino (usando o método IQR, por exemplo).\n",
    "2. Defina os limites (limite inferior e superior) com base no dataset de treino.\n",
    "3. Aplique esses mesmos limites para remover (ou tratar) os outliers no dataset de teste. É crucial usar os limites do treino para todos os conjuntos.\n",
    "\n",
    "### Por que é Errado Calcular os Limites de Outliers em Cada Conjunto Separadamente?\n",
    "Isso é uma forma sutil de vazamento de dados (data leakage). Se você calcular os limites do IQR para X_train, e depois recalcular novos limites para X_test, você está usando informações de X_test (sua distribuição, seus quartis) para decidir como processá-lo.\n",
    "\n",
    "Lembre-se, o conjunto de teste deve ser tratado como se fosse completamente desconhecido até o momento da avaliação final. Você não pode usar nenhuma informação dele para tomar decisões de pré-processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff141ed-71b3-42ea-9694-a0e994e77a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Aprendendo os limites dos outliers com o conjunto de treino ---\n",
      "Coluna 'Temperature(°C)': Limites calculados = [-25.04, 51.06]\n",
      "Coluna 'Humidity(%)': Limites calculados = [-6.00, 122.00]\n",
      "Coluna 'Wind speed (m/s)': Limites calculados = [-1.20, 4.40]\n",
      "Coluna 'Visibility (10m)': Limites calculados = [-637.50, 3582.50]\n",
      "Coluna 'Solar Radiation (MJ/m2)': Limites calculados = [-1.40, 2.33]\n",
      "\n",
      "--- Removendo outliers ---\n",
      "\n",
      "--- Comparação de Tamanhos (Antes vs. Depois) ---\n",
      "Tamanho de X_train: 7008 -> 6390 (removidos 618 outliers)\n",
      "Tamanho de X_train_early_stp_limpo: 5256 -> 4786 (removidos 470 outliers)\n",
      "Tamanho de X_val:   1752 -> 1604 (removidos 148 outliers)\n",
      "Tamanho de X_test:  1752 -> 1599 (removidos 153 outliers)\n",
      "\n",
      "--- Amostra do DataFrame de Treino Limpo ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.300</td>\n",
       "      <td>45</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6921</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10.100</td>\n",
       "      <td>60</td>\n",
       "      <td>0.800</td>\n",
       "      <td>726</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>-15.300</td>\n",
       "      <td>47</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>59</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1948</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>9.700</td>\n",
       "      <td>56</td>\n",
       "      <td>1.300</td>\n",
       "      <td>1423</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Day  Weekday  Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  \\\n",
       "2785   19        5     1            9.300           45             0.800   \n",
       "6921   14        1     9           10.100           60             0.800   \n",
       "894    27        7     6          -15.300           47             0.700   \n",
       "320     2        3     8           -8.600           59             1.000   \n",
       "1271   11        1    23            9.700           56             1.300   \n",
       "\n",
       "      Visibility (10m)  Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm)  \n",
       "2785              1263                    0.000         0.000          0.000  \n",
       "6921               726                    1.020         0.000          0.000  \n",
       "894               1921                    0.000         0.000          0.300  \n",
       "320               1948                    0.010         0.000          1.600  \n",
       "1271              1423                    0.000         0.000          0.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---  Tratamento de Outliers ---\n",
    "\n",
    "\n",
    "# --- IDENTIFICAR AS COLUNAS PARA VERIFICAR OUTLIERS ---\n",
    "# Vamos focar nas colunas numéricas contínuas onde outliers são mais prováveis e problemáticos.\n",
    "# Colunas como 'Day', 'Weekday', 'Hour' são mais categóricas/ordinais e geralmente não são tratadas para outliers.\n",
    "# As colunas Rainfall e Snowfall são compostas com mais de 90% das amostras com valores zerados, oque significa que quase não teve\n",
    "# dias com chuva ou neve, mas isso pode acontecer, então não são tratadas para outliers\n",
    "colunas_para_verificar = ['Temperature(°C)', 'Humidity(%)', 'Wind speed (m/s)', \n",
    "                          'Visibility (10m)', 'Solar Radiation (MJ/m2)']\n",
    "\n",
    "\n",
    "# ---  APRENDER OS LIMITES DOS OUTLIERS APENAS COM O CONJUNTO DE TREINO ---\n",
    "print(\"--- Aprendendo os limites dos outliers com o conjunto de treino ---\")\n",
    "limites = {}\n",
    "\n",
    "for coluna in colunas_para_verificar:\n",
    "    Q1 = X_train[coluna].quantile(0.25)\n",
    "    Q3 = X_train[coluna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    limites[coluna] = (limite_inferior, limite_superior)\n",
    "    print(f\"Coluna '{coluna}': Limites calculados = [{limite_inferior:.2f}, {limite_superior:.2f}]\")\n",
    "\n",
    "    \n",
    "# --- APLICAR OS FILTROS A TODOS OS CONJUNTOS DE DADOS ---\n",
    "\n",
    "# Criar uma cópia para não modificar os dataframes originais\n",
    "X_train_limpo = X_train.copy()\n",
    "y_train_limpo = y_train.copy()\n",
    "X_train_early_stp_limpo = X_train_early_stp.copy()\n",
    "y_train_early_stp_limpo = y_train_early_stp.copy()\n",
    "X_val_limpo = X_val.copy()\n",
    "y_val_limpo = y_val.copy()\n",
    "X_test_limpo = X_test.copy()\n",
    "y_test_limpo = y_test.copy()\n",
    "\n",
    "print(\"\\n--- Removendo outliers ---\")\n",
    "for coluna in colunas_para_verificar:\n",
    "    limite_inf, limite_sup = limites[coluna]\n",
    "    \n",
    "    # Criar máscaras booleanas para cada conjunto de dados\n",
    "    mascara_train = (X_train_limpo[coluna] >= limite_inf) & (X_train_limpo[coluna] <= limite_sup)\n",
    "    mascara_train_early_stp = (X_train_early_stp_limpo[coluna] >= limite_inf) & (X_train_early_stp_limpo[coluna] <= limite_sup)\n",
    "    mascara_val = (X_val_limpo[coluna] >= limite_inf) & (X_val_limpo[coluna] <= limite_sup)\n",
    "    mascara_test = (X_test_limpo[coluna] >= limite_inf) & (X_test_limpo[coluna] <= limite_sup)\n",
    "    \n",
    "    # Aplicar as máscaras para filtrar os dataframes\n",
    "    X_train_limpo = X_train_limpo[mascara_train]\n",
    "    y_train_limpo = y_train_limpo[mascara_train]\n",
    "\n",
    "    X_train_early_stp_limpo = X_train_early_stp_limpo[mascara_train_early_stp]\n",
    "    y_train_early_stp_limpo = y_train_early_stp_limpo[mascara_train_early_stp]\n",
    "    \n",
    "    X_val_limpo = X_val_limpo[mascara_val]\n",
    "    y_val_limpo = y_val_limpo[mascara_val]\n",
    "    \n",
    "    X_test_limpo = X_test_limpo[mascara_test]\n",
    "    y_test_limpo = y_test_limpo[mascara_test]\n",
    "\n",
    "\n",
    "# ---  VERIFICAR O RESULTADO ---\n",
    "print(\"\\n--- Comparação de Tamanhos (Antes vs. Depois) ---\")\n",
    "print(f\"Tamanho de X_train: {len(X_train)} -> {len(X_train_limpo)} (removidos {len(X_train) - len(X_train_limpo)} outliers)\")\n",
    "print(f\"Tamanho de X_train_early_stp_limpo: {len(X_train_early_stp)} -> {len(X_train_early_stp_limpo)} (removidos {len(X_train_early_stp) - len(X_train_early_stp_limpo)} outliers)\")\n",
    "print(f\"Tamanho de X_val:   {len(X_val)} -> {len(X_val_limpo)} (removidos {len(X_val) - len(X_val_limpo)} outliers)\")\n",
    "print(f\"Tamanho de X_test:  {len(X_test)} -> {len(X_test_limpo)} (removidos {len(X_test) - len(X_test_limpo)} outliers)\")\n",
    "\n",
    "print(\"\\n--- Amostra do DataFrame de Treino Limpo ---\")\n",
    "display(X_train_limpo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85081056-881e-4907-9230-45ece3497869",
   "metadata": {},
   "source": [
    "\n",
    "## Seleção de Atributos\n",
    "Por que é a melhor abordagem inicial para este dataset?\n",
    "\n",
    "1. Alta Redundância nos Dados: O dataset possui colunas que são naturalmente correlacionadas e podem carregar informações muito similares. O exemplo mais claro é entre **Temperature(°C)** e **Dew point temperature(°C)** (Temperatura do Ponto de Orvalho). A temperatura do ponto de orvalho é diretamente derivada da temperatura e da umidade. Manter ambas pode ser redundante para muitos modelos. A Seleção de Atributos pode ajudar a identificar e remover uma delas sem grande perda de informação. Alem  de outros atributos que tem baixa correlação com a atributo a ser predito (**Rented Bike Count**).\n",
    "2. Manutenção da Interpretabilidade: Esta é a maior vantagem. Ao selecionar atributos, você continua trabalhando com as colunas originais (Temperature, Wind speed, Hour, etc.). Isso significa que, ao final, você pode analisar o seu modelo e dizer: \"A temperatura e a hora do dia foram os fatores mais importantes para prever a demanda\". Essa interpretabilidade é crucial para gerar insights de negócio e entender o \"porquê\" por trás das previsões.\n",
    "\n",
    "### VarianceThreshold\n",
    "Se uma feature (coluna) não varia muito, ela não contém muita informação e, portanto, provavelmente não é útil para um modelo preditivo. Em outras palavras, ele remove todas as features cuja variância não atinge um determinado limiar (threshold). \n",
    "\n",
    "Um **threshold=0** significa que será removido apenas as colunas com valores constantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "390260c7-1cb1-4830-ad1e-585a5107643d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variância de cada coluna do dataset de treino:\n",
      "Day                           76.489\n",
      "Weekday                        4.051\n",
      "Hour                          51.442\n",
      "Temperature(°C)              137.060\n",
      "Humidity(%)                  402.164\n",
      "Wind speed (m/s)               0.878\n",
      "Visibility (10m)          375622.761\n",
      "Solar Radiation (MJ/m2)        0.393\n",
      "Rainfall(mm)                   1.324\n",
      "Snowfall (cm)                  0.194\n",
      "dtype: float64\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# vamos verificar qual é a variancia de cada coluna\n",
    "print(\"\\nVariância de cada coluna do dataset de treino:\")\n",
    "print(X_train_limpo.var())\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2132afec-2666-45fb-882b-699abbaacecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato de X_train após VarianceThreshold:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>19.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9.300</td>\n",
       "      <td>45.000</td>\n",
       "      <td>1263.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6921</th>\n",
       "      <td>14.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>10.100</td>\n",
       "      <td>60.000</td>\n",
       "      <td>726.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>27.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>-15.300</td>\n",
       "      <td>47.000</td>\n",
       "      <td>1921.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>59.000</td>\n",
       "      <td>1948.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>11.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>9.700</td>\n",
       "      <td>56.000</td>\n",
       "      <td>1423.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>11.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>8.900</td>\n",
       "      <td>67.000</td>\n",
       "      <td>578.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>28.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>10.800</td>\n",
       "      <td>78.000</td>\n",
       "      <td>335.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>23.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>13.600</td>\n",
       "      <td>70.000</td>\n",
       "      <td>1392.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>13.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>2.400</td>\n",
       "      <td>59.000</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>28.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>23.100</td>\n",
       "      <td>94.000</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6390 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Day  Weekday   Hour  Temperature(°C)  Humidity(%)  Visibility (10m)  \\\n",
       "2785 19.000    5.000  1.000            9.300       45.000          1263.000   \n",
       "6921 14.000    1.000  9.000           10.100       60.000           726.000   \n",
       "894  27.000    7.000  6.000          -15.300       47.000          1921.000   \n",
       "320   2.000    3.000  8.000           -8.600       59.000          1948.000   \n",
       "1271 11.000    1.000 23.000            9.700       56.000          1423.000   \n",
       "...     ...      ...    ...              ...          ...               ...   \n",
       "3321 11.000    6.000  9.000            8.900       67.000           578.000   \n",
       "3007 28.000    7.000  7.000           10.800       78.000           335.000   \n",
       "7148 23.000    3.000 20.000           13.600       70.000          1392.000   \n",
       "1295 13.000    3.000 23.000            2.400       59.000          2000.000   \n",
       "5833 28.000    3.000  1.000           23.100       94.000          2000.000   \n",
       "\n",
       "      Rainfall(mm)  \n",
       "2785         0.000  \n",
       "6921         0.000  \n",
       "894          0.000  \n",
       "320          0.000  \n",
       "1271         0.000  \n",
       "...            ...  \n",
       "3321         0.000  \n",
       "3007         0.000  \n",
       "7148         0.000  \n",
       "1295         0.000  \n",
       "5833         0.000  \n",
       "\n",
       "[6390 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=1) \n",
    "\n",
    "# Aprender com o dataset de trein \n",
    "X_train_vt_array = selector.fit_transform(X_train_limpo)\n",
    "# O resultado é um array NumPy. Vamos convertê-lo de volta para um DataFrame\n",
    "# para melhor visualização, usando os nomes das colunas selecionadas.\n",
    "colunas = selector.get_feature_names_out()\n",
    "X_train_vt = pd.DataFrame(data=X_train_vt_array, columns=colunas, index=X_train_limpo.index)\n",
    "\n",
    "# transformar todos outros dataset com os valores aprendidos com o dataset de treino\n",
    "X_train_early_stp_vt_array = selector.transform(X_train_early_stp_limpo)\n",
    "X_train_early_stp_vt = pd.DataFrame(data=X_train_early_stp_vt_array, columns=colunas, index=X_train_early_stp_limpo.index)\n",
    "\n",
    "X_val_vt_array = selector.transform(X_val_limpo)\n",
    "X_val_vt = pd.DataFrame(data=X_val_vt_array, columns=colunas, index=X_val_limpo.index)\n",
    "\n",
    "X_test_vt_array = selector.transform(X_test_limpo)\n",
    "X_test_vt = pd.DataFrame(data=X_test_vt_array, columns=colunas, index=X_test_limpo.index)\n",
    "\n",
    "print(\"Formato de X_train após VarianceThreshold:\")\n",
    "X_train_vt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ae2b3-9e5c-44cd-b3f5-86a0ba5f436f",
   "metadata": {},
   "source": [
    "### SelectKBest \n",
    "Seleciona um número fixo (K) de features com as maiores pontuações no teste estatístico.\n",
    "\n",
    "Para Problemas de Regressão:\n",
    "* **f_regression** (Padrão): Calcula a correlação entre cada feature (X) e a variável alvo (y) e converte isso em um valor-F estatístico. Essencialmente, ele pontua mais alto as features que têm uma relação linear mais forte com o alvo.\n",
    "* **mutual_info_regression**: Mede a \"informação mútua\" entre cada feature e o alvo. É mais poderoso que f_regression porque consegue capturar relações não-lineares também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7808965-946b-4b00-a951-196430d2124a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame de Treino após SelectKBest ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>1.000</td>\n",
       "      <td>9.300</td>\n",
       "      <td>45.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1263.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6921</th>\n",
       "      <td>9.000</td>\n",
       "      <td>10.100</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>726.000</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>6.000</td>\n",
       "      <td>-15.300</td>\n",
       "      <td>47.000</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1921.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>8.000</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>59.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1948.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>23.000</td>\n",
       "      <td>9.700</td>\n",
       "      <td>56.000</td>\n",
       "      <td>1.300</td>\n",
       "      <td>1423.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>9.000</td>\n",
       "      <td>8.900</td>\n",
       "      <td>67.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>578.000</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>7.000</td>\n",
       "      <td>10.800</td>\n",
       "      <td>78.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>335.000</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>20.000</td>\n",
       "      <td>13.600</td>\n",
       "      <td>70.000</td>\n",
       "      <td>1.400</td>\n",
       "      <td>1392.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>23.000</td>\n",
       "      <td>2.400</td>\n",
       "      <td>59.000</td>\n",
       "      <td>3.200</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>1.000</td>\n",
       "      <td>23.100</td>\n",
       "      <td>94.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6390 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  Visibility (10m)  \\\n",
       "2785  1.000            9.300       45.000             0.800          1263.000   \n",
       "6921  9.000           10.100       60.000             0.800           726.000   \n",
       "894   6.000          -15.300       47.000             0.700          1921.000   \n",
       "320   8.000           -8.600       59.000             1.000          1948.000   \n",
       "1271 23.000            9.700       56.000             1.300          1423.000   \n",
       "...     ...              ...          ...               ...               ...   \n",
       "3321  9.000            8.900       67.000             1.100           578.000   \n",
       "3007  7.000           10.800       78.000             0.500           335.000   \n",
       "7148 20.000           13.600       70.000             1.400          1392.000   \n",
       "1295 23.000            2.400       59.000             3.200          2000.000   \n",
       "5833  1.000           23.100       94.000             0.600          2000.000   \n",
       "\n",
       "      Solar Radiation (MJ/m2)  Snowfall (cm)  \n",
       "2785                    0.000          0.000  \n",
       "6921                    1.020          0.000  \n",
       "894                     0.000          0.300  \n",
       "320                     0.010          1.600  \n",
       "1271                    0.000          0.000  \n",
       "...                       ...            ...  \n",
       "3321                    0.690          0.000  \n",
       "3007                    0.260          0.000  \n",
       "7148                    0.000          0.000  \n",
       "1295                    0.000          0.000  \n",
       "5833                    0.000          0.000  \n",
       "\n",
       "[6390 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando a função f_regression do seletor\n",
    "col = 7\n",
    "selector_kbest = SelectKBest(score_func=f_regression, k=col)  # vamos escolher as 8 melhores colunas\n",
    "\n",
    "# Aprender quais são as melhores features com os dados de treino\n",
    "X_train_kbest_array = selector_kbest.fit_transform(X_train_limpo, y_train_limpo)\n",
    "\n",
    "# Obter os nomes das colunas mantidas\n",
    "colunas_selecionadas_nomes = selector_kbest.get_feature_names_out()\n",
    "\n",
    "# Transformar o X_train_limpo para conter apenas as features selecionadas\n",
    "X_train_kbest = pd.DataFrame(\n",
    "    data=X_train_kbest_array, \n",
    "    columns=colunas_selecionadas_nomes, \n",
    "    index=X_train_limpo.index\n",
    ")\n",
    "\n",
    "# Transformar o X_train_early_stp_limpo para conter apenas as features selecionadas\n",
    "X_train_early_stp_limpo_kbest_array = selector_kbest.transform(X_train_early_stp_limpo)\n",
    "# Criar o novo DataFrame (esta parte agora funciona corretamente)\n",
    "X_train_early_stp_kbest = pd.DataFrame(\n",
    "    data=X_train_early_stp_limpo_kbest_array, \n",
    "    columns=colunas_selecionadas_nomes, \n",
    "    index=X_train_early_stp_limpo.index\n",
    ")\n",
    "\n",
    "# Transformar o X_val_limpo para conter apenas as features selecionadas\n",
    "X_val_limpo_kbest_array = selector_kbest.transform(X_val_limpo)\n",
    "# Criar o novo DataFrame (esta parte agora funciona corretamente)\n",
    "X_val_kbest = pd.DataFrame(\n",
    "    data=X_val_limpo_kbest_array, \n",
    "    columns=colunas_selecionadas_nomes, \n",
    "    index=X_val_limpo.index\n",
    ")\n",
    "\n",
    "# Transformar o X_test_limpo para conter apenas as features selecionadas\n",
    "X_test_limpo_kbest_array = selector_kbest.transform(X_test_limpo)\n",
    "# Criar o novo DataFrame (esta parte agora funciona corretamente)\n",
    "X_test_kbest = pd.DataFrame(\n",
    "    data=X_test_limpo_kbest_array, \n",
    "    columns=colunas_selecionadas_nomes, \n",
    "    index=X_test_limpo.index\n",
    ")\n",
    "\n",
    "\n",
    "# ---  VERIFICAR O RESULTADO ---\n",
    "print(\"--- DataFrame de Treino após SelectKBest ---\")\n",
    "X_train_kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a16326-8103-44e9-bea6-808e8d52c9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame de Treino após SelectKBest ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>19.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9.300</td>\n",
       "      <td>45.000</td>\n",
       "      <td>1263.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6921</th>\n",
       "      <td>14.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>10.100</td>\n",
       "      <td>60.000</td>\n",
       "      <td>726.000</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>27.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>-15.300</td>\n",
       "      <td>47.000</td>\n",
       "      <td>1921.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>59.000</td>\n",
       "      <td>1948.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>11.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>9.700</td>\n",
       "      <td>56.000</td>\n",
       "      <td>1423.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>11.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>8.900</td>\n",
       "      <td>67.000</td>\n",
       "      <td>578.000</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>28.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>10.800</td>\n",
       "      <td>78.000</td>\n",
       "      <td>335.000</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>23.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>13.600</td>\n",
       "      <td>70.000</td>\n",
       "      <td>1392.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>13.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>2.400</td>\n",
       "      <td>59.000</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>28.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>23.100</td>\n",
       "      <td>94.000</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6390 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  Visibility (10m)  \\\n",
       "2785 19.000            1.000        9.300            45.000          1263.000   \n",
       "6921 14.000            9.000       10.100            60.000           726.000   \n",
       "894  27.000            6.000      -15.300            47.000          1921.000   \n",
       "320   2.000            8.000       -8.600            59.000          1948.000   \n",
       "1271 11.000           23.000        9.700            56.000          1423.000   \n",
       "...     ...              ...          ...               ...               ...   \n",
       "3321 11.000            9.000        8.900            67.000           578.000   \n",
       "3007 28.000            7.000       10.800            78.000           335.000   \n",
       "7148 23.000           20.000       13.600            70.000          1392.000   \n",
       "1295 13.000           23.000        2.400            59.000          2000.000   \n",
       "5833 28.000            1.000       23.100            94.000          2000.000   \n",
       "\n",
       "      Solar Radiation (MJ/m2)  Snowfall (cm)  \n",
       "2785                    0.000          0.000  \n",
       "6921                    1.020          0.000  \n",
       "894                     0.000          0.000  \n",
       "320                     0.010          0.000  \n",
       "1271                    0.000          0.000  \n",
       "...                       ...            ...  \n",
       "3321                    0.690          0.000  \n",
       "3007                    0.260          0.000  \n",
       "7148                    0.000          0.000  \n",
       "1295                    0.000          0.000  \n",
       "5833                    0.000          0.000  \n",
       "\n",
       "[6390 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando a função mutual_info_regression do seletor\n",
    "col = 7\n",
    "selector_kbest_mutual = SelectKBest(score_func=mutual_info_regression, k=col)  # vamos escolher as 8 melhores colunas\n",
    "\n",
    "# Aprender quais são as melhores features com os dados de treino\n",
    "X_train_kbest_mutual_array = selector_kbest_mutual.fit_transform(X_train_limpo, y_train_limpo)\n",
    "\n",
    "# Obter os nomes das colunas mantidas\n",
    "colunas_selecionadas_nomes_mutual = selector_kbest_mutual.get_feature_names_out()\n",
    "\n",
    "# Transformar o X_train_limpo para conter apenas as features selecionadas\n",
    "X_train_kbest_mutual = pd.DataFrame(\n",
    "    data=X_train_kbest_mutual_array, \n",
    "    columns=colunas_selecionadas_nomes, \n",
    "    index=X_train_limpo.index\n",
    ")\n",
    "\n",
    "# Transformar o X_train_early_stp_limpo para conter apenas as features selecionadas\n",
    "X_train_early_stp_limpo_kbest_mutual_array = selector_kbest_mutual.transform(X_train_early_stp_limpo)\n",
    "# Criar o novo DataFrame (esta parte agora funciona corretamente)\n",
    "X_train_early_stp_kbest_mutual = pd.DataFrame(\n",
    "    data=X_train_early_stp_limpo_kbest_mutual_array, \n",
    "    columns=colunas_selecionadas_nomes, \n",
    "    index=X_train_early_stp_limpo.index\n",
    ")\n",
    "\n",
    "# Transformar o X_val_limpo para conter apenas as features selecionadas\n",
    "X_val_limpo_kbest_mutual_array = selector_kbest_mutual.transform(X_val_limpo)\n",
    "# Criar o novo DataFrame (esta parte agora funciona corretamente)\n",
    "X_val_kbest_mutual = pd.DataFrame(\n",
    "    data=X_val_limpo_kbest_mutual_array, \n",
    "    columns=colunas_selecionadas_nomes, \n",
    "    index=X_val_limpo.index\n",
    ")\n",
    "\n",
    "# Transformar o X_test_limpo para conter apenas as features selecionadas\n",
    "X_test_limpo_kbest_mutual_array = selector_kbest_mutual.transform(X_test_limpo)\n",
    "# Criar o novo DataFrame (esta parte agora funciona corretamente)\n",
    "X_test_kbest_mutual = pd.DataFrame(\n",
    "    data=X_test_limpo_kbest_mutual_array, \n",
    "    columns=colunas_selecionadas_nomes, \n",
    "    index=X_test_limpo.index\n",
    ")\n",
    "\n",
    "\n",
    "# ---  VERIFICAR O RESULTADO ---\n",
    "print(\"--- DataFrame de Treino após SelectKBest ---\")\n",
    "X_train_kbest_mutual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb03be48-f29a-4c67-82ec-ee08a3f40dba",
   "metadata": {},
   "source": [
    "## Normalização ou padronização\n",
    "Algoritmos da fámilia Symbolists (Árvores de Decisão, Random Forest, XGBoost, LightGBM...) não são sensíveis à escala das features, portanto não exigem normalização. Eles funcionam fazendo \"perguntas\" sobre os dados, como \"A Temperature é maior que 15°C?\". Essa pergunta funciona da mesma forma, não importa se as outras features estão em escalas diferentes. Eles são imunes à escala das features.\n",
    "\n",
    "Por que não é necessário?\n",
    "\n",
    "Esses modelos tomam decisões com base em regras ou divisões nos dados, e a escala de uma feature não afeta onde essas divisões são feitas.\n",
    "\n",
    "Porém, a variância é dependente da escala dos dados. Uma feature salário em Reais terá uma variância muito maior do que uma feature idade em anos, simplesmente por causa da escala. Portanto é uma boa prática sempre normalizar um dataset.\n",
    "\n",
    "### StandardScaler (Padronização):\n",
    "**O que faz?** Transforma os dados para que tenham uma média de 0 e um desvio padrão de 1. Isso é chamado de padronização. Os valores resultantes não ficam em um intervalo fixo (podem ser negativos ou positivos, como -1.5, 0.2, 2.1, etc.).\n",
    "\n",
    "**Quando usar?** É a escolha mais comum e robusta. Funciona bem para a maioria dos algoritmos, especialmente aqueles que assumem que os dados seguem uma distribuição normal (Gaussiana), como a Regressão Linear. É menos sensível a outliers do que o MinMaxScaler.\n",
    "\n",
    "### MinMaxScaler (Normalização para um Intervalo):\n",
    "**O que faz?** Transforma os dados para que todos os valores fiquem em um intervalo específico, geralmente entre 0 e 1.\n",
    "\n",
    "**Quando usar?** É muito útil para algoritmos que esperam dados em um intervalo pequeno e fixo, como Redes Neurais (especialmente com funções de ativação como a sigmoide). Também é bom para visualizações.\n",
    "\n",
    "**Cuidado:** É muito sensível a outliers. Se você tiver um valor extremo, ele pode \"espremer\" todos os outros dados em um intervalo muito pequeno, prejudicando a performance.\n",
    "\n",
    "### Como Aplicar a Normalização Corretamente\n",
    "A regra de ouro da normalização (e de todo o pré-processamento) é: você deve aprender os parâmetros da normalização (média, desvio padrão, etc.) APENAS no conjunto de treinamento e, em seguida, aplicar essa mesma transformação aos conjuntos de validação e teste.\n",
    "\n",
    "Isso evita o vazamento de dados (**data leakage**), onde informações do conjunto de teste \"vazam\" para o processo de treinamento, resultando em uma avaliação de performance otimista e irreal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ac3639e-9730-49c9-a078-e329d3ee7cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizando o conjunto de treinamento...\n",
      "Normalizando o conjunto de teste...\n",
      "Normalizando o conjunto de treinamento usando no metodo Early Stopping...\n",
      "Normalizando o conjunto de validação usado no Early Stopping...\n",
      "\n",
      "Normalização concluída!\n",
      "\n",
      "--- Amostra do DataFrame de Treino ANTES da Normalização ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.300</td>\n",
       "      <td>45</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6921</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10.100</td>\n",
       "      <td>60</td>\n",
       "      <td>0.800</td>\n",
       "      <td>726</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>-15.300</td>\n",
       "      <td>47</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>-8.600</td>\n",
       "      <td>59</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1948</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>9.700</td>\n",
       "      <td>56</td>\n",
       "      <td>1.300</td>\n",
       "      <td>1423</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Day  Weekday  Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  \\\n",
       "2785   19        5     1            9.300           45             0.800   \n",
       "6921   14        1     9           10.100           60             0.800   \n",
       "894    27        7     6          -15.300           47             0.700   \n",
       "320     2        3     8           -8.600           59             1.000   \n",
       "1271   11        1    23            9.700           56             1.300   \n",
       "\n",
       "      Visibility (10m)  Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm)  \n",
       "2785              1263                    0.000         0.000          0.000  \n",
       "6921               726                    1.020         0.000          0.000  \n",
       "894               1921                    0.000         0.000          0.300  \n",
       "320               1948                    0.010         0.000          1.600  \n",
       "1271              1423                    0.000         0.000          0.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra do DataFrame de Treino DEPOIS da Normalização ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>-1.438</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>-0.870</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6921</th>\n",
       "      <td>-0.322</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.870</td>\n",
       "      <td>-1.133</td>\n",
       "      <td>1.002</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>-0.741</td>\n",
       "      <td>-2.350</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>0.817</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-0.462</td>\n",
       "      <td>-1.777</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>0.861</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>3.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>1.630</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  Visibility (10m)  \\\n",
       "2785 -1.438           -0.248       -0.745            -0.870            -0.257   \n",
       "6921 -0.322           -0.180        0.003            -0.870            -1.133   \n",
       "894  -0.741           -2.350       -0.646            -0.977             0.817   \n",
       "320  -0.462           -1.777       -0.047            -0.657             0.861   \n",
       "1271  1.630           -0.214       -0.197            -0.337             0.005   \n",
       "\n",
       "      Solar Radiation (MJ/m2)  Snowfall (cm)  \n",
       "2785                   -0.625         -0.172  \n",
       "6921                    1.002         -0.172  \n",
       "894                    -0.625          0.508  \n",
       "320                    -0.610          3.457  \n",
       "1271                   -0.625         -0.172  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra do DataFrame de Teste ANTES da Normalização ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14.100</td>\n",
       "      <td>25</td>\n",
       "      <td>1.800</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>12.200</td>\n",
       "      <td>47</td>\n",
       "      <td>2.600</td>\n",
       "      <td>1427</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6536</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>14.800</td>\n",
       "      <td>51</td>\n",
       "      <td>1.100</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>35.300</td>\n",
       "      <td>45</td>\n",
       "      <td>1.700</td>\n",
       "      <td>1829</td>\n",
       "      <td>2.270</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>23.300</td>\n",
       "      <td>68</td>\n",
       "      <td>3.600</td>\n",
       "      <td>895</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Day  Weekday  Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  \\\n",
       "2665   14        7     1           14.100           25             1.800   \n",
       "7650   14        4    18           12.200           47             2.600   \n",
       "6536   27        5     8           14.800           51             1.100   \n",
       "1187    8        5    11           35.300           45             1.700   \n",
       "4244   20        4    20           23.300           68             3.600   \n",
       "\n",
       "      Visibility (10m)  Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm)  \n",
       "2665              2000                    0.000         0.000          0.000  \n",
       "7650              1427                    0.010         0.000          0.000  \n",
       "6536              2000                    0.590         0.000          0.000  \n",
       "1187              1829                    2.270         0.000          0.000  \n",
       "4244               895                    0.110         0.000          0.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra do DataFrame de Teste DEPOIS da Normalização ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>-1.438</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-1.743</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.946</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>0.932</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>1.051</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6536</th>\n",
       "      <td>-0.462</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>-0.044</td>\n",
       "      <td>1.973</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.667</td>\n",
       "      <td>2.997</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>1.211</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.402</td>\n",
       "      <td>2.118</td>\n",
       "      <td>-0.857</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  Visibility (10m)  \\\n",
       "2665 -1.438            0.162       -1.743             0.197             0.946   \n",
       "7650  0.932           -0.001       -0.646             1.051             0.011   \n",
       "6536 -0.462            0.221       -0.446            -0.550             0.946   \n",
       "1187 -0.044            1.973       -0.745             0.090             0.667   \n",
       "4244  1.211            0.948        0.402             2.118            -0.857   \n",
       "\n",
       "      Solar Radiation (MJ/m2)  Snowfall (cm)  \n",
       "2665                   -0.625         -0.172  \n",
       "7650                   -0.610         -0.172  \n",
       "6536                    0.316         -0.172  \n",
       "1187                    2.997         -0.172  \n",
       "4244                   -0.450         -0.172  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra do DataFrame de treino com Early Stopping ANTES da Normalização ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7734</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.900</td>\n",
       "      <td>53</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1813</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5174</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>35.300</td>\n",
       "      <td>41</td>\n",
       "      <td>1.300</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>-6.600</td>\n",
       "      <td>31</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1988</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>7.500</td>\n",
       "      <td>21</td>\n",
       "      <td>2.700</td>\n",
       "      <td>1900</td>\n",
       "      <td>2.220</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>27.600</td>\n",
       "      <td>62</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1043</td>\n",
       "      <td>1.760</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Day  Weekday  Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  \\\n",
       "7734   18        1     6            1.900           53             0.400   \n",
       "5174   30        2    14           35.300           41             1.300   \n",
       "906    27        7    18           -6.600           31             3.000   \n",
       "1575   25        1    15            7.500           21             2.700   \n",
       "4905   19        5     9           27.600           62             1.500   \n",
       "\n",
       "      Visibility (10m)  Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm)  \n",
       "7734              1813                    0.000         0.000          0.000  \n",
       "5174              2000                    2.010         0.000          0.000  \n",
       "906               1988                    0.060         0.000          0.000  \n",
       "1575              1900                    2.220         0.000          0.000  \n",
       "4905              1043                    1.760         0.000          0.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra do DataFrame de treino com Early Stopping DEPOIS da Normalização ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7734</th>\n",
       "      <td>-0.741</td>\n",
       "      <td>-0.881</td>\n",
       "      <td>-0.346</td>\n",
       "      <td>-1.297</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5174</th>\n",
       "      <td>0.375</td>\n",
       "      <td>1.973</td>\n",
       "      <td>-0.945</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>0.946</td>\n",
       "      <td>2.582</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>0.932</td>\n",
       "      <td>-1.607</td>\n",
       "      <td>-1.444</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.926</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>0.514</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>-1.942</td>\n",
       "      <td>1.158</td>\n",
       "      <td>0.783</td>\n",
       "      <td>2.917</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>-0.322</td>\n",
       "      <td>1.315</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.616</td>\n",
       "      <td>2.183</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  Visibility (10m)  \\\n",
       "7734 -0.741           -0.881       -0.346            -1.297             0.641   \n",
       "5174  0.375            1.973       -0.945            -0.337             0.946   \n",
       "906   0.932           -1.607       -1.444             1.478             0.926   \n",
       "1575  0.514           -0.402       -1.942             1.158             0.783   \n",
       "4905 -0.322            1.315        0.102            -0.123            -0.616   \n",
       "\n",
       "      Solar Radiation (MJ/m2)  Snowfall (cm)  \n",
       "7734                   -0.625         -0.172  \n",
       "5174                    2.582         -0.172  \n",
       "906                    -0.530         -0.172  \n",
       "1575                    2.917         -0.172  \n",
       "4905                    2.183         -0.172  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra do DataFrame de validação com Early Stopping ANTES da Normalização ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>24.500</td>\n",
       "      <td>37</td>\n",
       "      <td>3.200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>14.200</td>\n",
       "      <td>73</td>\n",
       "      <td>1.900</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>11.900</td>\n",
       "      <td>48</td>\n",
       "      <td>1.900</td>\n",
       "      <td>1918</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>23.300</td>\n",
       "      <td>61</td>\n",
       "      <td>1.700</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>12.700</td>\n",
       "      <td>75</td>\n",
       "      <td>1.600</td>\n",
       "      <td>475</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Day  Weekday  Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  \\\n",
       "4697    9        2    17           24.500           37             3.200   \n",
       "3478   18        6    22           14.200           73             1.900   \n",
       "1773    5        2    21           11.900           48             1.900   \n",
       "3945    7        5     9           23.300           61             1.700   \n",
       "2327   29        5    23           12.700           75             1.600   \n",
       "\n",
       "      Visibility (10m)  Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm)  \n",
       "4697              2000                    1.040         0.000          0.000  \n",
       "3478              2000                    0.000         0.000          0.000  \n",
       "1773              1918                    0.000         0.000          0.000  \n",
       "3945              2000                    0.800         0.000          0.000  \n",
       "2327               475                    0.000         0.000          0.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra do DataFrame de validação com Early Stopping DEPOIS da Normalização ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>0.793</td>\n",
       "      <td>1.050</td>\n",
       "      <td>-1.144</td>\n",
       "      <td>1.691</td>\n",
       "      <td>0.946</td>\n",
       "      <td>1.034</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>1.490</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.946</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>1.351</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.596</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.812</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.651</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>1.630</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.751</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-1.542</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  Visibility (10m)  \\\n",
       "4697  0.793            1.050       -1.144             1.691             0.946   \n",
       "3478  1.490            0.170        0.651             0.304             0.946   \n",
       "1773  1.351           -0.026       -0.596             0.304             0.812   \n",
       "3945 -0.322            0.948        0.053             0.090             0.946   \n",
       "2327  1.630            0.042        0.751            -0.016            -1.542   \n",
       "\n",
       "      Solar Radiation (MJ/m2)  Snowfall (cm)  \n",
       "4697                    1.034         -0.172  \n",
       "3478                   -0.625         -0.172  \n",
       "1773                   -0.625         -0.172  \n",
       "3945                    0.651         -0.172  \n",
       "2327                   -0.625         -0.172  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Estatísticas Descritivas do Conjunto de Treino Normalizado ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6390.000</td>\n",
       "      <td>6390.000</td>\n",
       "      <td>6390.000</td>\n",
       "      <td>6390.000</td>\n",
       "      <td>6390.000</td>\n",
       "      <td>6390.000</td>\n",
       "      <td>6390.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.580</td>\n",
       "      <td>-2.490</td>\n",
       "      <td>-2.990</td>\n",
       "      <td>-1.720</td>\n",
       "      <td>-2.270</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.880</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.760</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.390</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.630</td>\n",
       "      <td>2.290</td>\n",
       "      <td>1.900</td>\n",
       "      <td>2.870</td>\n",
       "      <td>0.950</td>\n",
       "      <td>3.080</td>\n",
       "      <td>19.790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  \\\n",
       "count 6390.000         6390.000     6390.000          6390.000   \n",
       "mean     0.000            0.000        0.000            -0.000   \n",
       "std      1.000            1.000        1.000             1.000   \n",
       "min     -1.580           -2.490       -2.990            -1.720   \n",
       "25%     -0.880           -0.790       -0.800            -0.760   \n",
       "50%     -0.040            0.030        0.000            -0.230   \n",
       "75%      0.930            0.810        0.800             0.620   \n",
       "max      1.630            2.290        1.900             2.870   \n",
       "\n",
       "       Visibility (10m)  Solar Radiation (MJ/m2)  Snowfall (cm)  \n",
       "count          6390.000                 6390.000       6390.000  \n",
       "mean             -0.000                   -0.000          0.000  \n",
       "std               1.000                    1.000          1.000  \n",
       "min              -2.270                   -0.630         -0.170  \n",
       "25%              -0.850                   -0.630         -0.170  \n",
       "50%               0.390                   -0.630         -0.170  \n",
       "75%               0.950                    0.320         -0.170  \n",
       "max               0.950                    3.080         19.790  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vamos usar o StandardScaler, que padroniza os dados (média=0, desvio padrão=1).\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# --- APRENDER E TRANSFORMAR O CONJUNTO DE TREINO ---\n",
    "# O scaler \"aprende\" a média e o desvio padrão de cada coluna do X_train.\n",
    "# Em seguida, ele usa esses valores para transformar o X_train.\n",
    "# A função .fit_transform() faz essas duas etapas de uma só vez.\n",
    "print(\"Normalizando o conjunto de treinamento...\")\n",
    "#X_train_normalizado_array = scaler.fit_transform(X_train_limpo)\n",
    "#X_train_normalizado_array = scaler.fit_transform(X_train_vt)\n",
    "X_train_normalizado_array = scaler.fit_transform(X_train_kbest)\n",
    "\n",
    "\n",
    "# O resultado é um array NumPy. Vamos convertê-lo de volta para um DataFrame\n",
    "# para manter os nomes das colunas e a legibilidade.\n",
    "\n",
    "#X_train_normalizado = pd.DataFrame(X_train_normalizado_array, \n",
    "#                                  columns=X_train_limpo.columns, \n",
    "#                                  index=X_train_limpo.index)\n",
    "#X_train_normalizado = pd.DataFrame(X_train_normalizado_array, \n",
    "#                                  columns=X_train_vt.columns, \n",
    "#                                  index=X_train_vt.index)\n",
    "X_train_normalizado = pd.DataFrame(X_train_normalizado_array, \n",
    "                                  columns=X_train_kbest.columns, \n",
    "                                  index=X_train_kbest.index)\n",
    "\n",
    "# ---  APLICAR A MESMA TRANSFORMAÇÃO NO CONJUNTO DE TESTE ---\n",
    "# IMPORTANTE: Usamos apenas .transform() aqui.\n",
    "# Isso garante que o X_test seja normalizado usando a MESMA média e desvio padrão\n",
    "# que foram aprendidos com o X_train, evitando vazamento de dados (data leakage).\n",
    "print(\"Normalizando o conjunto de teste...\")\n",
    "#X_test_normalizado_array = scaler.transform(X_test_limpo)\n",
    "#X_test_normalizado_array = scaler.transform(X_test_vt)\n",
    "X_test_normalizado_array = scaler.transform(X_test_kbest)\n",
    "\n",
    "# Convertendo de volta para um DataFrame\n",
    "#X_test_normalizado = pd.DataFrame(X_test_normalizado_array, \n",
    "#                                 columns=X_test_limpo.columns, \n",
    "#                                 index=X_test_limpo.index)\n",
    "#X_test_normalizado = pd.DataFrame(X_test_normalizado_array, \n",
    "#                                 columns=X_test_vt.columns, \n",
    "#                                 index=X_test_vt.index)\n",
    "X_test_normalizado = pd.DataFrame(X_test_normalizado_array, \n",
    "                                 columns=X_test_kbest.columns, \n",
    "                                 index=X_test_kbest.index)\n",
    "\n",
    "# ---  APLICAR A MESMA TRANSFORMAÇÃO NO CONJUNTO DE TREINO USADO PARA O Early Stopping ---\n",
    "# IMPORTANTE: Usamos apenas .transform() aqui.\n",
    "# Isso garante que o novo dataframe seja normalizado usando a MESMA média e desvio padrão\n",
    "# que foram aprendidos com o X_train, evitando vazamento de dados (data leakage).\n",
    "print(\"Normalizando o conjunto de treinamento usando no metodo Early Stopping...\")\n",
    "#X_train_early_stp_normalizado_array = scaler.transform(X_train_early_stp_limpo)\n",
    "#X_train_early_stp_normalizado_array = scaler.transform(X_train_early_stp_vt)\n",
    "X_train_early_stp_normalizado_array = scaler.transform(X_train_early_stp_kbest)\n",
    "\n",
    "# O resultado é um array NumPy. Vamos convertê-lo de volta para um DataFrame\n",
    "# para manter os nomes das colunas e a legibilidade.\n",
    "#X_train_early_stp_normalizado = pd.DataFrame(X_train_early_stp_normalizado_array, \n",
    "#                                  columns=X_train_early_stp_limpo.columns, \n",
    "#                                  index=X_train_early_stp_limpo.index)\n",
    "#X_train_early_stp_normalizado = pd.DataFrame(X_train_early_stp_normalizado_array, \n",
    "#                                  columns=X_train_early_stp_vt.columns, \n",
    "#                                  index=X_train_early_stp_vt.index)\n",
    "X_train_early_stp_normalizado = pd.DataFrame(X_train_early_stp_normalizado_array, \n",
    "                                  columns=X_train_early_stp_kbest.columns, \n",
    "                                  index=X_train_early_stp_kbest.index)\n",
    "\n",
    "# ---  APLICAR A MESMA TRANSFORMAÇÃO NO CONJUNTO DE VALIDAÇÃO USADO PARA O Early Stopping ---\n",
    "# IMPORTANTE: Usamos apenas .transform() aqui.\n",
    "# Isso garante que o novo dataframe seja normalizado usando a MESMA média e desvio padrão\n",
    "# que foram aprendidos com o X_train, evitando vazamento de dados (data leakage).\n",
    "print(\"Normalizando o conjunto de validação usado no Early Stopping...\")\n",
    "#X_val_normalizado_array = scaler.transform(X_val_limpo)\n",
    "#X_val_normalizado_array = scaler.transform(X_val_vt)\n",
    "X_val_normalizado_array = scaler.transform(X_val_kbest)\n",
    "\n",
    "\n",
    "# Convertendo de volta para um DataFrame\n",
    "#X_val_normalizado = pd.DataFrame(X_val_normalizado_array, \n",
    "#                                 columns=X_val_limpo.columns, \n",
    "#                                 index=X_val_limpo.index)\n",
    "#X_val_normalizado = pd.DataFrame(X_val_normalizado_array, \n",
    "#                                 columns=X_val_vt.columns, \n",
    "#                                 index=X_val_vt.index)\n",
    "X_val_normalizado = pd.DataFrame(X_val_normalizado_array, \n",
    "                                 columns=X_val_kbest.columns, \n",
    "                                 index=X_val_kbest.index)\n",
    "\n",
    "print(\"\\nNormalização concluída!\")\n",
    "\n",
    "print(\"\\n--- Amostra do DataFrame de Treino ANTES da Normalização ---\")\n",
    "display(X_train_limpo.head())\n",
    "\n",
    "print(\"\\n--- Amostra do DataFrame de Treino DEPOIS da Normalização ---\")\n",
    "display(X_train_normalizado.head())\n",
    "\n",
    "print(\"\\n--- Amostra do DataFrame de Teste ANTES da Normalização ---\")\n",
    "display(X_test_limpo.head())\n",
    "\n",
    "print(\"\\n--- Amostra do DataFrame de Teste DEPOIS da Normalização ---\")\n",
    "display(X_test_normalizado.head())\n",
    "\n",
    "print(\"\\n--- Amostra do DataFrame de treino com Early Stopping ANTES da Normalização ---\")\n",
    "display(X_train_early_stp_limpo.head())\n",
    "\n",
    "print(\"\\n--- Amostra do DataFrame de treino com Early Stopping DEPOIS da Normalização ---\")\n",
    "display(X_train_early_stp_normalizado.head())\n",
    "\n",
    "print(\"\\n--- Amostra do DataFrame de validação com Early Stopping ANTES da Normalização ---\")\n",
    "display(X_val_limpo.head())\n",
    "\n",
    "print(\"\\n--- Amostra do DataFrame de validação com Early Stopping DEPOIS da Normalização ---\")\n",
    "display(X_val_normalizado.head())\n",
    "\n",
    "# Verificando as estatísticas do conjunto de treino normalizado\n",
    "# A média (mean) deve ser muito próxima de 0 e o desvio padrão (std) próximo de 1.\n",
    "print(\"\\n--- Estatísticas Descritivas do Conjunto de Treino Normalizado ---\")\n",
    "display(X_train_normalizado.describe().round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a75ef-b0da-4d9c-b21f-989bb5248521",
   "metadata": {},
   "source": [
    "# 5. Treinamento dos modelos preditivos\n",
    "\n",
    "## Regressão\n",
    "A regressão é usada para prever um valor numérico contínuo, neste caso, o número de bicicletas alugadas.\n",
    "Como se aplica aqui? Você usa os outros atributos (hora, temperatura, umidade, estação do ano, etc.) como features (variáveis de entrada) para treinar um modelo de regressão. O objetivo do modelo é aprender a relação matemática entre essas features e o Rented Bike Count.\n",
    "\n",
    "### XGBoost\n",
    "Vamos usar o algoritmo **XGBoost**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4feb81b7-2006-4fa4-b50a-2b1031ad9dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento com Early Stopping...\n",
      "Treinamento concluído!\n",
      "Melhor iteração encontrada: 461\n"
     ]
    }
   ],
   "source": [
    "# --- Treinamento com Early Stopping ---\n",
    "\n",
    "# Instanciar o modelo com um n_estimators alto\n",
    "xgbr = xgb.XGBRegressor(\n",
    "    n_estimators=2000, # Um número alto, pois vamos parar antes se necessário. É o número total de especialistas (árvores de decisão)\n",
    "    learning_rate=0.01, # É o peso dado (de 0 a 1) na confiança que o modelo tem da correção proposta pela nova árvore (n_estimators)\n",
    "    max_depth=7,   # Uma profundidade de 5 significa que cada árvore pode fazer, no máximo, 3 níveis de perguntas \"se-então-senão\" para chegar a uma previsão.\n",
    "    objective='reg:squarederror',   # define matematicamente o que significa \"erro\" para o seu problema específico. Define a função de perda (loss function) que o algoritmo tentará minimizar durante o treinamento.\n",
    "    eval_metric='rmse',\n",
    "    n_jobs=-1,  # Usa todos os núcleos de CPU disponíveis para acelerar o treino\n",
    "    random_state=35,\n",
    "    early_stopping_rounds=20 # Paciência de 10 rodadas\n",
    ")\n",
    "\n",
    "# Definir o conjunto de validação\n",
    "eval_set = [(X_train_early_stp_normalizado, y_train_early_stp_limpo), (X_val_normalizado, y_val_limpo)]\n",
    "\n",
    "print(\"Iniciando o treinamento com Early Stopping...\")\n",
    "# Treinar o modelo\n",
    "xgbr.fit(\n",
    "    X_train_early_stp_normalizado, y_train_early_stp_limpo,\n",
    "    eval_set=eval_set,\n",
    "    verbose=False # Mostra o progresso do erro a cada rodada\n",
    ")\n",
    "print(\"Treinamento concluído!\")\n",
    "print(f\"Melhor iteração encontrada: {xgbr.best_iteration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e66b84-ddb7-4ef0-aad0-b87585dc771b",
   "metadata": {},
   "source": [
    "# 6. Analisando o resultado do XGBoost\n",
    "Agora vamos analisar a predição usando a base de dados para teste.\n",
    "\n",
    "Vamos usar a metrica RMSE, MAPE, alem de mostar a quantidade bruta de erros na predição.\n",
    "\n",
    "## MAE\n",
    "É a média de todos os erros individuais, ignorando se eles são positivos ou negativos.\n",
    "*   **Como pensa:** \"Qual é, em média, a distância entre a minha previsão e o valor real?\"\n",
    "\n",
    "### Análise com MAE (O Erro Democrático)\n",
    "\n",
    "*   **erro_previsãol_modelo_1:** `(10 + 10 + 10 + 10 + 10) / 5 = 10`\n",
    "*   **erro_previsãol_modelo_2:** `(0 + 0 + 0 + 0 + 50) / 5 = 10`\n",
    "\n",
    "**Conclusão do MAE:** Segundo o MAE, erro_previsãol_modelo_1 e erro_previsãol_modelo_2 são **igualmente \"ruins\"**. O erro médio de ambos é 10. O MAE não se importa como o erro total foi distribuído; ele apenas se importa com a média.\n",
    "\n",
    "## RMSE\n",
    "Ela te dá o erro médio do modelo, na mesma unidade da sua variável alvo. No caso, o resultado do RMSE será em \"número de bicicletas\".\n",
    "\n",
    "Exemplo: Um RMSE de 55.8 significa que, em média, as previsões do seu modelo erram por cerca de 56 bicicletas (para mais ou para menos).\n",
    "\n",
    "Penaliza Erros Grandes: Como ela eleva os erros ao quadrado antes de tirar a média, erros grandes (outliers de previsão) têm um peso muito maior no resultado final. Um único erro grotesco vai inflar bastante o RMSE. Isso é útil porque te alerta sobre previsões muito ruins.\n",
    "\n",
    "*   **Como pensa:** \"Eu odeio erros grandes. Vou penalizá-los severamente para que eles se destaquem.\"\n",
    "\n",
    "### Análise com RMSE (O Erro Punitivo)\n",
    "\n",
    "1.  **Elevar os erros ao quadrado:**\n",
    "    *   erro²_previsãol_modelo_1: `[100, 100, 100, 100, 100]`\n",
    "    *   erros²_previsãol_modelo_2: `[0, 0, 0, 0, 2500]`\n",
    "\n",
    "2.  **Calcular a média dos quadrados:**\n",
    "    *   Média²_previsãol_modelo_1: `(100 + 100 + 100 + 100 + 100) / 5 = 100`\n",
    "    *   Média²_previsãol_modelo_2: `(0 + 0 + 0 + 0 + 2500) / 5 = 500`\n",
    "\n",
    "3.  **Tirar a raiz quadrada:**\n",
    "    *   **RMSE_previsãol_modelo_1:** `sqrt(100) = 10`\n",
    "    *   **RMSE_previsãol_modelo_2:** `sqrt(500) ≈ 22.36`\n",
    "\n",
    "**Conclusão do RMSE:** Segundo o RMSE, previsãol_modelo_2 é **mais do que o dobro \"pior\"** que previsãol_modelo_1 (22.36 vs. 10). Por quê? Porque o erro único e grande de 50 foi elevado ao quadrado, tornando-se 2500, um valor que dominou completamente a média. O RMSE penalizou severamente previsãol_modelo_2.\n",
    "\n",
    "## MAPE \n",
    "Um MAPE de 15% significa que, em média, a previsão do seu modelo está a 15% de distância do valor real. Se o valor real era 200 bicicletas, o modelo errou, em média, por 30 bicicletas (15% de 200). Se o valor real era 1000, ele errou por 150.\n",
    "\n",
    "Como existe zeros no dataset de label, não usaremos o MAPE!\n",
    "\n",
    "**Desvantagens e Cuidados (MUITO IMPORTANTE)**\n",
    "\n",
    "O MAPE tem duas fraquezas significativas que você precisa conhecer:\n",
    "1. É Indefinido ou Explode com Valores Reais Iguais a Zero:\n",
    "    * O Problema: Olhe a fórmula: ... / valor_real. Se o valor_real for zero, você terá uma divisão por zero, o que matematicamente é indefinido. No seu dataset, se houver uma hora em que nenhuma bicicleta foi alugada (Rented Bike Count = 0) e seu modelo prever qualquer valor diferente de zero (ex: 10), o cálculo do erro para esse ponto falhará ou resultará em infinito.\n",
    "    * Consequência: Se o seu y_test contém zeros, a função do Scikit-learn para o MAPE pode retornar um erro ou um valor gigantesco (inf), tornando a métrica inútil.\n",
    "2. É Assimétrico e Penaliza Mais os Erros de Superestimação:\n",
    "    * O Problema: O MAPE não trata erros para mais e para menos da mesma forma.\n",
    "        * Subestimação (prever menos que o real): O erro percentual máximo que você pode ter é 100% (se você prever 0 quando o real era 1000, o erro é (1000-0)/1000 = 100%).\n",
    "        * Superestimação (prever mais que o real): O erro percentual pode ser infinitamente grande. Se o real era 10 e você previu 1000, o erro é (10-1000)/10 = -99, e o erro percentual é 990%!\n",
    "    * Consequência: O MAPE \"incentiva\" os modelos a serem mais conservadores e a preverem valores mais baixos (subestimar), pois os erros de superestimação são penalizados de forma desproporcional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c700297c-70ed-4a55-bfd5-ba940e929ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.7581508755683899\n",
      "mae: 196.11 bicicletas.\n",
      "rmse: 327.51 bicicletas.\n",
      "\n",
      "Amostra da comparação entre valores reais e previstos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valor Real</th>\n",
       "      <th>Valor Previsto_xgbr</th>\n",
       "      <th>Erro</th>\n",
       "      <th>Erro %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>513</td>\n",
       "      <td>497.052</td>\n",
       "      <td>15.948</td>\n",
       "      <td>3.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>2200</td>\n",
       "      <td>1733.019</td>\n",
       "      <td>466.981</td>\n",
       "      <td>21.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6536</th>\n",
       "      <td>2129</td>\n",
       "      <td>975.860</td>\n",
       "      <td>1153.140</td>\n",
       "      <td>54.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>547</td>\n",
       "      <td>611.856</td>\n",
       "      <td>-64.856</td>\n",
       "      <td>-11.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>2519</td>\n",
       "      <td>2175.206</td>\n",
       "      <td>343.794</td>\n",
       "      <td>13.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>123</td>\n",
       "      <td>250.026</td>\n",
       "      <td>-127.026</td>\n",
       "      <td>-103.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>1558</td>\n",
       "      <td>1754.516</td>\n",
       "      <td>-196.516</td>\n",
       "      <td>-12.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>1344</td>\n",
       "      <td>1307.848</td>\n",
       "      <td>36.152</td>\n",
       "      <td>2.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6596</th>\n",
       "      <td>1835</td>\n",
       "      <td>1302.244</td>\n",
       "      <td>532.756</td>\n",
       "      <td>29.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3762</th>\n",
       "      <td>3251</td>\n",
       "      <td>2711.093</td>\n",
       "      <td>539.907</td>\n",
       "      <td>16.607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Valor Real  Valor Previsto_xgbr     Erro   Erro %\n",
       "2665         513              497.052   15.948    3.109\n",
       "7650        2200             1733.019  466.981   21.226\n",
       "6536        2129              975.860 1153.140   54.163\n",
       "1187         547              611.856  -64.856  -11.857\n",
       "4244        2519             2175.206  343.794   13.648\n",
       "4444         123              250.026 -127.026 -103.273\n",
       "1843        1558             1754.516 -196.516  -12.613\n",
       "7504        1344             1307.848   36.152    2.690\n",
       "6596        1835             1302.244  532.756   29.033\n",
       "3762        3251             2711.093  539.907   16.607"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "previsoes_xgbr = xgbr.predict(X_test_normalizado)\n",
    "\n",
    "# --- Comparar Previsões com Valores Reais ---\n",
    "# Criar um novo DataFrame para comparar os resultados\n",
    "resultados = pd.DataFrame({\n",
    "    'Valor Real': y_test_limpo,\n",
    "    'Valor Previsto_xgbr': previsoes_xgbr\n",
    "})\n",
    "\n",
    "# Adicionar uma coluna com a diferença (erro) para cada previsão\n",
    "resultados['Erro'] = resultados['Valor Real'] - resultados['Valor Previsto_xgbr']\n",
    "resultados['Erro %'] = ((resultados['Valor Real'] - resultados['Valor Previsto_xgbr']) * 100) / resultados['Valor Real']\n",
    "\n",
    "# calculando o mae entre o valor real e o predito\n",
    "mae = mean_absolute_error(y_test_limpo, previsoes_xgbr)\n",
    "# calculando o mape entre o valor real e o predito\n",
    "rmse = np.sqrt(mean_squared_error(y_test_limpo, previsoes_xgbr))\n",
    "\n",
    "# Mostra metricas\n",
    "print(f\"score: {xgbr.score(X_test_normalizado, y_test_limpo)}\")\n",
    "print(f\"mae: {mae:.2f} bicicletas.\" )\n",
    "print(f\"rmse: {rmse:.2f} bicicletas.\" )\n",
    "\n",
    "print(\"\\nAmostra da comparação entre valores reais e previstos:\")\n",
    "display(resultados.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66909b0-7689-40f6-adb4-d55cc58d0ea2",
   "metadata": {},
   "source": [
    "# 7. Pipeline\n",
    "Pipeline encapsula todas as etapas de pré-processamento e o modelo final em um único objeto, o que simplifica o treinamento, a avaliação e, mais importante, a implantação.\n",
    "\n",
    "Vamos usar pipeline para fazer o mesmo passo a passo que fizemos para treinar o modelo xgboost para comparar a quantidade de comandos necessários.\n",
    "\n",
    "Depois vamos usar outros pipelines com técnicas diferentes de preparação de dados e treinamento de outros modelos preditivos para analisar o desempenho.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d80dde5-2f6d-4f1d-b4d5-9488b2b1ccc3",
   "metadata": {},
   "source": [
    "## Xgboost \n",
    "\n",
    "### Sem tratamento de dados\n",
    "vamos montar um pipeline para treinar o xgboost sem passar nenhum tratamento de dados antes de treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b282f20-57fa-42d6-82b9-478c6198cff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento do Pipeline...\n",
      "Treinamento concluído!\n",
      "score: 0.8569183945655823\n",
      "\n",
      "Fazendo previsões com o Pipeline na base de teste...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 557.469 , 1983.0831,  685.4952, ...,  648.1433,  447.1227,\n",
       "       1557.3174], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- DEFINIR E MONTAR O PIPELINE ---\n",
    "\n",
    "# O Pipeline é uma lista de tuplas. Cada tupla contém:\n",
    "# 1. Um nome (string) que você dá para a etapa.\n",
    "# 2. O objeto do Scikit-learn para aquela etapa (instanciado).\n",
    "pipeline_xgboost_unclean = Pipeline([\n",
    "    ('xgboost_unclean', xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=7,\n",
    "        eval_metric='rmse',\n",
    "        n_jobs=-1,\n",
    "        random_state=35\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# --- TREINAR O PIPELINE ---\n",
    "print(\"Iniciando o treinamento do Pipeline...\")\n",
    "pipeline_xgboost_unclean.fit(X_train, y_train)\n",
    "print(\"Treinamento concluído!\")\n",
    "print(f\"score: {pipeline_xgboost_unclean.score(X_test, y_test)}\")\n",
    "\n",
    "# --- FAZER PREVISÕES COM O PIPELINE ---\n",
    "print(\"\\nFazendo previsões com o Pipeline na base de teste...\")\n",
    "previsoes_xgboost_unclean = pipeline_xgboost_unclean.predict(X_test)\n",
    "previsoes_xgboost_unclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4bec2c3-010c-4d23-aba5-259babccda3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Previsão para um Novo Dado ---\n",
      "O número previsto de aluguéis é: -26\n"
     ]
    }
   ],
   "source": [
    "# ---  USANDO O PIPELINE PARA PREVER UM NOVO DADO ---\n",
    "\n",
    "# Exemplo de um novo dado\n",
    "novo_dado = {\n",
    "    'Day': 28, 'Weekday': 7, 'Hour': 4, 'Temperature(°C)': -10.5,\n",
    "    'Humidity(%)': 95, 'Wind speed (m/s)': 5.2, 'Visibility (10m)': 1950,\n",
    "    'Solar Radiation (MJ/m2)': 0.0, 'Rainfall(mm)': 10.0, 'Snowfall (cm)': 5.0,\n",
    "}\n",
    "\n",
    "# Converter para DataFrame com a ordem correta das colunas\n",
    "novo_dado_df = pd.DataFrame([novo_dado])[X_train.columns]\n",
    "\n",
    "# Fazer a previsão é incrivelmente simples agora\n",
    "previsao_novo_dado = pipeline_xgboost_unclean.predict(novo_dado_df)\n",
    "valor_previsto = previsao_novo_dado[0]\n",
    "\n",
    "print(\"\\n--- Previsão para um Novo Dado ---\")\n",
    "print(f\"O número previsto de aluguéis é: {valor_previsto:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70792fc3-8513-4761-885b-e28549fe8b0f",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Agora vamos treinar com o uso de early stopping para evitar overfiting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1ee96d8-258c-44f8-a8cb-2ec3b4c6d275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento com Early Stopping...\n",
      "[0]\tvalidation_0-rmse:639.72158\tvalidation_1-rmse:632.73614\n",
      "[100]\tvalidation_0-rmse:355.15621\tvalidation_1-rmse:383.65808\n",
      "[200]\tvalidation_0-rmse:260.70262\tvalidation_1-rmse:322.06420\n",
      "[300]\tvalidation_0-rmse:218.98296\tvalidation_1-rmse:304.08648\n",
      "[400]\tvalidation_0-rmse:197.08040\tvalidation_1-rmse:296.30121\n",
      "[500]\tvalidation_0-rmse:183.54509\tvalidation_1-rmse:288.78276\n",
      "[600]\tvalidation_0-rmse:168.22878\tvalidation_1-rmse:281.08172\n",
      "[700]\tvalidation_0-rmse:157.18136\tvalidation_1-rmse:276.12558\n",
      "[800]\tvalidation_0-rmse:149.13222\tvalidation_1-rmse:272.72431\n",
      "[900]\tvalidation_0-rmse:141.20299\tvalidation_1-rmse:269.64807\n",
      "[1000]\tvalidation_0-rmse:133.54156\tvalidation_1-rmse:266.89359\n",
      "[1100]\tvalidation_0-rmse:127.47089\tvalidation_1-rmse:265.42260\n",
      "[1200]\tvalidation_0-rmse:120.74693\tvalidation_1-rmse:263.72575\n",
      "[1300]\tvalidation_0-rmse:115.26309\tvalidation_1-rmse:262.11240\n",
      "[1400]\tvalidation_0-rmse:111.26125\tvalidation_1-rmse:260.99594\n",
      "[1500]\tvalidation_0-rmse:107.16335\tvalidation_1-rmse:259.92854\n",
      "[1600]\tvalidation_0-rmse:104.11153\tvalidation_1-rmse:259.49822\n",
      "[1700]\tvalidation_0-rmse:99.75215\tvalidation_1-rmse:258.24034\n",
      "[1800]\tvalidation_0-rmse:96.39503\tvalidation_1-rmse:257.61362\n",
      "[1900]\tvalidation_0-rmse:92.17900\tvalidation_1-rmse:256.49509\n",
      "[1924]\tvalidation_0-rmse:91.26218\tvalidation_1-rmse:256.52078\n",
      "Treinamento concluído!\n",
      "score: 0.8476635813713074\n",
      "Melhor iteração encontrada: 1904\n",
      "\n",
      "Fazendo previsões com o Pipeline na base de teste...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 519.1198 , 1973.4935 ,  719.28375, ...,  629.1213 ,  340.89914,\n",
       "       1450.7251 ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar o eval_set para o Early Stopping.\n",
    "eval_set = [(X_train_early_stp, y_train_early_stp), (X_val, y_val)]\n",
    "\n",
    "# --- TREINAR O MODELO FINAL COM EARLY STOPPING ---\n",
    "# Vamos treinar apenas o modelo XGBoost com os dados já processados.\n",
    "pipeline_xgboost_unclean_early_stp = xgb.XGBRegressor(\n",
    "    n_estimators=2000, # Um número alto, pois vamos parar antes se necessário. É o número total de especialistas (árvores de decisão)\n",
    "    learning_rate=0.01, # É o peso dado (de 0 a 1) na confiança que o modelo tem da correção proposta pela nova árvore (n_estimators)\n",
    "    max_depth=7,   # Uma profundidade de 5 significa que cada árvore pode fazer, no máximo, 3 níveis de perguntas \"se-então-senão\" para chegar a uma previsão.\n",
    "    objective='reg:squarederror',   # define matematicamente o que significa \"erro\" para o seu problema específico. Define a função de perda (loss function) que o algoritmo tentará minimizar durante o treinamento.\n",
    "    eval_metric='rmse',\n",
    "    n_jobs=-1,  # Usa todos os núcleos de CPU disponíveis para acelerar o treino\n",
    "    random_state=35,\n",
    "    early_stopping_rounds=20 # Paciência de 10 rodadas\n",
    ")\n",
    "\n",
    "print(\"Iniciando o treinamento com Early Stopping...\")\n",
    "pipeline_xgboost_unclean_early_stp.fit(\n",
    "    X_train_early_stp, y_train_early_stp,\n",
    "    eval_set=eval_set,\n",
    "    verbose=100 # Mostra o progresso a cada 100 rodadas\n",
    ")\n",
    "print(\"Treinamento concluído!\")\n",
    "print(f\"score: {pipeline_xgboost_unclean_early_stp.score(X_test, y_test)}\")\n",
    "print(f\"Melhor iteração encontrada: {pipeline_xgboost_unclean_early_stp.best_iteration}\")\n",
    "\n",
    "# --- FAZER PREVISÕES COM O PIPELINE ---\n",
    "print(\"\\nFazendo previsões com o Pipeline na base de teste...\")\n",
    "previsoes_xgboost_unclean_early_stp = pipeline_xgboost_unclean_early_stp.predict(X_test)\n",
    "previsoes_xgboost_unclean_early_stp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f529bd2b-d601-4708-8ef6-35653326b730",
   "metadata": {},
   "source": [
    "### Com tratamento de dados\n",
    "Agora vamos montar um pipeline para treinar o xgboost tratando os dados antes de treinar o modelo.\n",
    "\n",
    "#### Remoção de outliers\n",
    "Vamos começar apenas com remosção de outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdeb0192-0247-4afb-858b-9ff29e0a25f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento com Early Stopping...\n",
      "[0]\tvalidation_0-rmse:651.48435\tvalidation_1-rmse:644.12965\n",
      "[100]\tvalidation_0-rmse:357.38121\tvalidation_1-rmse:388.94641\n",
      "[200]\tvalidation_0-rmse:258.53363\tvalidation_1-rmse:324.44858\n",
      "[300]\tvalidation_0-rmse:215.65426\tvalidation_1-rmse:305.01032\n",
      "[400]\tvalidation_0-rmse:192.60947\tvalidation_1-rmse:297.34130\n",
      "[500]\tvalidation_0-rmse:176.88186\tvalidation_1-rmse:291.46565\n",
      "[600]\tvalidation_0-rmse:165.58997\tvalidation_1-rmse:286.87062\n",
      "[700]\tvalidation_0-rmse:156.95685\tvalidation_1-rmse:283.89118\n",
      "[800]\tvalidation_0-rmse:147.94237\tvalidation_1-rmse:280.25066\n",
      "[900]\tvalidation_0-rmse:141.39270\tvalidation_1-rmse:277.56542\n",
      "[1000]\tvalidation_0-rmse:136.14647\tvalidation_1-rmse:275.73561\n",
      "[1100]\tvalidation_0-rmse:131.19634\tvalidation_1-rmse:274.60691\n",
      "[1200]\tvalidation_0-rmse:125.22667\tvalidation_1-rmse:272.88071\n",
      "[1300]\tvalidation_0-rmse:120.19127\tvalidation_1-rmse:271.28205\n",
      "[1400]\tvalidation_0-rmse:115.68170\tvalidation_1-rmse:269.99047\n",
      "[1500]\tvalidation_0-rmse:110.52897\tvalidation_1-rmse:268.10495\n",
      "[1600]\tvalidation_0-rmse:106.11131\tvalidation_1-rmse:266.99832\n",
      "[1700]\tvalidation_0-rmse:101.57424\tvalidation_1-rmse:265.38049\n",
      "[1800]\tvalidation_0-rmse:97.64024\tvalidation_1-rmse:264.37718\n",
      "[1900]\tvalidation_0-rmse:93.54533\tvalidation_1-rmse:263.71596\n",
      "[1999]\tvalidation_0-rmse:90.62215\tvalidation_1-rmse:263.13183\n",
      "Treinamento concluído!\n",
      "score: 0.8476245999336243\n",
      "Melhor iteração encontrada: 1999\n",
      "\n",
      "Fazendo previsões com o Pipeline na base de teste...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 515.85095, 2005.1682 , 1529.6564 , ...,  256.07498,  414.61868,\n",
       "       1450.6443 ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar o eval_set para o Early Stopping.\n",
    "eval_set = [(X_train_early_stp_limpo, y_train_early_stp_limpo), (X_val_limpo, y_val_limpo)]\n",
    "\n",
    "# --- TREINAR O MODELO FINAL COM EARLY STOPPING ---\n",
    "# Vamos treinar apenas o modelo XGBoost com os dados já processados.\n",
    "pipeline_xgboost_outlier = xgb.XGBRegressor(\n",
    "    n_estimators=2000, # Um número alto, pois vamos parar antes se necessário. É o número total de especialistas (árvores de decisão)\n",
    "    learning_rate=0.01, # É o peso dado (de 0 a 1) na confiança que o modelo tem da correção proposta pela nova árvore (n_estimators)\n",
    "    max_depth=7,   # Uma profundidade de 5 significa que cada árvore pode fazer, no máximo, 3 níveis de perguntas \"se-então-senão\" para chegar a uma previsão.\n",
    "    objective='reg:squarederror',   # define matematicamente o que significa \"erro\" para o seu problema específico. Define a função de perda (loss function) que o algoritmo tentará minimizar durante o treinamento.\n",
    "    eval_metric='rmse',\n",
    "    n_jobs=-1,  # Usa todos os núcleos de CPU disponíveis para acelerar o treino\n",
    "    random_state=35,\n",
    "    early_stopping_rounds=20 # Paciência de 10 rodadas\n",
    ")\n",
    "\n",
    "print(\"Iniciando o treinamento com Early Stopping...\")\n",
    "pipeline_xgboost_outlier.fit(\n",
    "    X_train_early_stp_limpo, y_train_early_stp_limpo,\n",
    "    eval_set=eval_set,\n",
    "    verbose=100 # Mostra o progresso a cada 100 rodadas\n",
    ")\n",
    "print(\"Treinamento concluído!\")\n",
    "print(f\"score: {pipeline_xgboost_outlier.score(X_test_limpo, y_test_limpo)}\")\n",
    "print(f\"Melhor iteração encontrada: {pipeline_xgboost_outlier.best_iteration}\")\n",
    "\n",
    "# --- FAZER PREVISÕES COM O PIPELINE ---\n",
    "print(\"\\nFazendo previsões com o Pipeline na base de teste...\")\n",
    "previsoes_xgboost_outlier = pipeline_xgboost_outlier.predict(X_test_limpo)\n",
    "previsoes_xgboost_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d954740-7ba5-40fc-9fb0-ac07b680f500",
   "metadata": {},
   "source": [
    "#### Seleção de atributos\n",
    "Agora vamos treinar a seleçãode atributos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ca024-09b9-4eb8-9436-bd7adef16eae",
   "metadata": {},
   "source": [
    "##### VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81710f83-acf8-4c26-a240-644434739436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento com Early Stopping...\n",
      "[0]\tvalidation_0-rmse:651.55851\tvalidation_1-rmse:644.11331\n",
      "[100]\tvalidation_0-rmse:365.25354\tvalidation_1-rmse:394.99334\n",
      "[200]\tvalidation_0-rmse:270.39007\tvalidation_1-rmse:329.35248\n",
      "[300]\tvalidation_0-rmse:229.49683\tvalidation_1-rmse:311.12246\n",
      "[400]\tvalidation_0-rmse:205.14442\tvalidation_1-rmse:302.79376\n",
      "[500]\tvalidation_0-rmse:191.44309\tvalidation_1-rmse:296.36110\n",
      "[600]\tvalidation_0-rmse:178.60547\tvalidation_1-rmse:292.81452\n",
      "[700]\tvalidation_0-rmse:169.35049\tvalidation_1-rmse:288.31444\n",
      "[800]\tvalidation_0-rmse:163.12717\tvalidation_1-rmse:285.92783\n",
      "[900]\tvalidation_0-rmse:156.10111\tvalidation_1-rmse:283.44115\n",
      "[1000]\tvalidation_0-rmse:150.05652\tvalidation_1-rmse:281.54239\n",
      "[1100]\tvalidation_0-rmse:143.69693\tvalidation_1-rmse:280.06597\n",
      "[1200]\tvalidation_0-rmse:136.98101\tvalidation_1-rmse:278.77098\n",
      "[1300]\tvalidation_0-rmse:129.84259\tvalidation_1-rmse:277.02788\n",
      "[1400]\tvalidation_0-rmse:125.06157\tvalidation_1-rmse:276.17257\n",
      "[1500]\tvalidation_0-rmse:119.27160\tvalidation_1-rmse:274.79013\n",
      "[1600]\tvalidation_0-rmse:114.15396\tvalidation_1-rmse:274.04965\n",
      "[1700]\tvalidation_0-rmse:109.37914\tvalidation_1-rmse:273.41635\n",
      "[1800]\tvalidation_0-rmse:105.88616\tvalidation_1-rmse:273.05303\n",
      "[1899]\tvalidation_0-rmse:102.20270\tvalidation_1-rmse:272.68341\n",
      "Treinamento concluído!\n",
      "score: 0.8372461199760437\n",
      "Melhor iteração encontrada: 1879\n",
      "\n",
      "Fazendo previsões com o Pipeline na base de teste...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 557.6438 , 2074.6257 , 1401.6632 , ...,  331.96045,  331.71478,\n",
       "       1486.9435 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- DEFINIR O PIPELINE DE PRÉ-PROCESSAMENTO ---\n",
    "# Vamos criar um pipeline apenas para as etapas de transformação.\n",
    "# Isso facilita a aplicação consistente do pré-processamento.\n",
    "preprocessing_pipeline_vth = Pipeline([\n",
    "    ('variance_threshold', VarianceThreshold(threshold=1))\n",
    "])\n",
    "\n",
    "\n",
    "# --- APLICAR O PRÉ-PROCESSAMENTO NOS DADOS ---\n",
    "# Aprender com o treino e transformar o treino\n",
    "X_train_processed_vth = preprocessing_pipeline_vth.fit_transform(X_train_early_stp_limpo)\n",
    "\n",
    "# Apenas transformar a validação e o teste\n",
    "X_val_processed_vth = preprocessing_pipeline_vth.transform(X_val_limpo)\n",
    "X_test_processed_vth = preprocessing_pipeline_vth.transform(X_test_limpo)\n",
    "\n",
    "# Criar o eval_set para o Early Stopping.\n",
    "# IMPORTANTE: O eval_set também precisa ser pré-processado da mesma forma!\n",
    "# Felizmente, o pipeline cuida disso se passarmos os dados brutos.\n",
    "# No entanto, a sintaxe do .fit() espera os dados já processados para o eval_set.\n",
    "# A maneira mais limpa é pré-processar os dados primeiro, como fizemos acima.\n",
    "\n",
    "eval_set = [(X_train_processed_vth, y_train_early_stp_limpo), (X_val_processed_vth, y_val_limpo)]\n",
    "\n",
    "# --- TREINAR O MODELO FINAL COM EARLY STOPPING ---\n",
    "# Vamos treinar apenas o modelo XGBoost com os dados já processados.\n",
    "pipeline_xgboost_vth = xgb.XGBRegressor(\n",
    "    n_estimators=2000, # Um número alto, pois vamos parar antes se necessário. É o número total de especialistas (árvores de decisão)\n",
    "    learning_rate=0.01, # É o peso dado (de 0 a 1) na confiança que o modelo tem da correção proposta pela nova árvore (n_estimators)\n",
    "    max_depth=7,   # Uma profundidade de 5 significa que cada árvore pode fazer, no máximo, 3 níveis de perguntas \"se-então-senão\" para chegar a uma previsão.\n",
    "    objective='reg:squarederror',   # define matematicamente o que significa \"erro\" para o seu problema específico. Define a função de perda (loss function) que o algoritmo tentará minimizar durante o treinamento.\n",
    "    eval_metric='rmse',\n",
    "    n_jobs=-1,  # Usa todos os núcleos de CPU disponíveis para acelerar o treino\n",
    "    random_state=35,\n",
    "    early_stopping_rounds=20 # Paciência de 10 rodadas\n",
    ")\n",
    "\n",
    "print(\"Iniciando o treinamento com Early Stopping...\")\n",
    "pipeline_xgboost_vth.fit(\n",
    "    X_train_processed_vth, y_train_early_stp_limpo,\n",
    "    eval_set=eval_set,\n",
    "    verbose=100 # Mostra o progresso a cada 100 rodadas\n",
    ")\n",
    "print(\"Treinamento concluído!\")\n",
    "print(f\"score: {pipeline_xgboost_vth.score(X_test_processed_vth, y_test_limpo)}\")\n",
    "print(f\"Melhor iteração encontrada: {pipeline_xgboost_vth.best_iteration}\")\n",
    "\n",
    "# --- FAZER PREVISÕES COM O PIPELINE ---\n",
    "print(\"\\nFazendo previsões com o Pipeline na base de teste...\")\n",
    "previsoes_xgboost_vth = pipeline_xgboost_vth.predict(X_test_processed_vth)\n",
    "previsoes_xgboost_vth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36655b-5bea-475d-af01-442e5a0c8e8c",
   "metadata": {},
   "source": [
    "##### SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b15e378e-5b03-41b3-b046-def6d8abb0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento com Early Stopping...\n",
      "[0]\tvalidation_0-rmse:651.50915\tvalidation_1-rmse:644.15143\n",
      "[100]\tvalidation_0-rmse:365.77591\tvalidation_1-rmse:401.90811\n",
      "[200]\tvalidation_0-rmse:276.27824\tvalidation_1-rmse:353.97580\n",
      "[300]\tvalidation_0-rmse:238.98233\tvalidation_1-rmse:347.05489\n",
      "[400]\tvalidation_0-rmse:218.76685\tvalidation_1-rmse:345.68596\n",
      "[481]\tvalidation_0-rmse:207.62610\tvalidation_1-rmse:345.30341\n",
      "Treinamento concluído!\n",
      "score: 0.7581508755683899\n",
      "Melhor iteração encontrada: 461\n",
      "\n",
      "Fazendo previsões com o Pipeline na base de teste...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 497.05237, 1733.0186 ,  975.8598 , ...,  144.47696,  220.6581 ,\n",
       "       1435.4913 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- DEFINIR O PIPELINE DE PRÉ-PROCESSAMENTO ---\n",
    "# Vamos criar um pipeline apenas para as etapas de transformação.\n",
    "# Isso facilita a aplicação consistente do pré-processamento.\n",
    "preprocessing_pipeline_KBest = Pipeline([\n",
    "    ('select_k_best', SelectKBest(score_func=f_regression, k=7))\n",
    "])\n",
    "\n",
    "\n",
    "# --- APLICAR O PRÉ-PROCESSAMENTO NOS DADOS ---\n",
    "# Aprender com o treino e transformar o treino\n",
    "X_train_processed_KBest = preprocessing_pipeline_KBest.fit_transform(X_train_early_stp_limpo, y_train_early_stp_limpo)\n",
    "\n",
    "# Apenas transformar a validação e o teste\n",
    "X_val_processed_KBest = preprocessing_pipeline_KBest.transform(X_val_limpo)\n",
    "X_test_processed_KBest = preprocessing_pipeline_KBest.transform(X_test_limpo)\n",
    "\n",
    "# Criar o eval_set para o Early Stopping.\n",
    "# IMPORTANTE: O eval_set também precisa ser pré-processado da mesma forma!\n",
    "# Felizmente, o pipeline cuida disso se passarmos os dados brutos.\n",
    "# No entanto, a sintaxe do .fit() espera os dados já processados para o eval_set.\n",
    "# A maneira mais limpa é pré-processar os dados primeiro, como fizemos acima.\n",
    "\n",
    "eval_set = [(X_train_processed_KBest, y_train_early_stp_limpo), (X_val_processed_KBest, y_val_limpo)]\n",
    "\n",
    "# --- TREINAR O MODELO FINAL COM EARLY STOPPING ---\n",
    "# Vamos treinar apenas o modelo XGBoost com os dados já processados.\n",
    "pipeline_xgboost_KBest = xgb.XGBRegressor(\n",
    "    n_estimators=2000, # Um número alto, pois vamos parar antes se necessário. É o número total de especialistas (árvores de decisão)\n",
    "    learning_rate=0.01, # É o peso dado (de 0 a 1) na confiança que o modelo tem da correção proposta pela nova árvore (n_estimators)\n",
    "    max_depth=7,   # Uma profundidade de 5 significa que cada árvore pode fazer, no máximo, 3 níveis de perguntas \"se-então-senão\" para chegar a uma previsão.\n",
    "    objective='reg:squarederror',   # define matematicamente o que significa \"erro\" para o seu problema específico. Define a função de perda (loss function) que o algoritmo tentará minimizar durante o treinamento.\n",
    "    eval_metric='rmse',\n",
    "    n_jobs=-1,  # Usa todos os núcleos de CPU disponíveis para acelerar o treino\n",
    "    random_state=35,\n",
    "    early_stopping_rounds=20 # Paciência de 10 rodadas\n",
    ")\n",
    "\n",
    "print(\"Iniciando o treinamento com Early Stopping...\")\n",
    "pipeline_xgboost_KBest.fit(\n",
    "    X_train_processed_KBest, y_train_early_stp_limpo,\n",
    "    eval_set=eval_set,\n",
    "    verbose=100 # Mostra o progresso a cada 100 rodadas\n",
    ")\n",
    "print(\"Treinamento concluído!\")\n",
    "print(f\"score: {pipeline_xgboost_KBest.score(X_test_processed_KBest, y_test_limpo)}\")\n",
    "print(f\"Melhor iteração encontrada: {pipeline_xgboost_KBest.best_iteration}\")\n",
    "\n",
    "# --- FAZER PREVISÕES COM O PIPELINE ---\n",
    "print(\"\\nFazendo previsões com o Pipeline na base de teste...\")\n",
    "previsoes_xgboost_KBest = pipeline_xgboost_KBest.predict(X_test_processed_KBest)\n",
    "previsoes_xgboost_KBest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c64ec-d191-460a-bb7d-3be68c1f4d48",
   "metadata": {},
   "source": [
    "#### Padronização\n",
    "Agora vamos treinar com a padronização de atributos atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8326fe9-5ec6-48ad-9cc0-7528dbd26300",
   "metadata": {},
   "source": [
    "##### VarianceThreshold sem early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eba826fa-da64-40b9-a964-3fa79adff7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento do Pipeline...\n",
      "Treinamento concluído!\n",
      "score: 0.8414660692214966\n",
      "\n",
      "Fazendo previsões com o Pipeline na base de teste...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 599.18646, 1981.7196 , 1417.2788 , ...,  316.7231 ,  444.57266,\n",
       "       1584.5525 ], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---  DEFINIR E MONTAR O PIPELINE ---\n",
    "\n",
    "# O Pipeline é uma lista de tuplas. Cada tupla contém:\n",
    "# 1. Um nome (string) que você dá para a etapa.\n",
    "# 2. O objeto do Scikit-learn para aquela etapa (instanciado).\n",
    "\n",
    "pipeline_xgboost_vth_no_early_stp = Pipeline([\n",
    "    ('variance_threshold', VarianceThreshold(threshold=1)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgboost_regressor', xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=7,\n",
    "        eval_metric='rmse',\n",
    "        n_jobs=-1,\n",
    "        random_state=35\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- TREINAR O PIPELINE ---\n",
    "# A mágica do Pipeline: você chama .fit() apenas uma vez!\n",
    "# O Pipeline gerencia internamente o fluxo:\n",
    "# 1. X_train_limpo passa pelo .fit_transform() do VarianceThreshold.\n",
    "# 2. O resultado passa pelo .fit_transform() do StandardScaler.\n",
    "# 3. O resultado final é usado para treinar o XGBRegressor.\n",
    "\n",
    "print(\"Iniciando o treinamento do Pipeline...\")\n",
    "pipeline_xgboost_vth_no_early_stp.fit(X_train_limpo, y_train_limpo)\n",
    "print(\"Treinamento concluído!\")\n",
    "print(f\"score: {pipeline_xgboost_vth_no_early_stp.score(X_test_limpo, y_test_limpo)}\")\n",
    "\n",
    "\n",
    "# --- FAZER PREVISÕES COM O PIPELINE ---\n",
    "\n",
    "# Novamente, você chama .predict() apenas uma vez.\n",
    "# O Pipeline gerencia o fluxo para os dados de teste:\n",
    "# 1. X_test_limpo passa pelo .transform() do VarianceThreshold (que já foi treinado).\n",
    "# 2. O resultado passa pelo .transform() do StandardScaler (que também já foi treinado).\n",
    "# 3. O resultado final é usado pelo XGBRegressor para fazer a previsão.\n",
    "\n",
    "print(\"\\nFazendo previsões com o Pipeline na base de teste...\")\n",
    "previsoes_xgboost_vth_no_early_stp = pipeline_xgboost_vth_no_early_stp.predict(X_test_limpo)\n",
    "previsoes_xgboost_vth_no_early_stp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf0a37b-fdde-4df0-b767-98b5b7306989",
   "metadata": {},
   "source": [
    "##### VarianceThreshold com early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f1bbf82-0ab3-457f-8912-83877a6ee8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento com Early Stopping...\n",
      "[0]\tvalidation_0-rmse:651.55851\tvalidation_1-rmse:644.11331\n",
      "[100]\tvalidation_0-rmse:365.25354\tvalidation_1-rmse:394.99334\n",
      "[200]\tvalidation_0-rmse:270.39007\tvalidation_1-rmse:329.35248\n",
      "[300]\tvalidation_0-rmse:229.49683\tvalidation_1-rmse:311.12246\n",
      "[400]\tvalidation_0-rmse:205.14442\tvalidation_1-rmse:302.79376\n",
      "[500]\tvalidation_0-rmse:191.44309\tvalidation_1-rmse:296.36110\n",
      "[600]\tvalidation_0-rmse:178.60547\tvalidation_1-rmse:292.81452\n",
      "[700]\tvalidation_0-rmse:169.35049\tvalidation_1-rmse:288.31444\n",
      "[800]\tvalidation_0-rmse:163.12717\tvalidation_1-rmse:285.92783\n",
      "[900]\tvalidation_0-rmse:156.10111\tvalidation_1-rmse:283.44115\n",
      "[1000]\tvalidation_0-rmse:150.05652\tvalidation_1-rmse:281.54239\n",
      "[1100]\tvalidation_0-rmse:143.69693\tvalidation_1-rmse:280.06597\n",
      "[1200]\tvalidation_0-rmse:136.98101\tvalidation_1-rmse:278.77098\n",
      "[1300]\tvalidation_0-rmse:129.84259\tvalidation_1-rmse:277.02788\n",
      "[1400]\tvalidation_0-rmse:125.06157\tvalidation_1-rmse:276.17257\n",
      "[1500]\tvalidation_0-rmse:119.27160\tvalidation_1-rmse:274.79013\n",
      "[1600]\tvalidation_0-rmse:114.15396\tvalidation_1-rmse:274.04965\n",
      "[1700]\tvalidation_0-rmse:109.37914\tvalidation_1-rmse:273.41635\n",
      "[1800]\tvalidation_0-rmse:105.88616\tvalidation_1-rmse:273.05303\n",
      "[1898]\tvalidation_0-rmse:102.20956\tvalidation_1-rmse:272.68022\n",
      "Treinamento concluído!\n",
      "score: 0.8372461199760437\n",
      "Melhor iteração encontrada: 1879\n",
      "\n",
      "Fazendo previsões com o Pipeline na base de teste...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 557.6438 , 2074.6257 , 1401.6632 , ...,  331.96045,  331.71478,\n",
       "       1486.9435 ], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- DEFINIR O PIPELINE DE PRÉ-PROCESSAMENTO ---\n",
    "# Vamos criar um pipeline apenas para as etapas de transformação.\n",
    "# Isso facilita a aplicação consistente do pré-processamento.\n",
    "preprocessing_pipeline_vth_std = Pipeline([\n",
    "    ('variance_threshold', VarianceThreshold(threshold=1)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "# --- APLICAR O PRÉ-PROCESSAMENTO NOS DADOS ---\n",
    "# Aprender com o treino e transformar o treino\n",
    "X_train_processed_vth_std = preprocessing_pipeline_vth_std.fit_transform(X_train_early_stp_limpo)\n",
    "\n",
    "# Apenas transformar a validação e o teste\n",
    "X_val_processed_vth_std = preprocessing_pipeline_vth_std.transform(X_val_limpo)\n",
    "X_test_processed_vth_std = preprocessing_pipeline_vth_std.transform(X_test_limpo)\n",
    "\n",
    "# Criar o eval_set para o Early Stopping.\n",
    "# IMPORTANTE: O eval_set também precisa ser pré-processado da mesma forma!\n",
    "# Felizmente, o pipeline cuida disso se passarmos os dados brutos.\n",
    "# No entanto, a sintaxe do .fit() espera os dados já processados para o eval_set.\n",
    "# A maneira mais limpa é pré-processar os dados primeiro, como fizemos acima.\n",
    "\n",
    "eval_set = [(X_train_processed_vth_std, y_train_early_stp_limpo), (X_val_processed_vth_std, y_val_limpo)]\n",
    "\n",
    "# --- TREINAR O MODELO FINAL COM EARLY STOPPING ---\n",
    "# Vamos treinar apenas o modelo XGBoost com os dados já processados.\n",
    "pipeline_xgboost_vth_std = xgb.XGBRegressor(\n",
    "    n_estimators=2000, # Um número alto, pois vamos parar antes se necessário. É o número total de especialistas (árvores de decisão)\n",
    "    learning_rate=0.01, # É o peso dado (de 0 a 1) na confiança que o modelo tem da correção proposta pela nova árvore (n_estimators)\n",
    "    max_depth=7,   # Uma profundidade de 5 significa que cada árvore pode fazer, no máximo, 3 níveis de perguntas \"se-então-senão\" para chegar a uma previsão.\n",
    "    objective='reg:squarederror',   # define matematicamente o que significa \"erro\" para o seu problema específico. Define a função de perda (loss function) que o algoritmo tentará minimizar durante o treinamento.\n",
    "    eval_metric='rmse',\n",
    "    n_jobs=-1,  # Usa todos os núcleos de CPU disponíveis para acelerar o treino\n",
    "    random_state=35,\n",
    "    early_stopping_rounds=20 # Paciência de 10 rodadas\n",
    ")\n",
    "\n",
    "print(\"Iniciando o treinamento com Early Stopping...\")\n",
    "pipeline_xgboost_vth_std.fit(\n",
    "    X_train_processed_vth_std, y_train_early_stp_limpo,\n",
    "    eval_set=eval_set,\n",
    "    verbose=100 # Mostra o progresso a cada 100 rodadas\n",
    ")\n",
    "print(\"Treinamento concluído!\")\n",
    "print(f\"score: {pipeline_xgboost_vth_std.score(X_test_processed_vth_std, y_test_limpo)}\")\n",
    "print(f\"Melhor iteração encontrada: {pipeline_xgboost_vth_std.best_iteration}\")\n",
    "\n",
    "# --- FAZER PREVISÕES COM O PIPELINE ---\n",
    "print(\"\\nFazendo previsões com o Pipeline na base de teste...\")\n",
    "previsoes_xgboost_vth_std = pipeline_xgboost_vth_std.predict(X_test_processed_vth_std)\n",
    "previsoes_xgboost_vth_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e990bd14-20e1-457b-99c6-71d30be6c7f8",
   "metadata": {},
   "source": [
    "##### SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcbbce95-efd1-4458-8517-9b2dd384cdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento com Early Stopping...\n",
      "[0]\tvalidation_0-rmse:612.39895\tvalidation_1-rmse:607.34650\n",
      "[99]\tvalidation_0-rmse:265.40845\tvalidation_1-rmse:343.06491\n",
      "Treinamento concluído!\n",
      "score: 0.759266197681427\n",
      "Melhor iteração encontrada: 91\n",
      "\n",
      "Fazendo previsões com o Pipeline na base de teste...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 514.91296, 1712.7094 , 1162.7498 , ...,  132.07289,   72.15905,\n",
       "       1526.8689 ], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- DEFINIR O PIPELINE DE PRÉ-PROCESSAMENTO ---\n",
    "# Vamos criar um pipeline apenas para as etapas de transformação.\n",
    "# Isso facilita a aplicação consistente do pré-processamento.\n",
    "preprocessing_pipeline_KBest_std = Pipeline([\n",
    "    ('select_k_best', SelectKBest(score_func=f_regression, k=5)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# --- APLICAR O PRÉ-PROCESSAMENTO NOS DADOS ---\n",
    "# Aprender com o treino e transformar o treino\n",
    "X_train_processed_KBest_std = preprocessing_pipeline_KBest_std.fit_transform(X_train_early_stp_limpo, y_train_early_stp_limpo)\n",
    "\n",
    "# Apenas transformar a validação e o teste\n",
    "X_val_processed_KBest_std = preprocessing_pipeline_KBest_std.transform(X_val_limpo)\n",
    "X_test_processed_KBest_std = preprocessing_pipeline_KBest_std.transform(X_test_limpo)\n",
    "\n",
    "# Criar o eval_set para o Early Stopping.\n",
    "# IMPORTANTE: O eval_set também precisa ser pré-processado da mesma forma!\n",
    "# Felizmente, o pipeline cuida disso se passarmos os dados brutos.\n",
    "# No entanto, a sintaxe do .fit() espera os dados já processados para o eval_set.\n",
    "# A maneira mais limpa é pré-processar os dados primeiro, como fizemos acima.\n",
    "\n",
    "eval_set = [(X_train_processed_KBest_std, y_train_early_stp_limpo), (X_val_processed_KBest_std, y_val_limpo)]\n",
    "\n",
    "# --- TREINAR O MODELO FINAL COM EARLY STOPPING ---\n",
    "# Vamos treinar apenas o modelo XGBoost com os dados já processados.\n",
    "pipeline_xgboost_KBest_std = xgb.XGBRegressor(\n",
    "    n_estimators=100, # Um número alto, pois vamos parar antes se necessário. É o número total de especialistas (árvores de decisão)\n",
    "    learning_rate=0.1, # É o peso dado (de 0 a 1) na confiança que o modelo tem da correção proposta pela nova árvore (n_estimators)\n",
    "    max_depth=5,   # Uma profundidade de 5 significa que cada árvore pode fazer, no máximo, 3 níveis de perguntas \"se-então-senão\" para chegar a uma previsão.\n",
    "    objective='reg:squarederror',   # define matematicamente o que significa \"erro\" para o seu problema específico. Define a função de perda (loss function) que o algoritmo tentará minimizar durante o treinamento.\n",
    "    eval_metric='rmse',\n",
    "    n_jobs=-1,  # Usa todos os núcleos de CPU disponíveis para acelerar o treino\n",
    "    random_state=35,\n",
    "    early_stopping_rounds=20 # Paciência de 10 rodadas\n",
    ")\n",
    "\n",
    "print(\"Iniciando o treinamento com Early Stopping...\")\n",
    "pipeline_xgboost_KBest_std.fit(\n",
    "    X_train_processed_KBest_std, y_train_early_stp_limpo,\n",
    "    eval_set=eval_set,\n",
    "    verbose=100 # Mostra o progresso a cada 100 rodadas\n",
    ")\n",
    "print(\"Treinamento concluído!\")\n",
    "print(f\"score: {pipeline_xgboost_KBest_std.score(X_test_processed_KBest_std, y_test_limpo)}\")\n",
    "print(f\"Melhor iteração encontrada: {pipeline_xgboost_KBest_std.best_iteration}\")\n",
    "\n",
    "# --- FAZER PREVISÕES COM O PIPELINE ---\n",
    "print(\"\\nFazendo previsões com o Pipeline na base de teste...\")\n",
    "previsoes_xgboost_KBest_std = pipeline_xgboost_KBest_std.predict(X_test_processed_KBest_std)\n",
    "previsoes_xgboost_KBest_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ebefed-6488-4790-b5b1-dec0282ef320",
   "metadata": {},
   "source": [
    "# 8. Analisando os resultados dos pipelines\n",
    "Agora vamos analisar a predição dos pipelines do modelo XGBoost usados com as metricas usadas anteriormente (RMSE, MAPE, alem de mostar a quantidade bruta de erros na predição):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cca1ac1-5508-4d6a-9c41-09f579958a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score do pipeline_xgboost_unclean: 0.8569183945655823\n",
      "rmse do pipeline_xgboost_unclean: 12.04 bicicletas.\n",
      "mae do pipeline_xgboost_unclean: 144.89 bicicletas.\n",
      "------------------------------\n",
      "score do pipeline_xgboost_unclean_early_stp: 0.8476635813713074\n",
      "rmse do pipeline_xgboost_unclean_early_stp: 12.24 bicicletas.\n",
      "mae do pipeline_xgboost_unclean_early_stp: 149.94 bicicletas.\n",
      "------------------------------\n",
      "score do pipeline_xgboost_outlier: 0.8476245999336243\n",
      "rmse do pipeline_xgboost_outlier: 12.35 bicicletas.\n",
      "mae do pipeline_xgboost_outlier: 152.53 bicicletas.\n",
      "------------------------------\n",
      "score do pipeline_xgboost_vth: 0.8372461199760437\n",
      "rmse do pipeline_xgboost_vth: 12.42 bicicletas.\n",
      "mae do pipeline_xgboost_vth: 154.20 bicicletas.\n",
      "------------------------------\n",
      "score do pipeline_xgboost_KBest: 0.7581508755683899\n",
      "rmse do pipeline_xgboost_KBest: 14.00 bicicletas.\n",
      "mae do pipeline_xgboost_KBest: 196.11 bicicletas.\n",
      "------------------------------\n",
      "score do pipeline_xgboost_vth_no_early_stp: 0.8414660692214966\n",
      "rmse do pipeline_xgboost_vth_no_early_stp: 12.42 bicicletas.\n",
      "mae do pipeline_xgboost_vth_no_early_stp: 154.17 bicicletas.\n",
      "------------------------------\n",
      "score do pipeline_xgboost_vth_std: 0.8372461199760437\n",
      "rmse do pipeline_xgboost_vth_std: 12.42 bicicletas.\n",
      "mae do pipeline_xgboost_vth_std: 154.20 bicicletas.\n",
      "------------------------------\n",
      "score do pipeline_xgboost_KBest_std: 0.759266197681427\n",
      "rmse do pipeline_xgboost_KBest_std: 14.05 bicicletas.\n",
      "mae do pipeline_xgboost_KBest_std: 197.36 bicicletas.\n"
     ]
    }
   ],
   "source": [
    "# calculando o rmse entre o valor real e o predito dos pipeline\n",
    "rmse_previsoes_xgboost_unclean = np.sqrt(mean_absolute_error(y_test, previsoes_xgboost_unclean))\n",
    "rmse_previsoes_xgboost_unclean_early_stp = np.sqrt(mean_absolute_error(y_test, previsoes_xgboost_unclean_early_stp))\n",
    "rmse_previsoes_xgboost_outlier = np.sqrt(mean_absolute_error(y_test_limpo, previsoes_xgboost_outlier))\n",
    "rmse_previsoes_xgboost_vth = np.sqrt(mean_absolute_error(y_test_limpo, previsoes_xgboost_vth))\n",
    "rmse_previsoes_xgboost_KBest = np.sqrt(mean_absolute_error(y_test_limpo, previsoes_xgboost_KBest))\n",
    "rmse_previsoes_xgboost_vth_no_early_stp = np.sqrt(mean_absolute_error(y_test_limpo, previsoes_xgboost_vth_no_early_stp))\n",
    "rmse_previsoes_xgboost_vth_std = np.sqrt(mean_absolute_error(y_test_limpo, previsoes_xgboost_vth_std))\n",
    "rmse_previsoes_xgboost_KBest_std= np.sqrt(mean_absolute_error(y_test_limpo, previsoes_xgboost_KBest_std))\n",
    "\n",
    "# calculando o mape entre o valor real e o predito dos pipeline\n",
    "mae_previsoes_xgboost_unclean = mean_absolute_error(y_test, previsoes_xgboost_unclean)\n",
    "mae_previsoes_xgboost_unclean_early_stp = mean_absolute_error(y_test, previsoes_xgboost_unclean_early_stp)\n",
    "mae_previsoes_xgboost_outlier = mean_absolute_error(y_test_limpo, previsoes_xgboost_outlier)\n",
    "mae_previsoes_xgboost_vth = mean_absolute_error(y_test_limpo, previsoes_xgboost_vth)\n",
    "mae_previsoes_xgboost_KBest = mean_absolute_error(y_test_limpo, previsoes_xgboost_KBest)\n",
    "mae_previsoes_xgboost_vth_no_early_stp = mean_absolute_error(y_test_limpo, previsoes_xgboost_vth_no_early_stp)\n",
    "mae_previsoes_xgboost_vth_std = mean_absolute_error(y_test_limpo, previsoes_xgboost_vth_std)\n",
    "mae_previsoes_xgboost_KBest_std = mean_absolute_error(y_test_limpo, previsoes_xgboost_KBest_std)\n",
    "\n",
    "\n",
    "# Mostra metricas\n",
    "print(f\"score do pipeline_xgboost_unclean: {pipeline_xgboost_unclean.score(X_test, y_test)}\")\n",
    "print(f\"rmse do pipeline_xgboost_unclean: {rmse_previsoes_xgboost_unclean:.2f} bicicletas.\" )\n",
    "print(f\"mae do pipeline_xgboost_unclean: {mae_previsoes_xgboost_unclean:.2f} bicicletas.\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"score do pipeline_xgboost_unclean_early_stp: {pipeline_xgboost_unclean_early_stp.score(X_test, y_test)}\")\n",
    "print(f\"rmse do pipeline_xgboost_unclean_early_stp: {rmse_previsoes_xgboost_unclean_early_stp:.2f} bicicletas.\" )\n",
    "print(f\"mae do pipeline_xgboost_unclean_early_stp: {mae_previsoes_xgboost_unclean_early_stp:.2f} bicicletas.\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"score do pipeline_xgboost_outlier: {pipeline_xgboost_outlier.score(X_test_limpo, y_test_limpo)}\")\n",
    "print(f\"rmse do pipeline_xgboost_outlier: {rmse_previsoes_xgboost_outlier:.2f} bicicletas.\" )\n",
    "print(f\"mae do pipeline_xgboost_outlier: {mae_previsoes_xgboost_outlier:.2f} bicicletas.\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"score do pipeline_xgboost_vth: {pipeline_xgboost_vth.score(X_test_processed_vth, y_test_limpo)}\")\n",
    "print(f\"rmse do pipeline_xgboost_vth: {rmse_previsoes_xgboost_vth:.2f} bicicletas.\" )\n",
    "print(f\"mae do pipeline_xgboost_vth: {mae_previsoes_xgboost_vth:.2f} bicicletas.\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"score do pipeline_xgboost_KBest: {pipeline_xgboost_KBest.score(X_test_processed_KBest, y_test_limpo)}\")\n",
    "print(f\"rmse do pipeline_xgboost_KBest: {rmse_previsoes_xgboost_KBest:.2f} bicicletas.\" )\n",
    "print(f\"mae do pipeline_xgboost_KBest: {mae_previsoes_xgboost_KBest:.2f} bicicletas.\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"score do pipeline_xgboost_vth_no_early_stp: {pipeline_xgboost_vth_no_early_stp.score(X_test_limpo, y_test_limpo)}\")\n",
    "print(f\"rmse do pipeline_xgboost_vth_no_early_stp: {rmse_previsoes_xgboost_vth_no_early_stp:.2f} bicicletas.\" )\n",
    "print(f\"mae do pipeline_xgboost_vth_no_early_stp: {mae_previsoes_xgboost_vth_no_early_stp:.2f} bicicletas.\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"score do pipeline_xgboost_vth_std: {pipeline_xgboost_vth_std.score(X_test_processed_vth_std, y_test_limpo)}\")\n",
    "print(f\"rmse do pipeline_xgboost_vth_std: {rmse_previsoes_xgboost_vth_std:.2f} bicicletas.\" )\n",
    "print(f\"mae do pipeline_xgboost_vth_std: {mae_previsoes_xgboost_vth_std:.2f} bicicletas.\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"score do pipeline_xgboost_KBest_std: {pipeline_xgboost_KBest_std.score(X_test_processed_KBest_std, y_test_limpo)}\")\n",
    "print(f\"rmse do pipeline_xgboost_KBest_std: {rmse_previsoes_xgboost_KBest_std:.2f} bicicletas.\" )\n",
    "print(f\"mae do pipeline_xgboost_KBest_std: {mae_previsoes_xgboost_KBest_std:.2f} bicicletas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b755a-48e5-4cad-8370-830d6bdc3422",
   "metadata": {},
   "source": [
    "# 9. Otimizando hiperparametros\n",
    "## Grid Search CV (Busca em Grade com Validação Cruzada)\n",
    "GridSearchCV é uma das ferramentas mais importantes e poderosas para otimizar a performance de um modelo de Machine Learning. Ela automatiza o processo tedioso e demorado de encontrar a melhor combinação de hiperparâmetros para o seu modelo.\n",
    "\n",
    "Vamos verificar quais são os melhores parÂmetros para usar com o VarianceThreshold e XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e375993-cbe2-43d1-b2ce-3a94ec0c7926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a busca pelos melhores hiperparâmetros...\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Busca concluída!\n",
      "\n",
      "--- Melhores Parâmetros Encontrados ---\n",
      "{'variance_threshold__threshold': 0.5, 'xgboost_regressor__eval_metric': 'rmse', 'xgboost_regressor__learning_rate': 0.05, 'xgboost_regressor__max_depth': 7, 'xgboost_regressor__n_estimators': 2000}\n",
      "\n",
      "--- Melhor Pontuação (RMSE) na Validação Cruzada ---\n",
      "257.88 bicicletas\n",
      "\n",
      "--- Avaliando o melhor modelo no conjunto de teste ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rmse_previsoes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m rmse_teste \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test_limpo, previsoes_finais))\n\u001b[0;32m     83\u001b[0m mape_teste \u001b[38;5;241m=\u001b[39m mean_absolute_percentage_error(y_test_limpo, previsoes_finais)\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE no teste: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse_previsoes\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bicicletas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE no teste: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse_teste\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bicicletas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rmse_previsoes' is not defined"
     ]
    }
   ],
   "source": [
    "# ---  DEFINIR O PIPELINE ---\n",
    "'''\n",
    "pipeline_default = Pipeline([\n",
    "    ('select_k_best', SelectKBest(score_func=f_regression)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgboost_regressor', xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        eval_metric='rmse',\n",
    "        n_jobs=-1,\n",
    "        random_state=35\n",
    "    ))\n",
    "])\n",
    "'''\n",
    "\n",
    "pipeline_default = Pipeline([\n",
    "    ('variance_threshold', VarianceThreshold()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgboost_regressor', xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_jobs=-1,\n",
    "        random_state=35\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ---  DEFINIR A GRADE DE HIPERPARÂMETROS ---\n",
    "# Usamos a sintaxe 'nome_da_etapa__nome_do_parametro'\n",
    "param_grid = {\n",
    "    'variance_threshold__threshold': [0.5, 0.05, 0.01],  # Testar diferentes números de features\n",
    "    'xgboost_regressor__n_estimators': [1000, 1500, 2000],\n",
    "    'xgboost_regressor__max_depth': [3, 5, 7],\n",
    "    'xgboost_regressor__learning_rate': [0.5, 0.05, 0.01],\n",
    "    'xgboost_regressor__eval_metric': ['rmse', 'mae']\n",
    "}\n",
    "# Total de combinações a serem testadas: 3 * 3 * 3 * 3 * 2 = 162 combinações.\n",
    "# Se cv=5, isso significa 162 * 5 = 810 treinamentos de modelo!\n",
    "\n",
    "# ---  INSTANCIAR E EXECUTAR O GRIDSEARCHCV ---\n",
    "\n",
    "# Instanciar o GridSearchCV\n",
    "# estimator: o pipeline ou modelo a ser otimizado.\n",
    "# param_grid: a grade de parâmetros.\n",
    "# cv: o número de folds para a validação cruzada.\n",
    "# scoring: a métrica a ser otimizada. Para regressão, 'neg_mean_squared_error' é comum.\n",
    "#          (É negativo porque o GridSearchCV tenta maximizar a pontuação, e nós queremos minimizar o erro).\n",
    "# n_jobs: -1 para usar todos os núcleos de CPU e acelerar a busca.\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline_default,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # número de validação cruzada\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1, # usa todos os nucleos do processador\n",
    "    verbose=3 # Mostra o progresso\n",
    ")\n",
    "\n",
    "print(\"Iniciando a busca pelos melhores hiperparâmetros...\")\n",
    "# O .fit() aqui vai treinar o pipeline para cada combinação de parâmetros\n",
    "grid_search.fit(X_train_limpo, y_train_limpo)\n",
    "print(\"Busca concluída!\")\n",
    "\n",
    "\n",
    "# --- ANALISAR OS RESULTADOS ---\n",
    "\n",
    "print(\"\\n--- Melhores Parâmetros Encontrados ---\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\n--- Melhor Pontuação (RMSE) na Validação Cruzada ---\")\n",
    "# A pontuação é negativa, então multiplicamos por -1 para ver o RMSE real\n",
    "best_rmse = -grid_search.best_score_\n",
    "print(f\"{best_rmse:.2f} bicicletas\")\n",
    "\n",
    "# O grid_search.best_estimator_ é o pipeline já treinado com a melhor combinação de parâmetros\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# --- AVALIAR O MELHOR MODELO NO CONJUNTO DE TESTE ---\n",
    "\n",
    "print(\"\\n--- Avaliando o melhor modelo no conjunto de teste ---\")\n",
    "previsoes = best_pipeline.predict(X_test_limpo)\n",
    "previsoes_finais = np.maximum(0, previsoes) # Pós-processamento\n",
    "\n",
    "mae_teste = mean_absolute_error(y_test_limpo, previsoes_finais)\n",
    "rmse_teste = np.sqrt(mean_squared_error(y_test_limpo, previsoes_finais))\n",
    "\n",
    "print(f\"MAE no teste: {mae_teste:.2f} bicicletas\")\n",
    "print(f\"RMSE no teste: {rmse_teste:.2f} bicicletas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556afa0-b1e1-4449-bda8-e46b4188b756",
   "metadata": {},
   "source": [
    "# 10. Conclusões\n",
    "* A função **f_regression** e **mutual_info_regression** do método **SelectKBest** com um k=7 retornaram as mesmas colunas.\n",
    "* Usar o VarianceThreshold com threshold=1 descartou 3 colunas, manteve as colunas; `Day,\tWeekday,\tHour,\tTemperature(°C),\tHumidity(%),\tVisibility (10m), e\tRainfall(mm)`.\n",
    "* Usar o SelectKBest com um k=7 manteve as colunas; `Hour, Temperature(°C), Humidity(%), Wind speed (m/s),\tVisibility (10m),\tSolar Radiation (MJ/m2) e\tSnowfall (cm)`.\n",
    "* Usar o VarianceThreshold mostrou melhor resultados doque usar o SelectKBest.\n",
    "* Para o modelo xgboost sem nenhum tratamento de dados foi realizado uma predição de demando em um cenário de tempestade forte (mostrado a baixo), e previu um valor de -26 bicicletas, isso pode significar que o aluguel será algo raro para esssa situação.\n",
    "    * 'Day': 28,\n",
    "    * 'Weekday': 7,\n",
    "    * 'Hour': 4,\n",
    "    * 'Temperature(°C)': -10.5,\n",
    "    * 'Humidity(%)': 95,\n",
    "    * 'Wind speed (m/s)': 5.2,\n",
    "    * 'Visibility (10m)': 1950,\n",
    "    * 'Solar Radiation (MJ/m2)': 0.0,\n",
    "    * 'Rainfall(mm)': 10.0, 'Snowfall (cm)': 5.0,\n",
    "* A remoção de colunas com o VarianceThreshold ou SelectKBest deixou o modelo pior.\n",
    "*  Os hiperparâmetros retornados pelo método Grid Search CV não foram tão bons quantos os escolhidos a dedo nos pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c6405-f094-4cff-8434-f4045acd272f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
